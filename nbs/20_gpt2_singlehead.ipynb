{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2 model (Custom Single Head)\n",
    "\n",
    "> This notebook contains some example of how to use the GPT2-based models in this NLP library\n",
    "\n",
    "- skip_showdoc: true\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this series, we walk through some of the capability of this library: single-head classification, multi-head classification, multi-label classification, and regression. If you want a more detailed tutorial, check [this](https://anhquan0412.github.io/that-nlp-library/model_classification_tutorial.html) out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will specify a (or a list) of GPUs for training\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from that_nlp_library.text_transformation import *\n",
    "from that_nlp_library.text_augmentation import *\n",
    "from that_nlp_library.text_main import *\n",
    "from that_nlp_library.utils import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from underthesea import text_normalize\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nlpaug.augmenter.char as nac\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the custom augmentation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_aug_stochastic(x,aug=None,p=0.5):\n",
    "    if not isinstance(x,list): \n",
    "        if random.random()<p: return aug.augment(x)[0]\n",
    "        return x\n",
    "    news=[]\n",
    "    originals=[]\n",
    "    for _x in x:\n",
    "        if random.random()<p: news.append(_x)\n",
    "        else: originals.append(_x)\n",
    "    # only perform augmentation when needed\n",
    "    if len(news): news = aug.augment(news)\n",
    "    return news+originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = nac.KeyboardAug(aug_char_max=3,aug_char_p=0.1,aug_word_p=0.07)\n",
    "nearby_aug_func = partial(nlp_aug_stochastic,aug=aug,p=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a TextDataController object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reuse the data and the preprocessings in [this tutorial](https://anhquan0412.github.io/that-nlp-library/text_main.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv'],split='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         sup_types='classification',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         # add \"str.lower\" here because nearby_aug might return uppercase character\n",
    "                         val_ratio=0.2,\n",
    "                         batch_size=1000,\n",
    "                         seed=42,\n",
    "                         num_proc=20,\n",
    "                         verbose=False\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our tokenizer for GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/nlp_dev/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_tokenizer = AutoTokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tokenizer.pad_token = _tokenizer.eos_token\n",
    "_tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "}\n",
      "50257\n"
     ]
    }
   ],
   "source": [
    "print(_tokenizer)\n",
    "print(len(_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process and tokenize our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdc.process_and_tokenize(_tokenizer,max_length=100,shuffle_trn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Title', 'Review Text', 'Division Name', 'Department Name', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 18102\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Title', 'Review Text', 'Division Name', 'Department Name', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4526\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdc.main_ddict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experiment: GPT2 Single-Head Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train a vanilla GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from that_nlp_library.models.roberta.classifiers import ConcatHeadSimple\n",
    "from that_nlp_library.model_main import *\n",
    "from that_nlp_library.models.gpt2.classifiers import *\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using HuggingFace model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.gpt2.modeling_gpt2 import GPT2ForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(tdc.label_lists[0])\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/nlp_dev/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "model = GPT2ForSequenceClassification.from_pretrained('gpt2',num_labels=num_classes)\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 768)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score]\n",
    "controller = ModelController(model,tdc,seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can start training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='849' max='849' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [849/849 02:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score Department name</th>\n",
       "      <th>Accuracy Score Department name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.283675</td>\n",
       "      <td>0.739092</td>\n",
       "      <td>0.910075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.656600</td>\n",
       "      <td>0.261791</td>\n",
       "      <td>0.749196</td>\n",
       "      <td>0.920901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.656600</td>\n",
       "      <td>0.263783</td>\n",
       "      <td>0.751478</td>\n",
       "      <td>0.922448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 8e-5\n",
    "bs=32\n",
    "wd=0.01\n",
    "epochs= 3\n",
    "\n",
    "controller.fit(epochs,lr,\n",
    "               metric_funcs=metric_funcs,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=compute_metrics,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the GPT2Base model (designed for not only single-head but multi-head, multi-label ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/nlp_dev/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gpt2body = GPT2Model.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading body weights. This assumes the body is the very first block of your custom architecture\n",
      "Total parameters: 124444416\n",
      "Total trainable parameters: 124444416\n"
     ]
    }
   ],
   "source": [
    "# our model is more complex, so it's best to define some of its arguments\n",
    "_model_kwargs={\n",
    "    # overall model hyperparams\n",
    "    'head_class_sizes':num_classes,\n",
    "    # classfication head hyperparams\n",
    "    'classifier_dropout':0.1 \n",
    "}\n",
    "\n",
    "model = model_init_classification(model_class = GPT2BaseForSequenceClassification,\n",
    "                                  cpoint_path = 'gpt2', \n",
    "                                  output_hidden_states=False, # since we are not using 'hidden layer contatenation' technique\n",
    "                                  seed=42,\n",
    "                                  body_model=gpt2body,\n",
    "                                  model_kwargs = _model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 768)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resize token embedding\n",
    "model.body_model.resize_token_embeddings(len(_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Create ModelController and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score]\n",
    "controller = ModelController(model,tdc,seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can start training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='849' max='849' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [849/849 03:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score Department name</th>\n",
       "      <th>Accuracy Score Department name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.293438</td>\n",
       "      <td>0.736128</td>\n",
       "      <td>0.910296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.743200</td>\n",
       "      <td>0.263558</td>\n",
       "      <td>0.748740</td>\n",
       "      <td>0.918692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.743200</td>\n",
       "      <td>0.264788</td>\n",
       "      <td>0.746244</td>\n",
       "      <td>0.917587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 8e-5\n",
    "bs=32\n",
    "wd=0.01\n",
    "epochs= 3\n",
    "\n",
    "controller.fit(epochs,lr,\n",
    "               metric_funcs=metric_funcs,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=compute_metrics,\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    }
   ],
   "source": [
    "df_val = controller.predict_ddict(ds_type='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>label</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>pred_Department Name</th>\n",
       "      <th>pred_prob_Department Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>general petite . . such a fun jacket ! great t...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>2</td>\n",
       "      <td>[50256, 50256, 50256, 50256, 50256, 50256, 502...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Jackets</td>\n",
       "      <td>0.879402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simple and elegant</td>\n",
       "      <td>general petite . simple and elegant . i though...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>4</td>\n",
       "      <td>[24622, 4273, 578, 764, 2829, 290, 19992, 764,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Tops</td>\n",
       "      <td>0.998374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>retro and pretty</td>\n",
       "      <td>general . retro and pretty . this top has a bi...</td>\n",
       "      <td>general</td>\n",
       "      <td>Tops</td>\n",
       "      <td>4</td>\n",
       "      <td>[50256, 50256, 50256, 50256, 50256, 50256, 502...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Tops</td>\n",
       "      <td>0.999834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>summer/fall wear</td>\n",
       "      <td>general petite . summer / fall wear . i first ...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1</td>\n",
       "      <td>[50256, 50256, 50256, 50256, 50256, 50256, 502...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0.949195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perfect except slip</td>\n",
       "      <td>general petite . perfect except slip . this is...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1</td>\n",
       "      <td>[50256, 50256, 50256, 50256, 50256, 50256, 502...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0.993209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Title                                        Review Text  \\\n",
       "0                       general petite . . such a fun jacket ! great t...   \n",
       "1   simple and elegant  general petite . simple and elegant . i though...   \n",
       "2     retro and pretty  general . retro and pretty . this top has a bi...   \n",
       "3     summer/fall wear  general petite . summer / fall wear . i first ...   \n",
       "4  perfect except slip  general petite . perfect except slip . this is...   \n",
       "\n",
       "    Division Name Department Name  label  \\\n",
       "0  general petite        Intimate      2   \n",
       "1  general petite            Tops      4   \n",
       "2         general            Tops      4   \n",
       "3  general petite         Dresses      1   \n",
       "4  general petite         Dresses      1   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [50256, 50256, 50256, 50256, 50256, 50256, 502...   \n",
       "1  [24622, 4273, 578, 764, 2829, 290, 19992, 764,...   \n",
       "2  [50256, 50256, 50256, 50256, 50256, 50256, 502...   \n",
       "3  [50256, 50256, 50256, 50256, 50256, 50256, 502...   \n",
       "4  [50256, 50256, 50256, 50256, 50256, 50256, 502...   \n",
       "\n",
       "                                      attention_mask pred_Department Name  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...              Jackets   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                 Tops   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...                 Tops   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ...              Dresses   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...              Dresses   \n",
       "\n",
       "   pred_prob_Department Name  \n",
       "0                   0.879402  \n",
       "1                   0.998374  \n",
       "2                   0.999834  \n",
       "3                   0.949195  \n",
       "4                   0.993209  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = df_val.to_pandas()\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try to get your metric to see if it matches your last traing epoch's above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7462441580902758"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_val['Department Name'],df_val['pred_Department Name'],average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experiment: GPT2 Single-Head Classification (with hidden layer concatenation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train a custom GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from that_nlp_library.models.roberta.classifiers import ConcatHeadSimple\n",
    "from that_nlp_library.model_main import *\n",
    "from that_nlp_library.models.gpt2.classifiers import *\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(tdc.label_lists[0])\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/nlp_dev/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gpt2body = GPT2Model.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can define a classification head. One trick we can use to boost the performance of our entire model is to concatenate the outputs of the last tokens from the four last layers of the pre-trained Roberta model (an improvised approach from this source: https://ieeexplore.ieee.org/document/9335912). We already define such custom head (`ConcatHeadSimple`), and the necessary architecture to make it work (`GPT2HiddenStateConcatForSequenceClassification`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading body weights. This assumes the body is the very first block of your custom architecture\n",
      "Total parameters: 124449030\n",
      "Total trainable parameters: 124449030\n"
     ]
    }
   ],
   "source": [
    "# our model is more complex, so it's best to define some of its arguments\n",
    "_model_kwargs={\n",
    "    # overall model hyperparams\n",
    "    'head_class_sizes':num_classes,\n",
    "    'head_class': ConcatHeadSimple,\n",
    "    # classfication head hyperparams\n",
    "    'layer2concat':2, # you can change the number of layers to concat (default is 4, based on the paper)\n",
    "    'classifier_dropout':0.1 \n",
    "}\n",
    "\n",
    "model = model_init_classification(model_class = GPT2HiddenStateConcatForSequenceClassification,\n",
    "                                  cpoint_path = 'gpt2', \n",
    "                                  output_hidden_states=True, # since we are using 'hidden layer contatenation' technique\n",
    "                                  seed=42,\n",
    "                                  body_model=gpt2body,\n",
    "                                  model_kwargs = _model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 768)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resize token embedding\n",
    "model.body_model.resize_token_embeddings(len(_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score]\n",
    "controller = ModelController(model,tdc,seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can start training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='849' max='849' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [849/849 03:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score Department name</th>\n",
       "      <th>Accuracy Score Department name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.316337</td>\n",
       "      <td>0.733385</td>\n",
       "      <td>0.907866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.719600</td>\n",
       "      <td>0.271895</td>\n",
       "      <td>0.746649</td>\n",
       "      <td>0.915820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.719600</td>\n",
       "      <td>0.269325</td>\n",
       "      <td>0.745756</td>\n",
       "      <td>0.916924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 8e-5\n",
    "bs=32\n",
    "wd=0.01\n",
    "epochs= 3\n",
    "\n",
    "controller.fit(epochs,lr,\n",
    "               metric_funcs=metric_funcs,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=compute_metrics,\n",
    "              )\n",
    "\n",
    "# Epoch\tTraining Loss\tValidation Loss\tF1 Score Department name\tAccuracy Score Department name\n",
    "# 1\tNo log\t0.301476\t0.746599\t0.914494\n",
    "# 2\t0.400300\t0.263080\t0.749670\t0.920901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.trainer.model.save_pretrained('./sample_weights/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'head_class_sizes': 6,\n",
       " 'head_class': that_nlp_library.models.roberta.classifiers.ConcatHeadSimple,\n",
       " 'layer2concat': 2,\n",
       " 'classifier_dropout': 0.1}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_model_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 124449030\n",
      "Total trainable parameters: 124449030\n"
     ]
    }
   ],
   "source": [
    "trained_model = model_init_classification(model_class = GPT2HiddenStateConcatForSequenceClassification,\n",
    "                                          cpoint_path = Path('./sample_weights/my_model'), \n",
    "                                          output_hidden_states=True,\n",
    "                                          seed=42,\n",
    "                                          model_kwargs = _model_kwargs)\n",
    "\n",
    "controller = ModelController(trained_model,tdc,seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Train/Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    }
   ],
   "source": [
    "df_val = controller.predict_ddict(ds_type='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>label</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>pred_Department Name</th>\n",
       "      <th>pred_prob_Department Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>general petite . . such a fun jacket ! great t...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>2</td>\n",
       "      <td>[50256, 50256, 50256, 50256, 50256, 50256, 502...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Jackets</td>\n",
       "      <td>0.937680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simple and elegant</td>\n",
       "      <td>general petite . simple and elegant . i though...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>4</td>\n",
       "      <td>[24622, 4273, 578, 764, 2829, 290, 19992, 764,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Tops</td>\n",
       "      <td>0.997647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>retro and pretty</td>\n",
       "      <td>general . retro and pretty . this top has a bi...</td>\n",
       "      <td>general</td>\n",
       "      <td>Tops</td>\n",
       "      <td>4</td>\n",
       "      <td>[50256, 50256, 50256, 50256, 50256, 50256, 502...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Tops</td>\n",
       "      <td>0.998581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>summer/fall wear</td>\n",
       "      <td>general petite . summer / fall wear . i first ...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1</td>\n",
       "      <td>[50256, 50256, 50256, 50256, 50256, 50256, 502...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0.973116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perfect except slip</td>\n",
       "      <td>general petite . perfect except slip . this is...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1</td>\n",
       "      <td>[50256, 50256, 50256, 50256, 50256, 50256, 502...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0.996431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Title                                        Review Text  \\\n",
       "0                       general petite . . such a fun jacket ! great t...   \n",
       "1   simple and elegant  general petite . simple and elegant . i though...   \n",
       "2     retro and pretty  general . retro and pretty . this top has a bi...   \n",
       "3     summer/fall wear  general petite . summer / fall wear . i first ...   \n",
       "4  perfect except slip  general petite . perfect except slip . this is...   \n",
       "\n",
       "    Division Name Department Name  label  \\\n",
       "0  general petite        Intimate      2   \n",
       "1  general petite            Tops      4   \n",
       "2         general            Tops      4   \n",
       "3  general petite         Dresses      1   \n",
       "4  general petite         Dresses      1   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [50256, 50256, 50256, 50256, 50256, 50256, 502...   \n",
       "1  [24622, 4273, 578, 764, 2829, 290, 19992, 764,...   \n",
       "2  [50256, 50256, 50256, 50256, 50256, 50256, 502...   \n",
       "3  [50256, 50256, 50256, 50256, 50256, 50256, 502...   \n",
       "4  [50256, 50256, 50256, 50256, 50256, 50256, 502...   \n",
       "\n",
       "                                      attention_mask pred_Department Name  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...              Jackets   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                 Tops   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...                 Tops   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ...              Dresses   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...              Dresses   \n",
       "\n",
       "   pred_prob_Department Name  \n",
       "0                   0.937680  \n",
       "1                   0.997647  \n",
       "2                   0.998581  \n",
       "3                   0.973116  \n",
       "4                   0.996431  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = df_val.to_pandas()\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try to get your metric to see if it matches your last traing epoch's above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.746104914178913"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_val['Department Name'],df_val['pred_Department Name'],average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go through details on how to make a prediction on a completely new and raw dataset using our trained model. For now, let's reuse the sample csv and pretend it's our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('sample_data/Womens_Clothing_Reviews.csv',encoding='utf-8-sig').sample(frac=0.2,random_state=1)\n",
    "# drop NaN values in the label column\n",
    "df_test = df_test[~df_test['Department Name'].isna()].reset_index(drop=True)\n",
    "\n",
    "# save the label, as we will calculate some metrics later. We also filter out labels with NaN Review Text,\n",
    "# as there will be a filtering processing on the test set\n",
    "true_labels = df_test.loc[~df_test['Review Text'].isna(),'Department Name'].values \n",
    "\n",
    "# drop the label (you don't need to, but this is necessary to simulate an actual test set)\n",
    "df_test.drop('Department Name',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    }
   ],
   "source": [
    "_test_dset = Dataset.from_pandas(df_test)\n",
    "_test_dset_predicted = controller.predict_raw_dset(_test_dset,\n",
    "                                                   do_filtering=True, # since we have some text filtering in the processing\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_predicted = _test_dset_predicted.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>pred_Department Name</th>\n",
       "      <th>pred_prob_Department Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perfect for work and play</td>\n",
       "      <td>general . perfect for work and play . this shi...</td>\n",
       "      <td>general</td>\n",
       "      <td>[50256, 50256, 50256, 50256, 50256, 50256, 502...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Tops</td>\n",
       "      <td>0.999322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>general petite . . i don't know why i had the ...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[24622, 4273, 578, 764, 764, 1312, 836, 470, 7...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>0.988174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great pants</td>\n",
       "      <td>general petite . great pants . thes e cords ar...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[50256, 50256, 50256, 50256, 50256, 50256, 502...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>0.995248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprisingly comfy for a button down</td>\n",
       "      <td>general petite . surprisingly comfy for a butt...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[24622, 4273, 578, 764, 12362, 401, 24928, 329...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Tops</td>\n",
       "      <td>0.914309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>short and small</td>\n",
       "      <td>general petite . short and small . the shirt i...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[50256, 50256, 50256, 50256, 50256, 50256, 502...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Tops</td>\n",
       "      <td>0.997992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title  \\\n",
       "0             perfect for work and play   \n",
       "1                                         \n",
       "2                           great pants   \n",
       "3  surprisingly comfy for a button down   \n",
       "4                       short and small   \n",
       "\n",
       "                                         Review Text   Division Name  \\\n",
       "0  general . perfect for work and play . this shi...         general   \n",
       "1  general petite . . i don't know why i had the ...  general petite   \n",
       "2  general petite . great pants . thes e cords ar...  general petite   \n",
       "3  general petite . surprisingly comfy for a butt...  general petite   \n",
       "4  general petite . short and small . the shirt i...  general petite   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [50256, 50256, 50256, 50256, 50256, 50256, 502...   \n",
       "1  [24622, 4273, 578, 764, 764, 1312, 836, 470, 7...   \n",
       "2  [50256, 50256, 50256, 50256, 50256, 50256, 502...   \n",
       "3  [24622, 4273, 578, 764, 12362, 401, 24928, 329...   \n",
       "4  [50256, 50256, 50256, 50256, 50256, 50256, 502...   \n",
       "\n",
       "                                      attention_mask pred_Department Name  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...                 Tops   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...              Bottoms   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...              Bottoms   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                 Tops   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...                 Tops   \n",
       "\n",
       "   pred_prob_Department Name  \n",
       "0                   0.999322  \n",
       "1                   0.988174  \n",
       "2                   0.995248  \n",
       "3                   0.914309  \n",
       "4                   0.997992  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_predicted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly check the f1 score to make sure everything works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.757361738460204"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(true_labels,df_test_predicted['pred_Department Name'],average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict top k results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    }
   ],
   "source": [
    "_test_dset = Dataset.from_pandas(df_test)\n",
    "_test_dset_predicted = controller.predict_raw_dset(_test_dset,\n",
    "                                                   do_filtering=True,\n",
    "                                                   topk=3\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>pred_Department Name</th>\n",
       "      <th>pred_prob_Department Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perfect for work and play</td>\n",
       "      <td>general . perfect for work and play . this shi...</td>\n",
       "      <td>general</td>\n",
       "      <td>[50256, 50256, 50256, 50256, 50256, 50256, 502...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Tops, Dresses, Jackets]</td>\n",
       "      <td>[0.9993216, 0.00019925594, 0.00019223447]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>general petite . . i don't know why i had the ...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[24622, 4273, 578, 764, 764, 1312, 836, 470, 7...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[Bottoms, Intimate, Jackets]</td>\n",
       "      <td>[0.98817396, 0.0063540265, 0.004216876]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great pants</td>\n",
       "      <td>general petite . great pants . thes e cords ar...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[50256, 50256, 50256, 50256, 50256, 50256, 502...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Bottoms, Intimate, Trend]</td>\n",
       "      <td>[0.995248, 0.004601938, 0.00012541868]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprisingly comfy for a button down</td>\n",
       "      <td>general petite . surprisingly comfy for a butt...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[24622, 4273, 578, 764, 12362, 401, 24928, 329...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[Tops, Dresses, Bottoms]</td>\n",
       "      <td>[0.914309, 0.06820013, 0.00940009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>short and small</td>\n",
       "      <td>general petite . short and small . the shirt i...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[50256, 50256, 50256, 50256, 50256, 50256, 502...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Tops, Intimate, Jackets]</td>\n",
       "      <td>[0.9979918, 0.00080933404, 0.0005731517]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title  \\\n",
       "0             perfect for work and play   \n",
       "1                                         \n",
       "2                           great pants   \n",
       "3  surprisingly comfy for a button down   \n",
       "4                       short and small   \n",
       "\n",
       "                                         Review Text   Division Name  \\\n",
       "0  general . perfect for work and play . this shi...         general   \n",
       "1  general petite . . i don't know why i had the ...  general petite   \n",
       "2  general petite . great pants . thes e cords ar...  general petite   \n",
       "3  general petite . surprisingly comfy for a butt...  general petite   \n",
       "4  general petite . short and small . the shirt i...  general petite   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [50256, 50256, 50256, 50256, 50256, 50256, 502...   \n",
       "1  [24622, 4273, 578, 764, 764, 1312, 836, 470, 7...   \n",
       "2  [50256, 50256, 50256, 50256, 50256, 50256, 502...   \n",
       "3  [24622, 4273, 578, 764, 12362, 401, 24928, 329...   \n",
       "4  [50256, 50256, 50256, 50256, 50256, 50256, 502...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "           pred_Department Name                  pred_prob_Department Name  \n",
       "0      [Tops, Dresses, Jackets]  [0.9993216, 0.00019925594, 0.00019223447]  \n",
       "1  [Bottoms, Intimate, Jackets]    [0.98817396, 0.0063540265, 0.004216876]  \n",
       "2    [Bottoms, Intimate, Trend]     [0.995248, 0.004601938, 0.00012541868]  \n",
       "3      [Tops, Dresses, Bottoms]         [0.914309, 0.06820013, 0.00940009]  \n",
       "4     [Tops, Intimate, Jackets]   [0.9979918, 0.00080933404, 0.0005731517]  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_predicted = _test_dset_predicted.to_pandas()\n",
    "\n",
    "df_test_predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have some metadatas (Title and Division Name), we need to define a dictionary containing those values\n",
    "raw_content={'Review Text': 'This shirt is so comfortable I love it!',\n",
    "             'Title': 'Great shirt',\n",
    "             'Division Name': 'general'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.data_store.num_proc=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    }
   ],
   "source": [
    "df_result = controller.predict_raw_text(raw_content,topk=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Review Text': ['general . great shirt . this shirt is so comfortable i love it !'],\n",
       " 'Title': ['great shirt'],\n",
       " 'Division Name': ['general'],\n",
       " 'input_ids': [[24622,\n",
       "   764,\n",
       "   1049,\n",
       "   10147,\n",
       "   764,\n",
       "   428,\n",
       "   10147,\n",
       "   318,\n",
       "   523,\n",
       "   6792,\n",
       "   1312,\n",
       "   1842,\n",
       "   340,\n",
       "   5145]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " 'pred_Department Name': [['Tops', 'Trend', 'Dresses']],\n",
       " 'pred_prob_Department Name': [[0.9987654685974121,\n",
       "   0.0003842698351945728,\n",
       "   0.0003074762353207916]]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
