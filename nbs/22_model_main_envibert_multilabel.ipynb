{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Controller Tutorial: EnviBert model (Multi Label)\n",
    "\n",
    "> This notebook contains some example of how to use the EnviBert-based models in this NLP library\n",
    "\n",
    "- skip_showdoc: true\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will walk through other cases of classification: multi-head and multi-label. Since we will showcase the capabiilty of this label in these cases, there won't be as detailed as [this tutorial](https://anhquan0412.github.io/that-nlp-library/model_main_envibert.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from that_nlp_library.text_transformation import *\n",
    "from that_nlp_library.text_augmentation import *\n",
    "from that_nlp_library.text_main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from underthesea import text_normalize\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from importlib.machinery import SourceFileLoader\n",
    "import os\n",
    "from transformers import DataCollatorWithPadding\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some necessary text augmentations and text transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For Text Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_tfms=[text_normalize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For Text Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_nonown_tfm = partial(sampling_with_condition,query='Source==\"non owned\"',frac=0.5,seed=42,apply_to_all=False)\n",
    "over_nonown_tfm.__name__ = 'Oversampling Non Owned'\n",
    "\n",
    "over_own_tfm = partial(sampling_with_condition,query='Source==\"owned\"',frac=2,seed=42,apply_to_all=False)\n",
    "over_own_tfm.__name__ = 'Oversampling Owned'\n",
    "\n",
    "over_hc_tfm = partial(sampling_with_condition,query='Source==\"hc search\"',frac=2.5,seed=42,apply_to_all=False)\n",
    "over_hc_tfm.__name__ = 'Oversampling HC search'\n",
    "\n",
    "remove_accent_tfm = partial(remove_vnmese_accent,frac=1,seed=42,apply_to_all=True)\n",
    "remove_accent_tfm.__name__ = 'Add No-Accent Text'\n",
    "\n",
    "aug_tfms = [over_nonown_tfm,over_own_tfm,over_hc_tfm,remove_accent_tfm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a TextDataMain object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Input Validation Precheck -----\n",
      "DataFrame contains missing values!\n",
      "-----> List of columns and the number of missing values for each\n",
      "is_valid    65804\n",
      "dtype: int64\n",
      "DataFrame contains duplicated values!\n",
      "-----> Number of duplications: 7 rows\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path('secret_data')\n",
    "\n",
    "df = TextDataMain.from_csv(DATA_PATH/'buyer_listening_with_all_raw_data_w2223.csv',return_df=True)\n",
    "\n",
    "#Quick preprocess of data and train/validation split. \n",
    "#Due to custom logic, we will sample our data here instead of using the `train_ratio` from the `to_datasetdict` function\n",
    "\n",
    "df_rare = df[df.L2.isin(['Chatbot', 'Commercial Others'])].copy()\n",
    "\n",
    "df_final = pd.concat([df.query('iteration==1').sample(500,random_state=42),\n",
    "                      df.query('iteration>=7 & iteration<13').sample(1200,random_state=42),\n",
    "                      df_rare,\n",
    "                      df.query('iteration>=13'),\n",
    "                     ],axis=0).reset_index(drop=True)\n",
    "\n",
    "val_idxs = df_final[df_final.iteration>=13].index.values # from week 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the problem is not multi-label, we will make it into one by concatenate L1 label and L2 label together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['L1L2'] = df_final[['L1','L2']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Group</th>\n",
       "      <th>Source</th>\n",
       "      <th>Content</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>L4</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>iteration</th>\n",
       "      <th>L1L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.0</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>Kog z√¥ dx x√≥a t·∫£i l·∫°i c·ªßg kog z√¥ dx lu√¥n v√£i c...</td>\n",
       "      <td>Feature</td>\n",
       "      <td>App performance</td>\n",
       "      <td>Lag when browsing in general</td>\n",
       "      <td>Tech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[Feature, App performance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>T√¥i m√™t moi voi c√°i ung dung nay qu√° lam sao x...</td>\n",
       "      <td>Others</td>\n",
       "      <td>Cannot defined</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[Others, Cannot defined]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>Lag vc fix ƒëi shoper</td>\n",
       "      <td>Feature</td>\n",
       "      <td>App performance</td>\n",
       "      <td>Lag when browsing in general</td>\n",
       "      <td>Tech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[Feature, App performance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>G·ª°</td>\n",
       "      <td>Others</td>\n",
       "      <td>Cannot defined</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[Others, Cannot defined]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.0</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>Ko m·ªü ƒëc ch√°n n·∫£n, b√°o update, update ko dc, v...</td>\n",
       "      <td>Feature</td>\n",
       "      <td>App performance</td>\n",
       "      <td>App installment problem</td>\n",
       "      <td>Tech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[Feature, App performance]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Week        Group       Source   \n",
       "0  46.0  Google Play  Google Play  \\\n",
       "1  32.0  Google Play  Google Play   \n",
       "2  10.0  Google Play  Google Play   \n",
       "3  20.0  Google Play  Google Play   \n",
       "4  31.0  Google Play  Google Play   \n",
       "\n",
       "                                             Content       L1   \n",
       "0  Kog z√¥ dx x√≥a t·∫£i l·∫°i c·ªßg kog z√¥ dx lu√¥n v√£i c...  Feature  \\\n",
       "1  T√¥i m√™t moi voi c√°i ung dung nay qu√° lam sao x...   Others   \n",
       "2                               Lag vc fix ƒëi shoper  Feature   \n",
       "3                                                 G·ª°   Others   \n",
       "4  Ko m·ªü ƒëc ch√°n n·∫£n, b√°o update, update ko dc, v...  Feature   \n",
       "\n",
       "                L2                            L3    L4  is_valid  iteration   \n",
       "0  App performance  Lag when browsing in general  Tech       NaN          1  \\\n",
       "1   Cannot defined                             -     -       NaN          1   \n",
       "2  App performance  Lag when browsing in general  Tech       NaN          1   \n",
       "3   Cannot defined                             -     -       NaN          1   \n",
       "4  App performance       App installment problem  Tech       NaN          1   \n",
       "\n",
       "                         L1L2  \n",
       "0  [Feature, App performance]  \n",
       "1    [Others, Cannot defined]  \n",
       "2  [Feature, App performance]  \n",
       "3    [Others, Cannot defined]  \n",
       "4  [Feature, App performance]  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Input Validation Precheck -----\n",
      "DataFrame contains missing values!\n",
      "-----> List of columns and the number of missing values for each\n",
      "is_valid    498\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tdm = TextDataMain(df_final,\n",
    "                    main_content='Content',\n",
    "                    metadatas='Source',\n",
    "                    label_names='L1L2',\n",
    "                    val_ratio=val_idxs,\n",
    "                    split_cols='L2',\n",
    "                    content_tfms = txt_tfms,\n",
    "                    aug_tfms = aug_tfms,\n",
    "                    process_metadatas=True,\n",
    "                    seed=42,\n",
    "                    shuffle_trn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our tokenizer for EnviBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir=Path('./envibert_tokenizer')\n",
    "tokenizer = SourceFileLoader(\"envibert.tokenizer\", \n",
    "                             str(cache_dir/'envibert_tokenizer.py')).load_module().RobertaTokenizer(cache_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our DatasetDict from TextDataMain (as our `ModelController` class can also work with DatasetDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start Main Text Processing --------------------\n",
      "----- Metadata Simple Processing & Concatenating to Main Content -----\n",
      "----- Label Encoding -----\n",
      "-------------------- Text Transformation --------------------\n",
      "----- text_normalize -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6649/6649 [00:01<00:00, 3621.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train Test Split --------------------\n",
      "Previous Validation Percentage: 74.101%\n",
      "- Before leak check\n",
      "Size: 4927\n",
      "- After leak check\n",
      "Size: 4885\n",
      "- Number of rows leaked: 42, or 0.85% of the original validation (or test) data\n",
      "Current Validation Percentage: 73.47%\n",
      "-------------------- Text Augmentation --------------------\n",
      "Train data size before augmentation: 1764\n",
      "----- Oversampling Non Owned -----\n",
      "Train data size after THIS augmentation: 2229\n",
      "----- Oversampling Owned -----\n",
      "Train data size after THIS augmentation: 2789\n",
      "----- Oversampling HC search -----\n",
      "Train data size after THIS augmentation: 2904\n",
      "----- Add No-Accent Text -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2904/2904 [00:00<00:00, 9960.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size after THIS augmentation: 5808\n",
      "Train data size after ALL augmentation: 5808\n",
      "-------------------- Map Tokenize Function --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5808 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4885 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main_ddict= tdm.to_datasetdict(tokenizer,\n",
    "                               max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'Source', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 5808\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'Source', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 4885\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_ddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(main_ddict['validation']['label'][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experiment: EnviBert Multi-Head Classification (with Hidden Layer Concatenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from that_nlp_library.models.roberta.classifiers import *\n",
    "from that_nlp_library.model_main import *\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import os\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train EnviBert (with hidden layer concatenation), using TDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nguyenvulebinh/envibert were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name='nguyenvulebinh/envibert'\n",
    "envibert_body = RobertaModel.from_pretrained(model_name)\n",
    "num_classes = len(tdm.label_lists[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our model controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading body weights. This assumes the body is the very first first-layer block of your custom architecture\n"
     ]
    }
   ],
   "source": [
    "_model_kwargs={\n",
    "    # overall model hyperparams\n",
    "    'layer2concat':4,\n",
    "    'is_multilabel':tdm.is_multilabel, # False\n",
    "    'is_multihead':tdm.is_multihead, # False\n",
    "    'head_class_sizes':num_classes,\n",
    "    'head_class': ConcatHeadSimple,\n",
    "    # classfication head hyperparams\n",
    "    'classifier_dropout':0.1 \n",
    "}\n",
    "\n",
    "model = model_init_classification(model_class = RobertaHiddenStateConcatForSequenceClassification,\n",
    "                                  cpoint_path = model_name, \n",
    "                                  output_hidden_states=True, # since we are not using 'hidden layer contatenation' technique\n",
    "                                  seed=42,\n",
    "                                  body_model=envibert_body,\n",
    "                                  model_kwargs = _model_kwargs)\n",
    "\n",
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score] # we will use both f1_macro and accuracy score as metrics\n",
    "controller = ModelController(model,tdm,metric_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can start training our model. Pay attention to the compute_metrics function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2904' max='2904' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2904/2904 03:23, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score L1l2</th>\n",
       "      <th>Accuracy Score L1l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.085917</td>\n",
       "      <td>0.021178</td>\n",
       "      <td>0.111771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.098200</td>\n",
       "      <td>0.078571</td>\n",
       "      <td>0.053714</td>\n",
       "      <td>0.210850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.098200</td>\n",
       "      <td>0.074122</td>\n",
       "      <td>0.078145</td>\n",
       "      <td>0.231116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.073689</td>\n",
       "      <td>0.079069</td>\n",
       "      <td>0.237666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "lr = 6e-5\n",
    "bs=4\n",
    "wd=0.01\n",
    "epochs= 4\n",
    "\n",
    "controller.fit(epochs,lr,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=partial(compute_metrics_classification,\n",
    "                                       is_multilabel=tdm.is_multilabel,\n",
    "                                       multilabel_threshold=0.5)\n",
    "              )\n",
    "# Epoch\tTraining Loss\tValidation Loss\tF1 Score L1l2\tAccuracy Score L1l2\n",
    "# 1\tNo log\t0.082577\t0.028576\t0.111771\n",
    "# 2\t0.090200\t0.076037\t0.057607\t0.223337\n",
    "# 3\t0.090200\t0.072825\t0.088066\t0.245241\n",
    "# 4\t0.023500\t0.073391\t0.095394\t0.253019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.trainer.model.save_pretrained('./sample_weights/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using trained model, using TDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer2concat': 4,\n",
       " 'is_multilabel': True,\n",
       " 'is_multihead': False,\n",
       " 'head_class_sizes': 76,\n",
       " 'head_class': that_nlp_library.models.roberta.classifiers.ConcatHeadSimple,\n",
       " 'classifier_dropout': 0.1}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_model_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sample_weights/my_model were not used when initializing RobertaHiddenStateConcatForSequenceClassification: ['body_model.pooler.dense.weight', 'body_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaHiddenStateConcatForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaHiddenStateConcatForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "trained_model = model_init_classification(model_class = RobertaHiddenStateConcatForSequenceClassification,\n",
    "                                          cpoint_path = Path('./sample_weights/my_model'), \n",
    "                                          output_hidden_states=True,\n",
    "                                          seed=42,\n",
    "                                          model_kwargs = _model_kwargs)\n",
    "\n",
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score]\n",
    "controller = ModelController(trained_model,tdm,metric_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Train/Validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction on all validation set. Note that you can set the probability threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4885 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_val = controller.predict_ddict(ds_type='validation',multilabel_threshold=0.5,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1L2</th>\n",
       "      <th>pred_prob_L1L2</th>\n",
       "      <th>pred_L1L2_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - lam phien</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>google play</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[0.00043046146, 0.00057243364, 0.0015474476, 0...</td>\n",
       "      <td>Cannot defined,Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google play - .. t . √Ä m√† h·ªç n·ªØ ∆∞u m</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>google play</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[0.00048226005, 0.0006290678, 0.001644549, 0.0...</td>\n",
       "      <td>Cannot defined,Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google play - Cc l√πa dao</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>google play</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[0.0004853605, 0.00060451776, 0.0016006823, 0....</td>\n",
       "      <td>Cannot defined,Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google play - M·∫∑t h√†ng sp m√¨nh ƒë·ªÅu nh·ª° v·ªõi Gia...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>google play</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[0.004979573, 0.007575649, 0.0147191025, 0.001...</td>\n",
       "      <td>Delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - Ch∆∞a t·ªëi ∆∞u t·ªët cho Android Oppo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>google play</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[0.00052510685, 0.0007405444, 0.0019072617, 0....</td>\n",
       "      <td>Cannot defined,Others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   \n",
       "0                            google play - lam phien  \\\n",
       "1               google play - .. t . √Ä m√† h·ªç n·ªØ ∆∞u m   \n",
       "2                           google play - Cc l√πa dao   \n",
       "3  google play - M·∫∑t h√†ng sp m√¨nh ƒë·ªÅu nh·ª° v·ªõi Gia...   \n",
       "4  google play - Ch∆∞a t·ªëi ∆∞u t·ªët cho Android Oppo...   \n",
       "\n",
       "                                               label       Source   \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  google play  \\\n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  google play   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  google play   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  google play   \n",
       "4  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  google play   \n",
       "\n",
       "                                           pred_L1L2   \n",
       "0  [False, False, False, False, False, False, Fal...  \\\n",
       "1  [False, False, False, False, False, False, Fal...   \n",
       "2  [False, False, False, False, False, False, Fal...   \n",
       "3  [False, False, False, False, False, False, Fal...   \n",
       "4  [False, False, False, False, False, False, Fal...   \n",
       "\n",
       "                                      pred_prob_L1L2       pred_L1L2_string  \n",
       "0  [0.00043046146, 0.00057243364, 0.0015474476, 0...  Cannot defined,Others  \n",
       "1  [0.00048226005, 0.0006290678, 0.001644549, 0.0...  Cannot defined,Others  \n",
       "2  [0.0004853605, 0.00060451776, 0.0016006823, 0....  Cannot defined,Others  \n",
       "3  [0.004979573, 0.007575649, 0.0147191025, 0.001...               Delivery  \n",
       "4  [0.00052510685, 0.0007405444, 0.0019072617, 0....  Cannot defined,Others  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the label index to string, we can use the ```label_lists``` attribute of tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_str_multilabel(row):\n",
    "    indices=np.where(row==1)[0]\n",
    "    return ','.join([tdm.label_lists[0][i] for i in indices])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['label_str']=df_val['label'].apply(get_label_str_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_str</th>\n",
       "      <th>pred_L1L2_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cannot defined,Others</td>\n",
       "      <td>Cannot defined,Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cannot defined,Others</td>\n",
       "      <td>Cannot defined,Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cannot defined,Others</td>\n",
       "      <td>Cannot defined,Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delivery,Delivery time</td>\n",
       "      <td>Delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>App performance,Feature</td>\n",
       "      <td>Cannot defined,Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880</th>\n",
       "      <td>Commercial,Flash Sale/Campaigns</td>\n",
       "      <td>Cannot defined,Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4881</th>\n",
       "      <td>Delivery,Driver</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4882</th>\n",
       "      <td>Other payment methods,Payment</td>\n",
       "      <td>Cannot defined,Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4883</th>\n",
       "      <td>Commercial,Flash Sale/Campaigns</td>\n",
       "      <td>Cannot defined,Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4884</th>\n",
       "      <td>Feature,Shopee coins</td>\n",
       "      <td>Delivery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4885 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            label_str       pred_L1L2_string\n",
       "0               Cannot defined,Others  Cannot defined,Others\n",
       "1               Cannot defined,Others  Cannot defined,Others\n",
       "2               Cannot defined,Others  Cannot defined,Others\n",
       "3              Delivery,Delivery time               Delivery\n",
       "4             App performance,Feature  Cannot defined,Others\n",
       "...                               ...                    ...\n",
       "4880  Commercial,Flash Sale/Campaigns  Cannot defined,Others\n",
       "4881                  Delivery,Driver                       \n",
       "4882    Other payment methods,Payment  Cannot defined,Others\n",
       "4883  Commercial,Flash Sale/Campaigns  Cannot defined,Others\n",
       "4884             Feature,Shopee coins               Delivery\n",
       "\n",
       "[4885 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val[['label_str','pred_L1L2_string']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go through details on how to make a prediction on a completely new and raw dataset using our trained model. For now, let's reuse the sample csv and pretend it's our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Input Validation Precheck -----\n",
      "DataFrame contains duplicated values!\n",
      "-----> Number of duplications: 16 rows\n"
     ]
    }
   ],
   "source": [
    "df_test = TextDataMain.from_csv(Path('sample_data')/'sample_large.csv',return_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove all the labels and unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['L1','L2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google Play</td>\n",
       "      <td>App ncc l√∫c n√†o cx lag ƒë∆°, ph·∫ßn t√¨m ki·∫øm th√¨ v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non Owned</td>\n",
       "      <td>..‚ùóÔ∏è G√ìC THANH L√ù T√≠nh ra r·∫ª h∆°n c·∫£ mua #Shope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google Play</td>\n",
       "      <td>M·∫Øc g√¨ ng∆∞·ªùi ta ƒë·∫∑t h√†ng to√†n l·ªói üòÉ????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owned</td>\n",
       "      <td>#GhienShopeePayawardT8 Khi b·∫°n ch∆°i shopee qu√°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google Play</td>\n",
       "      <td>R·∫•t b·ª©c x√∫c khi d√πng . m√£ gi·∫£m gi√° ng∆∞·ªùi d√πng ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source                                            Content\n",
       "0  Google Play  App ncc l√∫c n√†o cx lag ƒë∆°, ph·∫ßn t√¨m ki·∫øm th√¨ v...\n",
       "1    Non Owned  ..‚ùóÔ∏è G√ìC THANH L√ù T√≠nh ra r·∫ª h∆°n c·∫£ mua #Shope...\n",
       "2  Google Play            M·∫Øc g√¨ ng∆∞·ªùi ta ƒë·∫∑t h√†ng to√†n l·ªói üòÉ????\n",
       "3        Owned  #GhienShopeePayawardT8 Khi b·∫°n ch∆°i shopee qu√°...\n",
       "4  Google Play  R·∫•t b·ª©c x√∫c khi d√πng . m√£ gi·∫£m gi√° ng∆∞·ªùi d√πng ..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a DatasetDict for this test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Getting Test Set --------------------\n",
      "----- Input Validation Precheck -----\n",
      "DataFrame contains duplicated values!\n",
      "-----> Number of duplications: 19 rows\n",
      "-------------------- Start Test Set Transformation --------------------\n",
      "----- Metadata Simple Processing & Concatenating to Main Content -----\n",
      "-------------------- Text Transformation --------------------\n",
      "----- text_normalize -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2269/2269 [00:00<00:00, 3972.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Test Leak Checking --------------------\n",
      "- Before leak check\n",
      "Size: 2269\n",
      "- After leak check\n",
      "Size: 2080\n",
      "- Number of rows leaked: 189, or 8.33% of the original validation (or test) data\n",
      "-------------------- Construct DatasetDict --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ddict = tdm.get_test_datasetdict_from_df(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text', 'Source', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ddict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test data has been processed + transformed (but not augmented) the same way as the validation set. Now we can start making the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# controller = ModelController(model,tdm)\n",
    "df_result = controller.predict_ddict(ddict=test_ddict,ds_type='test',multilabel_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1L2</th>\n",
       "      <th>pred_prob_L1L2</th>\n",
       "      <th>pred_L1L2_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - App ncc l√∫c n√†o cx lag ƒë∆° , ph·∫ßn...</td>\n",
       "      <td>google play</td>\n",
       "      <td>[False, False, False, False, False, True, Fals...</td>\n",
       "      <td>[0.0025301736, 0.0055451845, 0.044778068, 0.00...</td>\n",
       "      <td>App performance,Feature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non owned - .. ‚ùó Ô∏è G√ìC THANH L√ù T√≠nh ra r·∫ª h∆°n...</td>\n",
       "      <td>non owned</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[0.00043563428, 0.00053482514, 0.0008672758, 0...</td>\n",
       "      <td>Cannot defined,Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google play - M·∫Øc g√¨ ng∆∞·ªùi ta ƒë·∫∑t h√†ng to√†n l·ªó...</td>\n",
       "      <td>google play</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[0.0018123146, 0.0027692849, 0.0063686953, 0.0...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owned - # GhienShopeePayawardT8 Khi b·∫°n ch∆°i s...</td>\n",
       "      <td>owned</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[0.0011939979, 0.0015298241, 0.0022472697, 0.0...</td>\n",
       "      <td>Commercial,Shopee Programs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - R·∫•t b·ª©c x√∫c khi d√πng . m√£ gi·∫£m g...</td>\n",
       "      <td>google play</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[0.002711329, 0.006989172, 0.05613184, 0.00163...</td>\n",
       "      <td>Feature</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       Source   \n",
       "0  google play - App ncc l√∫c n√†o cx lag ƒë∆° , ph·∫ßn...  google play  \\\n",
       "1  non owned - .. ‚ùó Ô∏è G√ìC THANH L√ù T√≠nh ra r·∫ª h∆°n...    non owned   \n",
       "2  google play - M·∫Øc g√¨ ng∆∞·ªùi ta ƒë·∫∑t h√†ng to√†n l·ªó...  google play   \n",
       "3  owned - # GhienShopeePayawardT8 Khi b·∫°n ch∆°i s...        owned   \n",
       "4  google play - R·∫•t b·ª©c x√∫c khi d√πng . m√£ gi·∫£m g...  google play   \n",
       "\n",
       "                                           pred_L1L2   \n",
       "0  [False, False, False, False, False, True, Fals...  \\\n",
       "1  [False, False, False, False, False, False, Fal...   \n",
       "2  [False, False, False, False, False, False, Fal...   \n",
       "3  [False, False, False, False, False, False, Fal...   \n",
       "4  [False, False, False, False, False, False, Fal...   \n",
       "\n",
       "                                      pred_prob_L1L2   \n",
       "0  [0.0025301736, 0.0055451845, 0.044778068, 0.00...  \\\n",
       "1  [0.00043563428, 0.00053482514, 0.0008672758, 0...   \n",
       "2  [0.0018123146, 0.0027692849, 0.0063686953, 0.0...   \n",
       "3  [0.0011939979, 0.0015298241, 0.0022472697, 0.0...   \n",
       "4  [0.002711329, 0.006989172, 0.05613184, 0.00163...   \n",
       "\n",
       "             pred_L1L2_string  \n",
       "0     App performance,Feature  \n",
       "1       Cannot defined,Others  \n",
       "2                              \n",
       "3  Commercial,Shopee Programs  \n",
       "4                     Feature  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want to make a prediction on a small amount of data (single sentence, or a few sentences), we can use `ModelController.predict_raw_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have some metadatas, we need to define a dictionary (to imitate a DatasetDict)\n",
    "raw_content={\n",
    "    'Source': 'Google play',\n",
    "    'Content':'T√¥i kh√¥ng th√≠ch Shopee.T·∫°i v√¨ d√πng app r·∫•t ch·∫≠m,lag banh nh√† l·∫ßu, th·∫≠m ch√≠ log in c√≤n kh√¥ng ƒëc'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't use metadata, we can use something like this: \n",
    "\n",
    "```raw_content='T√¥i kh√¥ng th√≠ch Shopee.T·∫°i v√¨ d√πng app r·∫•t ch·∫≠m,lag banh nh√† l·∫ßu, th·∫≠m ch√≠ log in c√≤n kh√¥ng ƒëc'```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 4951.95it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1L2</th>\n",
       "      <th>pred_prob_L1L2</th>\n",
       "      <th>pred_L1L2_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - T√¥i kh√¥ng th√≠ch Shopee . T·∫°i v√¨ ...</td>\n",
       "      <td>google play</td>\n",
       "      <td>[False, False, False, False, False, True, Fals...</td>\n",
       "      <td>[0.0017681926, 0.003631191, 0.018489178, 0.001...</td>\n",
       "      <td>App performance,Feature</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       Source   \n",
       "0  google play - T√¥i kh√¥ng th√≠ch Shopee . T·∫°i v√¨ ...  google play  \\\n",
       "\n",
       "                                           pred_L1L2   \n",
       "0  [False, False, False, False, False, True, Fals...  \\\n",
       "\n",
       "                                      pred_prob_L1L2         pred_L1L2_string  \n",
       "0  [0.0017681926, 0.003631191, 0.018489178, 0.001...  App performance,Feature  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = controller.predict_raw_text(raw_content,multilabel_threshold=0.5)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
