{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Controller Tutorial: Classification\n",
    "\n",
    "> This notebook contains an end-to-end process of preprocess + tokenizing your text, and build a classification model based on Roberta architecture\n",
    "\n",
    "- skip_showdoc: true\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from that_nlp_library.text_transformation import *\n",
    "from that_nlp_library.text_augmentation import *\n",
    "from that_nlp_library.text_main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from underthesea import text_normalize\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from importlib.machinery import SourceFileLoader\n",
    "import os\n",
    "from transformers import DataCollatorWithPadding,RobertaTokenizer\n",
    "import torch\n",
    "import nlpaug.augmenter.char as nac\n",
    "from datasets import load_dataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a TextDataController object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reuse the data and the preprocessings in [this tutorial](https://anhquan0412.github.io/that-nlp-library/text_main.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_aug_stochastic(x,aug=None,p=0.5):\n",
    "    results = aug.augment(x)\n",
    "    if not isinstance(x,list): return results[0] if random.random()<p else x\n",
    "    return [a if random.random()<p else b for a,b in zip(results,x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = nac.KeyboardAug(aug_char_max=3,aug_char_p=0.1,aug_word_p=0.07)\n",
    "nearby_aug_func = partial(nlp_aug_stochastic,aug=aug,p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-f893627565d98cd2/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv'],split='train')\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         # add \"str.lower\" here because nearby_aug might return uppercase character\n",
    "                         val_ratio=0.2,\n",
    "                         batch_size=1000,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=False,\n",
    "                         num_proc=16,\n",
    "                         verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our tokenizer for Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process and tokenize our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-f893627565d98cd2/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-e9c222e72d2d212d_*_of_00016.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-f893627565d98cd2/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-d1cd989e4813d263_*_of_00016.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-f893627565d98cd2/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-8db764ea689c4a2f_*_of_00016.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-f893627565d98cd2/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-5cfa4d6b4bbf77b8_*_of_00016.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-f893627565d98cd2/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-b8d4a635991df3a8_*_of_00016.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-f893627565d98cd2/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-5272bb88432c27c4_*_of_00016.arrow\n",
      "Loading cached split indices for dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-f893627565d98cd2/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-7185abc8f3df149c.arrow and /home/quan/.cache/huggingface/datasets/csv/sample_data-f893627565d98cd2/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-f8cd8f8673b4cc20.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start Main Text Processing --------------------\n",
      "-------------------- Data Filtering --------------------\n",
      "----- Do <lambda> on Review Text -----\n",
      "----- Do <lambda> on Department Name -----\n",
      "Done\n",
      "----- Metadata Simple Processing & Concatenating to Main Content -----\n",
      "Done\n",
      "----- Label Encoding -----\n",
      "Done\n",
      "-------------------- Text Transformation --------------------\n",
      "----- text_normalize -----\n",
      "----- lower -----\n",
      "Done\n",
      "-------------------- Train Test Split --------------------\n",
      "Validation split based on val_ratio\n",
      "Done\n",
      "-------------------- Dropping unused features --------------------\n",
      "Done\n",
      "- Number of rows leaked: 0, which is 0.00% of training set\n",
      "-------------------- Text Augmentation --------------------\n",
      "----- nlp_aug_stochastic -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/18102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- lower -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/18102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "-------------------- Shuffling train set --------------------\n",
      "Done\n",
      "-------------------- Tokenization --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4526 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "tdc.process_and_tokenize(tokenizer,max_length=512,shuffle_trn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Title', 'Review Text', 'Division Name', 'Department Name', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 18102\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Title', 'Review Text', 'Division Name', 'Department Name', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4526\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdc.main_ddict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see one example of how those content transformations and augmentations affect our input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_txt = 'This is not what I expected 🤬. I gulped when I put this in my bag during retailer days because the price was still too much ... but thought this has to be wonderful to charge so much,right??'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t------- Text Transformation Explained -------\n",
      "----- Raw sentence -----\n",
      "This is not what I expected 🤬. I gulped when I put this in my bag during retailer days because the price was still too much ... but thought this has to be wonderful to charge so much,right??\n",
      "\n",
      "----- Content Transformations (on both train and test) -----\n",
      "--- text_normalize ---\n",
      "This is not what I expected 🤬 . I gulped when I put this in my bag during retailer days because the price was still too much ... but thought this has to be wonderful to charge so much , right ? ?\n",
      "\n",
      "--- lower ---\n",
      "this is not what i expected 🤬 . i gulped when i put this in my bag during retailer days because the price was still too much ... but thought this has to be wonderful to charge so much , right ? ?\n",
      "\n",
      "\n",
      "----- Augmentations (on train only) -----\n",
      "--- nlp_aug_stochastic ---\n",
      "tNis is not what i expected 🤬. i gulpeR when i put this in my bag during rrtailer Cays because the price was still too much. .. but thought this has to be wonderful to charge so much, right??\n",
      "\n",
      "--- lower ---\n",
      "tnis is not what i expected 🤬. i gulper when i put this in my bag during rrtailer cays because the price was still too much. .. but thought this has to be wonderful to charge so much, right??\n",
      "\n",
      "\n",
      "\t\t------- Tokenizer Explained -------\n",
      "----- Input -----\n",
      "tnis is not what i expected 🤬. i gulper when i put this in my bag during rrtailer cays because the price was still too much. .. but thought this has to be wonderful to charge so much, right??\n",
      "\n",
      "----- Tokenized results ----- \n",
      "{'input_ids': [0, 90, 10892, 16, 45, 99, 939, 421, 8103, 10470, 11582, 4, 939, 42445, 1741, 77, 939, 342, 42, 11, 127, 3298, 148, 910, 338, 17624, 254, 740, 4113, 142, 5, 425, 21, 202, 350, 203, 4, 29942, 53, 802, 42, 34, 7, 28, 4613, 7, 1427, 98, 203, 6, 235, 28749, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "\n",
      "----- Results from tokenizer.convert_ids_to_tokens -----\n",
      "['<s>', 't', 'nis', 'Ġis', 'Ġnot', 'Ġwhat', 'Ġi', 'Ġexpected', 'ĠðŁ', '¤', '¬', '.', 'Ġi', 'Ġgul', 'per', 'Ġwhen', 'Ġi', 'Ġput', 'Ġthis', 'Ġin', 'Ġmy', 'Ġbag', 'Ġduring', 'Ġr', 'r', 'tail', 'er', 'Ġc', 'ays', 'Ġbecause', 'Ġthe', 'Ġprice', 'Ġwas', 'Ġstill', 'Ġtoo', 'Ġmuch', '.', 'Ġ..', 'Ġbut', 'Ġthought', 'Ġthis', 'Ġhas', 'Ġto', 'Ġbe', 'Ġwonderful', 'Ġto', 'Ġcharge', 'Ġso', 'Ġmuch', ',', 'Ġright', '??', '</s>']\n",
      "\n",
      "----- Results from tokenizer.decode ----- \n",
      "<s>tnis is not what i expected 🤬. i gulper when i put this in my bag during rrtailer cays because the price was still too much... but thought this has to be wonderful to charge so much, right??</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "two_steps_tokenization_explain(sample_txt,tokenizer,\n",
    "                               content_tfms=[text_normalize,str.lower],\n",
    "                               aug_tfms=[partial(nlp_aug_stochastic,aug=aug,p=1),str.lower]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experiment: EnviBert Single-Head Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "from that_nlp_library.models.roberta.classifiers import *\n",
    "from that_nlp_library.model_main import *\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will specify a (or a list) of GPUs for training\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train EnviBert using TDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Buyer complained seller',\n",
       "  'Commercial',\n",
       "  'Delivery',\n",
       "  'Feature',\n",
       "  'Order/Item',\n",
       "  'Others',\n",
       "  'Payment',\n",
       "  'Return/Refund',\n",
       "  'Services',\n",
       "  'Shopee account']]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm.label_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(tdm.label_lists[0]) # 10\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our model and model controller. First, we will initialize the pretrained `body` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.roberta.modeling_roberta import RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='nguyenvulebinh/envibert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nguyenvulebinh/envibert were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "envibert_body = RobertaModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can define a simple class as the head for our classification task, something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassificationHead(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 config, # HuggingFace model configuration\n",
    "                 classifier_dropout=0.1, # Dropout ratio (for dropout layer right before the last nn.Linear)\n",
    "                 num_labels=None, # Number of label output. Every classification class must have this exact variable\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(classifier_dropout)\n",
    "        self.out_proj = torch.nn.Linear(config.hidden_size, num_labels)\n",
    "    def forward(self, inp, **kwargs):\n",
    "        x = inp\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading body weights. This assumes the body is the very first first-layer block of your custom architecture\n"
     ]
    }
   ],
   "source": [
    "_model_kwargs={\n",
    "    # overall model hyperparams\n",
    "    'is_multilabel':tdm.is_multilabel, # False\n",
    "    'is_multihead':tdm.is_multihead, # False\n",
    "    'head_class_sizes':num_classes,\n",
    "    'head_class': SimpleClassificationHead,\n",
    "    # classfication head hyperparams\n",
    "    'classifier_dropout':0.1 \n",
    "}\n",
    "\n",
    "model = model_init_classification(model_class = RobertaBaseForSequenceClassification,\n",
    "                                  cpoint_path = 'nguyenvulebinh/envibert', \n",
    "                                  output_hidden_states=False, # since we are not using 'hidden layer contatenation' technique\n",
    "                                  seed=42,\n",
    "                                  body_model=envibert_body,\n",
    "                                  model_kwargs = _model_kwargs)\n",
    "\n",
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score] # we will use both f1_macro and accuracy score as metrics\n",
    "controller = ModelController(model,tdm,metric_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can start training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1194' max='1194' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1194/1194 01:04, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score L1</th>\n",
       "      <th>Accuracy Score L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.059704</td>\n",
       "      <td>0.350748</td>\n",
       "      <td>0.677852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.007712</td>\n",
       "      <td>0.462641</td>\n",
       "      <td>0.697987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 8e-5\n",
    "bs=4\n",
    "wd=0.01\n",
    "epochs= 2\n",
    "\n",
    "controller.fit(epochs,lr,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=compute_metrics_classification,\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging your training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can log your training using HuggingFace:\n",
    "\n",
    "- Supported platforms are \"azure_ml\", \"comet_ml\", \"mlflow\", \"neptune\", \"tensorboard\",\"clearml\" and \"wandb\"\n",
    "\n",
    "- References:\n",
    "\n",
    "    - https://huggingface.co/docs/transformers/v4.28.0/en/main_classes/trainer#transformers.TrainingArguments\n",
    "    \n",
    "    - https://docs.wandb.ai/guides/integrations/huggingface#:~:text=Logging%20your%20Hugging%20Face%20model,every%20save_steps%20in%20the%20TrainingArguments%20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "controller.fit(epochs,lr,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=compute_metrics_classification,\n",
    "               hf_report_to='wandb'\n",
    "              )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save your model weights at the end of your training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "controller.trainer.model.save_pretrained('./sample_weights/model_progress')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can save your weights at every epochs during your training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "controller.fit(epochs,lr,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=True,\n",
    "               o_dir='sample_weights',\n",
    "               compute_metrics=compute_metrics_classification,\n",
    "              )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train EnviBert with tokenized DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part assumes you already have your tokenized datasetdict. You must have your tokenizer as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaTokenizer(name_or_path='', vocab_size=59993, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that your DatasetDict must contain tokens besides raw text (which typically includes 'input_ids', 'token_type_ids', 'attention_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'Source', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 4780\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'Source', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 447\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_ddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='nguyenvulebinh/envibert'\n",
    "_model_kwargs={\n",
    "    # overall model hyperparams\n",
    "    'is_multilabel':False, # False\n",
    "    'is_multihead':False, # False\n",
    "    'head_class_sizes':num_classes,\n",
    "    'head_class': SimpleClassificationHead,\n",
    "    # classfication head hyperparams\n",
    "    'classifier_dropout':0.1 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envibert_body = RobertaModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nguyenvulebinh/envibert were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading body weights. This assumes the body is the very first first-layer block of your custom architecture\n"
     ]
    }
   ],
   "source": [
    "model = model_init_classification(model_class = RobertaBaseForSequenceClassification,\n",
    "                                  cpoint_path = 'nguyenvulebinh/envibert', \n",
    "                                  output_hidden_states=False, # since we are not using 'hidden layer contatenation' technique\n",
    "                                  seed=42,\n",
    "                                  body_model=envibert_body,\n",
    "                                  model_kwargs = _model_kwargs)\n",
    "\n",
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score] # we will use both f1_macro and accuracy score as metrics\n",
    "controller = ModelController(model,\n",
    "                             metric_funcs=metric_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1194' max='1194' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1194/1194 01:06, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score L1</th>\n",
       "      <th>Accuracy Score L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.059704</td>\n",
       "      <td>0.350748</td>\n",
       "      <td>0.677852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.007712</td>\n",
       "      <td>0.462641</td>\n",
       "      <td>0.697987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 8e-5\n",
    "bs=4\n",
    "wd=0.01\n",
    "epochs= 2\n",
    "\n",
    "controller.fit(epochs,lr,\n",
    "               ddict=main_ddict, # Put in your tokenized datasetdict here\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=compute_metrics_classification,\n",
    "               tokenizer=tokenizer,\n",
    "               label_names='L1'\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.trainer.model.save_pretrained('./sample_weights/model_progress')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using trained model, using TDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_multilabel': False,\n",
       " 'is_multihead': False,\n",
       " 'head_class_sizes': 10,\n",
       " 'head_class': __main__.SimpleClassificationHead,\n",
       " 'classifier_dropout': 0.1}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_model_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sample_weights/model_progress were not used when initializing RobertaBaseForSequenceClassification: ['body_model.pooler.dense.weight', 'body_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaBaseForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaBaseForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "trained_model = model_init_classification(model_class = RobertaBaseForSequenceClassification,\n",
    "                                          cpoint_path = Path('./sample_weights/model_progress'), \n",
    "                                          output_hidden_states=False,\n",
    "                                          seed=42,\n",
    "                                          model_kwargs = _model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaBaseForSequenceClassification(\n",
       "  (body_model): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(59993, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classification_head): SimpleClassificationHead(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score] # we will use both f1_macro and accuracy score as metrics\n",
    "controller = ModelController(trained_model,tdm,metric_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Train/Validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction on all validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/447 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_val = controller.predict_ddict(ds_type='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - Chơi gam rất là lác</td>\n",
       "      <td>3</td>\n",
       "      <td>google play</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>0.837496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google play - Zq</td>\n",
       "      <td>5</td>\n",
       "      <td>google play</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.927602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non owned - Làn sóng kỹ thuật số và sự lựa chọ...</td>\n",
       "      <td>5</td>\n",
       "      <td>non owned</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.918241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google play - Hàng quốc tế không còn ship COD ...</td>\n",
       "      <td>6</td>\n",
       "      <td>google play</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.804539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - Quá tệ . Giao hàng chậm như rùa ...</td>\n",
       "      <td>2</td>\n",
       "      <td>google play</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.758327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label       Source   \n",
       "0                  google play - Chơi gam rất là lác      3  google play  \\\n",
       "1                                   google play - Zq      5  google play   \n",
       "2  non owned - Làn sóng kỹ thuật số và sự lựa chọ...      5    non owned   \n",
       "3  google play - Hàng quốc tế không còn ship COD ...      6  google play   \n",
       "4  google play - Quá tệ . Giao hàng chậm như rùa ...      2  google play   \n",
       "\n",
       "      pred_L1  pred_prob_L1  \n",
       "0  Commercial      0.837496  \n",
       "1      Others      0.927602  \n",
       "2      Others      0.918241  \n",
       "3    Delivery      0.804539  \n",
       "4    Delivery      0.758327  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the label index to string, we can use the ```label_lists``` attribute of tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - Chơi gam rất là lác</td>\n",
       "      <td>Feature</td>\n",
       "      <td>google play</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>0.837496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google play - Zq</td>\n",
       "      <td>Others</td>\n",
       "      <td>google play</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.927602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non owned - Làn sóng kỹ thuật số và sự lựa chọ...</td>\n",
       "      <td>Others</td>\n",
       "      <td>non owned</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.918241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google play - Hàng quốc tế không còn ship COD ...</td>\n",
       "      <td>Payment</td>\n",
       "      <td>google play</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.804539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - Quá tệ . Giao hàng chậm như rùa ...</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>google play</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.758327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label       Source   \n",
       "0                  google play - Chơi gam rất là lác   Feature  google play  \\\n",
       "1                                   google play - Zq    Others  google play   \n",
       "2  non owned - Làn sóng kỹ thuật số và sự lựa chọ...    Others    non owned   \n",
       "3  google play - Hàng quốc tế không còn ship COD ...   Payment  google play   \n",
       "4  google play - Quá tệ . Giao hàng chậm như rùa ...  Delivery  google play   \n",
       "\n",
       "      pred_L1  pred_prob_L1  \n",
       "0  Commercial      0.837496  \n",
       "1      Others      0.927602  \n",
       "2      Others      0.918241  \n",
       "3    Delivery      0.804539  \n",
       "4    Delivery      0.758327  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['label']= df_val['label'].apply(lambda x: tdm.label_lists[0][x]).values\n",
    "\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try to get your metric to see if it matches your last traing epoch's above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4634417008698494"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_val.label,df_val.pred_L1,average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also make predictions on all training set, by changing argument ```ds_type``` to \"train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go through details on how to make a prediction on a completely new and raw dataset using our trained model. For now, let's reuse the sample csv and pretend it's our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Input Validation Precheck -----\n",
      "DataFrame contains duplicated values!\n",
      "-----> Number of duplications: 16 rows\n"
     ]
    }
   ],
   "source": [
    "df_test = TextDataMain.from_csv(Path('sample_data')/'sample_large.csv',return_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove all the labels and unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = df_test['L1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['L1','L2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google Play</td>\n",
       "      <td>App ncc lúc nào cx lag đơ, phần tìm kiếm thì v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non Owned</td>\n",
       "      <td>..❗️ GÓC THANH LÝ Tính ra rẻ hơn cả mua #Shope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google Play</td>\n",
       "      <td>Mắc gì người ta đặt hàng toàn lỗi 😃????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owned</td>\n",
       "      <td>#GhienShopeePayawardT8 Khi bạn chơi shopee quá...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google Play</td>\n",
       "      <td>Rất bức xúc khi dùng . mã giảm giá người dùng ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source                                            Content\n",
       "0  Google Play  App ncc lúc nào cx lag đơ, phần tìm kiếm thì v...\n",
       "1    Non Owned  ..❗️ GÓC THANH LÝ Tính ra rẻ hơn cả mua #Shope...\n",
       "2  Google Play            Mắc gì người ta đặt hàng toàn lỗi 😃????\n",
       "3        Owned  #GhienShopeePayawardT8 Khi bạn chơi shopee quá...\n",
       "4  Google Play  Rất bức xúc khi dùng . mã giảm giá người dùng ..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a DatasetDict for this test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Getting Test Set --------------------\n",
      "----- Input Validation Precheck -----\n",
      "DataFrame contains duplicated values!\n",
      "-----> Number of duplications: 19 rows\n",
      "-------------------- Start Test Set Transformation --------------------\n",
      "----- Metadata Simple Processing & Concatenating to Main Content -----\n",
      "-------------------- Text Transformation --------------------\n",
      "----- text_normalize -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2269/2269 [00:00<00:00, 3954.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Test Leak Checking --------------------\n",
      "- Before leak check\n",
      "Size: 2269\n",
      "- After leak check\n",
      "Size: 0\n",
      "- Number of rows leaked: 2269, or 100.00% of the original validation (or test) data\n",
      "-------------------- Construct DatasetDict --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ddict = tdm.get_test_datasetdict_from_df(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the ***Leak Check*** we did in TextDataMain? Our ```df_test``` only has 70 rows, and it also shows that 70 rows of our data is leaked (100%), which is correct because this test dataset is actually a small sample of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text', 'Source', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ddict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test data has been processed + transformed (but not augmented) the same way as the validation set. Now we can start making the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "controller = ModelController(trained_model,tdm)\n",
    "df_result = controller.predict_ddict(ddict=test_ddict,ds_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - App ncc lúc nào cx lag đơ , phần...</td>\n",
       "      <td>google play</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.878221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non owned - .. ❗ ️ GÓC THANH LÝ Tính ra rẻ hơn...</td>\n",
       "      <td>non owned</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.930981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google play - Mắc gì người ta đặt hàng toàn lỗ...</td>\n",
       "      <td>google play</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.849374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owned - # GhienShopeePayawardT8 Khi bạn chơi s...</td>\n",
       "      <td>owned</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>0.915552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - Rất bức xúc khi dùng . mã giảm g...</td>\n",
       "      <td>google play</td>\n",
       "      <td>Shopee account</td>\n",
       "      <td>0.571471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       Source   \n",
       "0  google play - App ncc lúc nào cx lag đơ , phần...  google play  \\\n",
       "1  non owned - .. ❗ ️ GÓC THANH LÝ Tính ra rẻ hơn...    non owned   \n",
       "2  google play - Mắc gì người ta đặt hàng toàn lỗ...  google play   \n",
       "3  owned - # GhienShopeePayawardT8 Khi bạn chơi s...        owned   \n",
       "4  google play - Rất bức xúc khi dùng . mã giảm g...  google play   \n",
       "\n",
       "          pred_L1  pred_prob_L1  \n",
       "0         Feature      0.878221  \n",
       "1          Others      0.930981  \n",
       "2         Feature      0.849374  \n",
       "3      Commercial      0.915552  \n",
       "4  Shopee account      0.571471  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly check the f1 score to make sure everything works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5303012712104336"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(true_label,df_result.pred_L1,average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are getting the predictions on the entire training+validation set, the F1 score is expected to be slightly higher than validation's F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even predict top k results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "      <th>pred_L1_top1</th>\n",
       "      <th>pred_L1_top2</th>\n",
       "      <th>pred_L1_top3</th>\n",
       "      <th>pred_prob_L1_top1</th>\n",
       "      <th>pred_prob_L1_top2</th>\n",
       "      <th>pred_prob_L1_top3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - App ncc lúc nào cx lag đơ , phần...</td>\n",
       "      <td>google play</td>\n",
       "      <td>[3, 5, 9]</td>\n",
       "      <td>[0.87822074, 0.023822138, 0.02159522]</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Others</td>\n",
       "      <td>Shopee account</td>\n",
       "      <td>0.878221</td>\n",
       "      <td>0.023822</td>\n",
       "      <td>0.021595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non owned - .. ❗ ️ GÓC THANH LÝ Tính ra rẻ hơn...</td>\n",
       "      <td>non owned</td>\n",
       "      <td>[5, 1, 0]</td>\n",
       "      <td>[0.9309808, 0.015578598, 0.009805982]</td>\n",
       "      <td>Others</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Buyer complained seller</td>\n",
       "      <td>0.930981</td>\n",
       "      <td>0.015579</td>\n",
       "      <td>0.009806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google play - Mắc gì người ta đặt hàng toàn lỗ...</td>\n",
       "      <td>google play</td>\n",
       "      <td>[3, 5, 9]</td>\n",
       "      <td>[0.8493735, 0.050054528, 0.021759989]</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Others</td>\n",
       "      <td>Shopee account</td>\n",
       "      <td>0.849374</td>\n",
       "      <td>0.050055</td>\n",
       "      <td>0.021760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owned - # GhienShopeePayawardT8 Khi bạn chơi s...</td>\n",
       "      <td>owned</td>\n",
       "      <td>[1, 6, 7]</td>\n",
       "      <td>[0.9155516, 0.01255093, 0.010521941]</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Payment</td>\n",
       "      <td>Return/Refund</td>\n",
       "      <td>0.915552</td>\n",
       "      <td>0.012551</td>\n",
       "      <td>0.010522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - Rất bức xúc khi dùng . mã giảm g...</td>\n",
       "      <td>google play</td>\n",
       "      <td>[9, 3, 1]</td>\n",
       "      <td>[0.57147133, 0.25687057, 0.03061041]</td>\n",
       "      <td>Shopee account</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>0.571471</td>\n",
       "      <td>0.256871</td>\n",
       "      <td>0.030610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       Source    pred_L1   \n",
       "0  google play - App ncc lúc nào cx lag đơ , phần...  google play  [3, 5, 9]  \\\n",
       "1  non owned - .. ❗ ️ GÓC THANH LÝ Tính ra rẻ hơn...    non owned  [5, 1, 0]   \n",
       "2  google play - Mắc gì người ta đặt hàng toàn lỗ...  google play  [3, 5, 9]   \n",
       "3  owned - # GhienShopeePayawardT8 Khi bạn chơi s...        owned  [1, 6, 7]   \n",
       "4  google play - Rất bức xúc khi dùng . mã giảm g...  google play  [9, 3, 1]   \n",
       "\n",
       "                            pred_prob_L1    pred_L1_top1 pred_L1_top2   \n",
       "0  [0.87822074, 0.023822138, 0.02159522]         Feature       Others  \\\n",
       "1  [0.9309808, 0.015578598, 0.009805982]          Others   Commercial   \n",
       "2  [0.8493735, 0.050054528, 0.021759989]         Feature       Others   \n",
       "3   [0.9155516, 0.01255093, 0.010521941]      Commercial      Payment   \n",
       "4   [0.57147133, 0.25687057, 0.03061041]  Shopee account      Feature   \n",
       "\n",
       "              pred_L1_top3  pred_prob_L1_top1  pred_prob_L1_top2   \n",
       "0           Shopee account           0.878221           0.023822  \\\n",
       "1  Buyer complained seller           0.930981           0.015579   \n",
       "2           Shopee account           0.849374           0.050055   \n",
       "3            Return/Refund           0.915552           0.012551   \n",
       "4               Commercial           0.571471           0.256871   \n",
       "\n",
       "   pred_prob_L1_top3  \n",
       "0           0.021595  \n",
       "1           0.009806  \n",
       "2           0.021760  \n",
       "3           0.010522  \n",
       "4           0.030610  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = controller.predict_ddict(ddict=test_ddict,ds_type='test',topk=3)\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want to make a prediction on a small amount of data (single sentence, or a few sentences), we can use `ModelController.predict_raw_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have some metadatas, we need to define a dictionary (to imitate a DatasetDict)\n",
    "raw_content={\n",
    "    'Source': 'Google play',\n",
    "    'Content':'Tôi không thích Shopee.Tại vì dùng app rất chậm,lag banh nhà lầu, thậm chí log in còn không đc'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't use metadata, we can use something like this: \n",
    "\n",
    "```raw_content='Tôi không thích Shopee.Tại vì dùng app rất chậm,lag banh nhà lầu, thậm chí log in còn không đc'```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 4718.00it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - Tôi không thích Shopee . Tại vì ...</td>\n",
       "      <td>google play</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.876843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       Source  pred_L1   \n",
       "0  google play - Tôi không thích Shopee . Tại vì ...  google play  Feature  \\\n",
       "\n",
       "   pred_prob_L1  \n",
       "0      0.876843  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = controller.predict_raw_text(raw_content,topk=1)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using trained model, using tokenized DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "model_name='nguyenvulebinh/envibert'\n",
    "_model_kwargs={\n",
    "    # overall model hyperparams\n",
    "    'is_multilabel':False, # False\n",
    "    'is_multihead':False, # False\n",
    "    'head_class_sizes':num_classes,\n",
    "    'head_class': SimpleClassificationHead,\n",
    "    # classfication head hyperparams\n",
    "    'classifier_dropout':0.1 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sample_weights/model_progress were not used when initializing RobertaBaseForSequenceClassification: ['body_model.pooler.dense.weight', 'body_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaBaseForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaBaseForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "trained_model = model_init_classification(model_class = RobertaBaseForSequenceClassification,\n",
    "                                          cpoint_path = Path('./sample_weights/model_progress'), \n",
    "                                          output_hidden_states=False,\n",
    "                                          seed=42,\n",
    "                                          model_kwargs = _model_kwargs)\n",
    "\n",
    "\n",
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score]\n",
    "controller = ModelController(trained_model,metric_funcs) # notice that we don't use tdm here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'Source', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 4780\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'Source', 'input_ids', 'token_type_ids', 'attention_mask', 'pred_L1', 'pred_prob_L1'],\n",
       "        num_rows: 447\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_ddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_label_name = 'L1'\n",
    "my_class_predefined = ['Buyer complained seller',\n",
    " 'Commercial',\n",
    " 'Delivery',\n",
    " 'Feature',\n",
    " 'Order/Item',\n",
    " 'Others',\n",
    " 'Payment',\n",
    " 'Return/Refund',\n",
    " 'Services',\n",
    " 'Shopee account']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/447 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_val = controller.predict_ddict(main_ddict,\n",
    "                                  ds_type='validation',\n",
    "                                  is_multilabel=False,\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  label_names = my_label_name,\n",
    "                                  class_names_predefined=my_class_predefined\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - Chơi gam rất là lác</td>\n",
       "      <td>3</td>\n",
       "      <td>google play</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>0.837496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google play - Zq</td>\n",
       "      <td>5</td>\n",
       "      <td>google play</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.927602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non owned - Làn sóng kỹ thuật số và sự lựa chọ...</td>\n",
       "      <td>5</td>\n",
       "      <td>non owned</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.918241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google play - Hàng quốc tế không còn ship COD ...</td>\n",
       "      <td>6</td>\n",
       "      <td>google play</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.804539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - Quá tệ . Giao hàng chậm như rùa ...</td>\n",
       "      <td>2</td>\n",
       "      <td>google play</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.758327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label       Source   \n",
       "0                  google play - Chơi gam rất là lác      3  google play  \\\n",
       "1                                   google play - Zq      5  google play   \n",
       "2  non owned - Làn sóng kỹ thuật số và sự lựa chọ...      5    non owned   \n",
       "3  google play - Hàng quốc tế không còn ship COD ...      6  google play   \n",
       "4  google play - Quá tệ . Giao hàng chậm như rùa ...      2  google play   \n",
       "\n",
       "      pred_L1  pred_prob_L1  \n",
       "0  Commercial      0.837496  \n",
       "1      Others      0.927602  \n",
       "2      Others      0.918241  \n",
       "3    Delivery      0.804539  \n",
       "4    Delivery      0.758327  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text', 'Source', 'input_ids', 'token_type_ids', 'attention_mask', 'pred_L1', 'pred_prob_L1'],\n",
       "        num_rows: 2269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ddict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be cumbersome to preprocess your test data the same way you preprocess your validation set, without the use of tdm (which stores the preprocess pipeline). In short, you need to produce the test datasetdict `test_ddict` containing processed `'input_ids', 'token_type_ids', 'attention_mask'`, then call\n",
    "\n",
    "```python\n",
    "df_results = controller.predict_ddict(ddict=test_ddict,\n",
    "                                      ds_type='test',\n",
    "                                      is_multilabel=False,\n",
    "                                      tokenizer=tokenizer,\n",
    "                                      label_names = my_label_name,\n",
    "                                      class_names_predefined=my_class_predefined     \n",
    "                                     )\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
