{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Controller Tutorial: Classification\n",
    "\n",
    "> This notebook contains an end-to-end process of preprocess + tokenizing your text, and build a classification model based on Roberta architecture\n",
    "\n",
    "- skip_showdoc: true\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#This will specify a (or a list) of GPUs for training\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from that_nlp_library.text_transformation import *\n",
    "from that_nlp_library.text_augmentation import *\n",
    "from that_nlp_library.text_main import *\n",
    "from that_nlp_library.utils import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from underthesea import text_normalize\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from importlib.machinery import SourceFileLoader\n",
    "import os\n",
    "from transformers import DataCollatorWithPadding,RobertaTokenizer\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel,RobertaForSequenceClassification\n",
    "import torch\n",
    "import nlpaug.augmenter.char as nac\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the custom augmentation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_aug_stochastic(x,aug=None,p=0.5):\n",
    "    if not isinstance(x,list): \n",
    "        if random.random()<p: return aug.augment(x)[0]\n",
    "        return x\n",
    "    news=[]\n",
    "    originals=[]\n",
    "    for _x in x:\n",
    "        if random.random()<p: news.append(_x)\n",
    "        else: originals.append(_x)\n",
    "    # only perform augmentation when needed\n",
    "    if len(news): news = aug.augment(news)\n",
    "    return news+originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = nac.KeyboardAug(aug_char_max=3,aug_char_p=0.1,aug_word_p=0.07)\n",
    "nearby_aug_func = partial(nlp_aug_stochastic,aug=aug,p=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a TextDataController object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reuse the data and the preprocessings in [this tutorial](https://anhquan0412.github.io/that-nlp-library/text_main.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv'],split='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    22641.000000\n",
       "mean        60.196679\n",
       "std         28.534612\n",
       "min          2.000000\n",
       "25%         36.000000\n",
       "50%         59.000000\n",
       "75%         88.000000\n",
       "max        115.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(list(map(lambda x: len(x.split()),[text for text in dset['Review Text'] if text is not None]))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         # add \"str.lower\" here because nearby_aug might return uppercase character\n",
    "                         val_ratio=0.2,\n",
    "                         batch_size=1000,\n",
    "                         seed=42,\n",
    "                         num_proc=20,\n",
    "                         verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our tokenizer for Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process and tokenize our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start Main Text Processing --------------------\n",
      "-------------------- Data Filtering --------------------\n",
      "----- Do <lambda> on Review Text -----\n",
      "----- Do <lambda> on Department Name -----\n",
      "Done\n",
      "----- Metadata Simple Processing & Concatenating to Main Content -----\n",
      "Done\n",
      "----- Label Encoding -----\n",
      "Done\n",
      "-------------------- Text Transformation --------------------\n",
      "----- text_normalize -----\n",
      "----- lower -----\n",
      "Done\n",
      "-------------------- Train Test Split --------------------\n",
      "Validation split based on val_ratio\n",
      "Done\n",
      "-------------------- Dropping unused features --------------------\n",
      "Done\n",
      "- Number of rows leaked: 0, which is 0.00% of training set\n",
      "-------------------- Text Augmentation --------------------\n",
      "----- nlp_aug_stochastic -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6049d5a3401845b9aa10cc639f8e3049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/18102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- lower -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94dc27c9b56d42f4824df19d37df08ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/18102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "-------------------- Shuffling and flattening train set --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb53120d15254e609fa40fc63f750e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices (num_proc=20):   0%|          | 0/18102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "-------------------- Tokenization --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7015e3fa0534f65b442f2529d53246e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/18102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e281dd97793146acaf5561fb009899b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/4526 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "tdc.process_and_tokenize(_tokenizer,max_length=100,shuffle_trn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Title', 'Review Text', 'Division Name', 'Department Name', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 18102\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Title', 'Review Text', 'Division Name', 'Department Name', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4526\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdc.main_ddict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see one example of how those content transformations and augmentations affect our input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is not what I expected ü§¨. I gulped when I put this in my bag during retailer days because the price was still too much ... but thought this has to be wonderful to charge so much,right??\n"
     ]
    }
   ],
   "source": [
    "sample_txt = 'This is not what I expected ü§¨. I gulped when I put this in my bag during retailer days because the price was still too much ... but thought this has to be wonderful to charge so much,right??'\n",
    "print(sample_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t------- Text Transformation Explained -------\n",
      "----- Raw sentence -----\n",
      "This is not what I expected ü§¨. I gulped when I put this in my bag during retailer days because the price was still too much ... but thought this has to be wonderful to charge so much,right??\n",
      "\n",
      "----- Content Transformations (on both train and test) -----\n",
      "--- text_normalize ---\n",
      "This is not what I expected ü§¨ . I gulped when I put this in my bag during retailer days because the price was still too much ... but thought this has to be wonderful to charge so much , right ? ?\n",
      "\n",
      "--- lower ---\n",
      "this is not what i expected ü§¨ . i gulped when i put this in my bag during retailer days because the price was still too much ... but thought this has to be wonderful to charge so much , right ? ?\n",
      "\n",
      "\n",
      "----- Augmentations (on train only) -----\n",
      "--- nlp_aug_stochastic ---\n",
      "tMis is not what i expected ü§¨. i gulped when i put this in my bag during rrtailer Cays because the price was still too much. .. but thought this has to be wonderful to Vharge so much, right??\n",
      "\n",
      "--- lower ---\n",
      "tmis is not what i expected ü§¨. i gulped when i put this in my bag during rrtailer cays because the price was still too much. .. but thought this has to be wonderful to vharge so much, right??\n",
      "\n",
      "\n",
      "\t\t------- Tokenizer Explained -------\n",
      "----- Input -----\n",
      "tmis is not what i expected ü§¨. i gulped when i put this in my bag during rrtailer cays because the price was still too much. .. but thought this has to be wonderful to vharge so much, right??\n",
      "\n",
      "----- Tokenized results ----- \n",
      "{'input_ids': [0, 26989, 354, 16, 45, 99, 939, 421, 8103, 10470, 11582, 4, 939, 42445, 9700, 77, 939, 342, 42, 11, 127, 3298, 148, 910, 338, 17624, 254, 740, 4113, 142, 5, 425, 21, 202, 350, 203, 4, 29942, 53, 802, 42, 34, 7, 28, 4613, 7, 748, 298, 16347, 98, 203, 6, 235, 28749, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "\n",
      "----- Results from tokenizer.convert_ids_to_tokens -----\n",
      "['<s>', 'tm', 'is', 'ƒ†is', 'ƒ†not', 'ƒ†what', 'ƒ†i', 'ƒ†expected', 'ƒ†√∞≈Å', '¬§', '¬¨', '.', 'ƒ†i', 'ƒ†gul', 'ped', 'ƒ†when', 'ƒ†i', 'ƒ†put', 'ƒ†this', 'ƒ†in', 'ƒ†my', 'ƒ†bag', 'ƒ†during', 'ƒ†r', 'r', 'tail', 'er', 'ƒ†c', 'ays', 'ƒ†because', 'ƒ†the', 'ƒ†price', 'ƒ†was', 'ƒ†still', 'ƒ†too', 'ƒ†much', '.', 'ƒ†..', 'ƒ†but', 'ƒ†thought', 'ƒ†this', 'ƒ†has', 'ƒ†to', 'ƒ†be', 'ƒ†wonderful', 'ƒ†to', 'ƒ†v', 'h', 'arge', 'ƒ†so', 'ƒ†much', ',', 'ƒ†right', '??', '</s>']\n",
      "\n",
      "----- Results from tokenizer.decode ----- \n",
      "<s>tmis is not what i expected ü§¨. i gulped when i put this in my bag during rrtailer cays because the price was still too much... but thought this has to be wonderful to vharge so much, right??</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "two_steps_tokenization_explain(sample_txt,_tokenizer,\n",
    "                               content_tfms=[text_normalize,str.lower],\n",
    "                               aug_tfms=[partial(nlp_aug_stochastic,aug=aug,p=1),str.lower]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experiment: Roberta Vanilla Single-Head Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "from that_nlp_library.models.roberta.classifiers import *\n",
    "from that_nlp_library.model_main import *\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Roberta model using the Model Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdc.label_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(tdc.label_lists[0])\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='roberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "_model = RobertaForSequenceClassification.from_pretrained(model_name,num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model = _model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can define the metrics to used, and the Model Controller object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score] \n",
    "# we will use both f1_macro and accuracy score as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = ModelController(_model,\n",
    "                             data_store=tdc,\n",
    "                             metric_funcs=metric_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can start training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='849' max='849' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [849/849 02:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score Department name</th>\n",
       "      <th>Accuracy Score Department name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.308028</td>\n",
       "      <td>0.743565</td>\n",
       "      <td>0.914494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.419900</td>\n",
       "      <td>0.295569</td>\n",
       "      <td>0.749259</td>\n",
       "      <td>0.919797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.419900</td>\n",
       "      <td>0.279552</td>\n",
       "      <td>0.747071</td>\n",
       "      <td>0.917808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "bs=32\n",
    "wd=0.01\n",
    "epochs= 3\n",
    "\n",
    "controller.fit(epochs,lr,\n",
    "               head_sizes=num_classes,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=compute_metrics_classification,\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging your training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can log your training using HuggingFace:\n",
    "\n",
    "- Supported platforms are \"azure_ml\", \"comet_ml\", \"mlflow\", \"neptune\", \"tensorboard\",\"clearml\" and \"wandb\"\n",
    "\n",
    "- References:\n",
    "\n",
    "    - https://huggingface.co/docs/transformers/v4.28.0/en/main_classes/trainer#transformers.TrainingArguments\n",
    "    \n",
    "    - https://docs.wandb.ai/guides/integrations/huggingface#:~:text=Logging%20your%20Hugging%20Face%20model,every%20save_steps%20in%20the%20TrainingArguments%20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "controller.fit(epochs,lr,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=compute_metrics_classification,\n",
    "               hf_report_to='wandb'\n",
    "              )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save your model weights at the end of your training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "controller.trainer.model.save_pretrained('./sample_weights/model_progress')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can save your weights at every epochs during your training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "controller.fit(epochs,lr,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=True,\n",
    "               o_dir='sample_weights',\n",
    "               compute_metrics=compute_metrics_classification,\n",
    "              )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with only a Tokenized DatasetDict (no TextDataController)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part assumes you already have your tokenized datasetdict, without the use of `TextDataController`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_ddict = copy.deepcopy(tdc.main_ddict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Title', 'Review Text', 'Division Name', 'Department Name', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 18102\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Title', 'Review Text', 'Division Name', 'Department Name', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4526\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_ddict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that your DatasetDict must contain tokens besides raw text (which typically includes 'input_ids', 'token_type_ids', 'attention_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name='roberta-base'\n",
    "\n",
    "_model = RobertaForSequenceClassification.from_pretrained(model_name,num_labels=num_classes)\n",
    "\n",
    "_model = _model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score] \n",
    "\n",
    "# note that you omit the `data_store` argument\n",
    "controller = ModelController(_model,metric_funcs=metric_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='849' max='849' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [849/849 02:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score Department name</th>\n",
       "      <th>Accuracy Score Department name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.331047</td>\n",
       "      <td>0.738015</td>\n",
       "      <td>0.905656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.427000</td>\n",
       "      <td>0.287491</td>\n",
       "      <td>0.747379</td>\n",
       "      <td>0.916703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.427000</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.746442</td>\n",
       "      <td>0.916483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "bs=32\n",
    "wd=0.01\n",
    "epochs= 3\n",
    "\n",
    "controller.fit(epochs,lr,\n",
    "               ddict=main_ddict, # Put in your tokenized datasetdict here\n",
    "               label_names='Department Name',\n",
    "               head_sizes=num_classes,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=compute_metrics_classification,\n",
    "               tokenizer=_tokenizer,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.trainer.model.save_pretrained('./sample_weights/model_progress')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions, using TextDataController"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = RobertaForSequenceClassification.from_pretrained('./sample_weights/model_progress',num_labels=6).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score]\n",
    "controller = ModelController(trained_model,tdc,metric_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Train/Validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction on all validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99fb10b05f9c42b79c6dd7c2ef3b0686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4526 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c895617f5de49d186f052de41fe6eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4526 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_val = controller.predict_ddict_classification(ds_type='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>label</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>pred_Department Name</th>\n",
       "      <th>pred_prob_Department Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>general petite . . such a fun jacket ! great t...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 15841, 4716, 1459, 479, 479, 215, 10, 1531...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Jackets</td>\n",
       "      <td>0.836846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simple and elegant</td>\n",
       "      <td>general petite . simple and elegant . i though...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 15841, 4716, 1459, 479, 2007, 8, 14878, 47...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Tops</td>\n",
       "      <td>0.994427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>retro and pretty</td>\n",
       "      <td>general . retro and pretty . this top has a bi...</td>\n",
       "      <td>general</td>\n",
       "      <td>Tops</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 15841, 479, 11299, 8, 1256, 479, 42, 299, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Tops</td>\n",
       "      <td>0.994420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>summer/fall wear</td>\n",
       "      <td>general petite . summer / fall wear . i first ...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 15841, 4716, 1459, 479, 1035, 1589, 1136, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0.984159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perfect except slip</td>\n",
       "      <td>general petite . perfect except slip . this is...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 15841, 4716, 1459, 479, 1969, 4682, 9215, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0.985003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Title                                        Review Text   \n",
       "0                       general petite . . such a fun jacket ! great t...  \\\n",
       "1   simple and elegant  general petite . simple and elegant . i though...   \n",
       "2     retro and pretty  general . retro and pretty . this top has a bi...   \n",
       "3     summer/fall wear  general petite . summer / fall wear . i first ...   \n",
       "4  perfect except slip  general petite . perfect except slip . this is...   \n",
       "\n",
       "    Division Name Department Name  label   \n",
       "0  general petite        Intimate      2  \\\n",
       "1  general petite            Tops      4   \n",
       "2         general            Tops      4   \n",
       "3  general petite         Dresses      1   \n",
       "4  general petite         Dresses      1   \n",
       "\n",
       "                                           input_ids   \n",
       "0  [0, 15841, 4716, 1459, 479, 479, 215, 10, 1531...  \\\n",
       "1  [0, 15841, 4716, 1459, 479, 2007, 8, 14878, 47...   \n",
       "2  [0, 15841, 479, 11299, 8, 1256, 479, 42, 299, ...   \n",
       "3  [0, 15841, 4716, 1459, 479, 1035, 1589, 1136, ...   \n",
       "4  [0, 15841, 4716, 1459, 479, 1969, 4682, 9215, ...   \n",
       "\n",
       "                                      attention_mask pred_Department Name   \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...              Jackets  \\\n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                 Tops   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                 Tops   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...              Dresses   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...              Dresses   \n",
       "\n",
       "   pred_prob_Department Name  \n",
       "0                   0.836846  \n",
       "1                   0.994427  \n",
       "2                   0.994420  \n",
       "3                   0.984159  \n",
       "4                   0.985003  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = df_val.to_pandas()\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the label index to string, we can use the ```label_lists``` attribute of tdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try to get your metric to see if it matches your last traing epoch's above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7464422585186901"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_val['Department Name'],df_val['pred_Department Name'],average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also make predictions on all training set, by changing argument ```ds_type``` to \"train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go through details on how to make a prediction on a completely new and raw dataset using our trained model. For now, let's reuse the sample csv and pretend it's our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('sample_data/Womens_Clothing_Reviews.csv',encoding='utf-8-sig').sample(frac=0.2,random_state=1)\n",
    "# drop NaN values in the label column\n",
    "df_test = df_test[~df_test['Department Name'].isna()].reset_index(drop=True)\n",
    "\n",
    "# save the label, as we will calculate some metrics later. We also filter out labels with NaN Review Text,\n",
    "# as there will be a filtering processing on the test set\n",
    "true_labels = df_test.loc[~df_test['Review Text'].isna(),'Department Name'].values \n",
    "\n",
    "# drop the label (you don't need to, but this is necessary to simulate an actual test set)\n",
    "df_test.drop('Department Name',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4692, 9)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>872</td>\n",
       "      <td>42</td>\n",
       "      <td>Perfect for work and play</td>\n",
       "      <td>This shirt works for both going out and going ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1033</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I don't know why i had the opposite problem mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Jeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1037</td>\n",
       "      <td>45</td>\n",
       "      <td>Great pants</td>\n",
       "      <td>These cords are great--lightweight for fl wint...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Jeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>829</td>\n",
       "      <td>35</td>\n",
       "      <td>Surprisingly comfy for a button down</td>\n",
       "      <td>I am a 10 m and got the 10. it fits perfectly ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>872</td>\n",
       "      <td>29</td>\n",
       "      <td>Short and small</td>\n",
       "      <td>The shirt is mostly a thick sweatshirt materia...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clothing ID  Age                                 Title   \n",
       "0          872   42             Perfect for work and play  \\\n",
       "1         1033   40                                   NaN   \n",
       "2         1037   45                           Great pants   \n",
       "3          829   35  Surprisingly comfy for a button down   \n",
       "4          872   29                       Short and small   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND   \n",
       "0  This shirt works for both going out and going ...       5                1  \\\n",
       "1  I don't know why i had the opposite problem mo...       4                1   \n",
       "2  These cords are great--lightweight for fl wint...       5                1   \n",
       "3  I am a 10 m and got the 10. it fits perfectly ...       5                1   \n",
       "4  The shirt is mostly a thick sweatshirt materia...       3                0   \n",
       "\n",
       "   Positive Feedback Count   Division Name Class Name  \n",
       "0                        0         General      Knits  \n",
       "1                        0  General Petite      Jeans  \n",
       "2                        1  General Petite      Jeans  \n",
       "3                        1  General Petite    Blouses  \n",
       "4                       15  General Petite      Knits  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, you have 2 options\n",
    "\n",
    "1. Use `TextDataController` to process your data, then `ModelController`'s job is to perform prediction\n",
    "2. Convert your dataframe to a HuggingFace Dataset, and let the `ModelController` take care of the preprocessing and the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Input Validation Precheck -\n",
      "Data contains missing values!\n",
      "-----> List of columns and the number of missing values for each\n",
      "Title          758\n",
      "Review Text    164\n",
      "dtype: int64\n",
      "Data contains duplicated values!\n",
      "-----> Number of duplications: 2 rows\n",
      "-------------------- Start Test Set Transformation --------------------\n",
      "-------------------- Data Filtering --------------------\n",
      "----- Do <lambda> on Review Text -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad597517a5e426ba5ed2c3a5d538e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=20):   0%|          | 0/4692 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "----- Metadata Simple Processing & Concatenating to Main Content -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d051ee65b3ee44bf8facb42b0e2a4b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/4528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "-------------------- Text Transformation --------------------\n",
      "----- text_normalize -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52874700dcf44f5b620f8ff4d1ccd73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/4528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- lower -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a674d1f9858f4e23b2d25e83c434f73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/4528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "-------------------- Tokenization --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d108eb0cf894ac9883ea646a2440351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/4528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "_test_dset_processed = tdc.prepare_test_dataset_from_df(df_test,validate=True,do_filtering=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Title', 'Review Text', 'Division Name', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4528\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_dset_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c8c8bc584347d5b2abd8679d686214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4449a61fb5c4fd8b141ba7161a6498d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_test_dset_predicted = controller.predict_ddict_classification(_test_dset_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>pred_Department Name</th>\n",
       "      <th>pred_prob_Department Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perfect for work and play</td>\n",
       "      <td>general . perfect for work and play . this shi...</td>\n",
       "      <td>general</td>\n",
       "      <td>[0, 15841, 479, 1969, 13, 173, 8, 310, 479, 42...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Tops</td>\n",
       "      <td>0.994379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>general petite . . i don't know why i had the ...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[0, 15841, 4716, 1459, 479, 479, 939, 218, 75,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>0.990404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great pants</td>\n",
       "      <td>general petite . great pants . thes e cords ar...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[0, 15841, 4716, 1459, 479, 372, 9304, 479, 5,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>0.985566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprisingly comfy for a button down</td>\n",
       "      <td>general petite . surprisingly comfy for a butt...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[0, 15841, 4716, 1459, 479, 10262, 3137, 24382...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Tops</td>\n",
       "      <td>0.991756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>short and small</td>\n",
       "      <td>general petite . short and small . the shirt i...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[0, 15841, 4716, 1459, 479, 765, 8, 650, 479, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Tops</td>\n",
       "      <td>0.992768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title   \n",
       "0             perfect for work and play  \\\n",
       "1                                         \n",
       "2                           great pants   \n",
       "3  surprisingly comfy for a button down   \n",
       "4                       short and small   \n",
       "\n",
       "                                         Review Text   Division Name   \n",
       "0  general . perfect for work and play . this shi...         general  \\\n",
       "1  general petite . . i don't know why i had the ...  general petite   \n",
       "2  general petite . great pants . thes e cords ar...  general petite   \n",
       "3  general petite . surprisingly comfy for a butt...  general petite   \n",
       "4  general petite . short and small . the shirt i...  general petite   \n",
       "\n",
       "                                           input_ids   \n",
       "0  [0, 15841, 479, 1969, 13, 173, 8, 310, 479, 42...  \\\n",
       "1  [0, 15841, 4716, 1459, 479, 479, 939, 218, 75,...   \n",
       "2  [0, 15841, 4716, 1459, 479, 372, 9304, 479, 5,...   \n",
       "3  [0, 15841, 4716, 1459, 479, 10262, 3137, 24382...   \n",
       "4  [0, 15841, 4716, 1459, 479, 765, 8, 650, 479, ...   \n",
       "\n",
       "                                      attention_mask pred_Department Name   \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                 Tops  \\\n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...              Bottoms   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...              Bottoms   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                 Tops   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                 Tops   \n",
       "\n",
       "   pred_prob_Department Name  \n",
       "0                   0.994379  \n",
       "1                   0.990404  \n",
       "2                   0.985566  \n",
       "3                   0.991756  \n",
       "4                   0.992768  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_predicted = _test_dset_predicted.to_pandas()\n",
    "df_test_predicted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to turn off the info printing, you can do it to the `TextDataController` (stored as `data_store`) in the `ModelController` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.data_store.set_verbose(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86c35ee3486423e82fc236239c151f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=20):   0%|          | 0/4692 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c12e02f3c84ef686258ef5f70126fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/4528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391312c7c4514873a667bf69277b603b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/4528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091dde25ee6647659a8a9d1161cba07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/4528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb6585b321f4920a59533ea28e50b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/4528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d0a82aea5b4f4fa17c4077b7d34c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1c3b6abcd249debd1ad010c8f290bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_test_dset = Dataset.from_pandas(df_test)\n",
    "_test_dset_predicted = controller.predict_raw_dset(_test_dset,\n",
    "                                                   do_filtering=True, # since we have some text filtering in the processing\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_predicted = _test_dset_predicted.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>pred_Department Name</th>\n",
       "      <th>pred_prob_Department Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perfect for work and play</td>\n",
       "      <td>general . perfect for work and play . this shi...</td>\n",
       "      <td>general</td>\n",
       "      <td>[0, 15841, 479, 1969, 13, 173, 8, 310, 479, 42...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Tops</td>\n",
       "      <td>0.994379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>general petite . . i don't know why i had the ...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[0, 15841, 4716, 1459, 479, 479, 939, 218, 75,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>0.990404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great pants</td>\n",
       "      <td>general petite . great pants . thes e cords ar...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[0, 15841, 4716, 1459, 479, 372, 9304, 479, 5,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>0.985566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprisingly comfy for a button down</td>\n",
       "      <td>general petite . surprisingly comfy for a butt...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[0, 15841, 4716, 1459, 479, 10262, 3137, 24382...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Tops</td>\n",
       "      <td>0.991756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>short and small</td>\n",
       "      <td>general petite . short and small . the shirt i...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[0, 15841, 4716, 1459, 479, 765, 8, 650, 479, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Tops</td>\n",
       "      <td>0.992768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title   \n",
       "0             perfect for work and play  \\\n",
       "1                                         \n",
       "2                           great pants   \n",
       "3  surprisingly comfy for a button down   \n",
       "4                       short and small   \n",
       "\n",
       "                                         Review Text   Division Name   \n",
       "0  general . perfect for work and play . this shi...         general  \\\n",
       "1  general petite . . i don't know why i had the ...  general petite   \n",
       "2  general petite . great pants . thes e cords ar...  general petite   \n",
       "3  general petite . surprisingly comfy for a butt...  general petite   \n",
       "4  general petite . short and small . the shirt i...  general petite   \n",
       "\n",
       "                                           input_ids   \n",
       "0  [0, 15841, 479, 1969, 13, 173, 8, 310, 479, 42...  \\\n",
       "1  [0, 15841, 4716, 1459, 479, 479, 939, 218, 75,...   \n",
       "2  [0, 15841, 4716, 1459, 479, 372, 9304, 479, 5,...   \n",
       "3  [0, 15841, 4716, 1459, 479, 10262, 3137, 24382...   \n",
       "4  [0, 15841, 4716, 1459, 479, 765, 8, 650, 479, ...   \n",
       "\n",
       "                                      attention_mask pred_Department Name   \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                 Tops  \\\n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...              Bottoms   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...              Bottoms   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                 Tops   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                 Tops   \n",
       "\n",
       "   pred_prob_Department Name  \n",
       "0                   0.994379  \n",
       "1                   0.990404  \n",
       "2                   0.985566  \n",
       "3                   0.991756  \n",
       "4                   0.992768  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_predicted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly check the f1 score to make sure everything works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7524749882584216"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(true_labels,df_test_predicted['pred_Department Name'],average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not too far off from the validation F1 score. Notice that the 'test set' is just a sample from the original dataset, not the entire new set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even predict top k results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2f297171434bf3b7cc4b7005084df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=20):   0%|          | 0/4692 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398fa30240bb4dc79f95264cf40ed4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/4528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfcd43e34cd442488fcde39696055bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/4528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05e46de76764ff38ca003e81cfd80b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/4528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5830b63355844f193b56f21b8dec03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/4528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fea6fc1e05549889381b3ea96732310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac130e4b5d74f378bcb0aeee697ee77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_test_dset = Dataset.from_pandas(df_test)\n",
    "_test_dset_predicted = controller.predict_raw_dset(_test_dset,\n",
    "                                                   do_filtering=True,\n",
    "                                                   topk=3\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>pred_Department Name</th>\n",
       "      <th>pred_prob_Department Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perfect for work and play</td>\n",
       "      <td>general . perfect for work and play . this shi...</td>\n",
       "      <td>general</td>\n",
       "      <td>[0, 15841, 479, 1969, 13, 173, 8, 310, 479, 42...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[Tops, Intimate, Trend]</td>\n",
       "      <td>[0.99437934, 0.0026560943, 0.0013421137]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>general petite . . i don't know why i had the ...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[0, 15841, 4716, 1459, 479, 479, 939, 218, 75,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[Bottoms, Intimate, Trend]</td>\n",
       "      <td>[0.9904045, 0.0038873425, 0.0037708243]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great pants</td>\n",
       "      <td>general petite . great pants . thes e cords ar...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[0, 15841, 4716, 1459, 479, 372, 9304, 479, 5,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[Bottoms, Intimate, Trend]</td>\n",
       "      <td>[0.9855661, 0.00844732, 0.004315549]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprisingly comfy for a button down</td>\n",
       "      <td>general petite . surprisingly comfy for a butt...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[0, 15841, 4716, 1459, 479, 10262, 3137, 24382...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[Tops, Intimate, Jackets]</td>\n",
       "      <td>[0.9917563, 0.003145057, 0.002268775]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>short and small</td>\n",
       "      <td>general petite . short and small . the shirt i...</td>\n",
       "      <td>general petite</td>\n",
       "      <td>[0, 15841, 4716, 1459, 479, 765, 8, 650, 479, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[Tops, Intimate, Trend]</td>\n",
       "      <td>[0.9927677, 0.002915126, 0.0016307276]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title   \n",
       "0             perfect for work and play  \\\n",
       "1                                         \n",
       "2                           great pants   \n",
       "3  surprisingly comfy for a button down   \n",
       "4                       short and small   \n",
       "\n",
       "                                         Review Text   Division Name   \n",
       "0  general . perfect for work and play . this shi...         general  \\\n",
       "1  general petite . . i don't know why i had the ...  general petite   \n",
       "2  general petite . great pants . thes e cords ar...  general petite   \n",
       "3  general petite . surprisingly comfy for a butt...  general petite   \n",
       "4  general petite . short and small . the shirt i...  general petite   \n",
       "\n",
       "                                           input_ids   \n",
       "0  [0, 15841, 479, 1969, 13, 173, 8, 310, 479, 42...  \\\n",
       "1  [0, 15841, 4716, 1459, 479, 479, 939, 218, 75,...   \n",
       "2  [0, 15841, 4716, 1459, 479, 372, 9304, 479, 5,...   \n",
       "3  [0, 15841, 4716, 1459, 479, 10262, 3137, 24382...   \n",
       "4  [0, 15841, 4716, 1459, 479, 765, 8, 650, 479, ...   \n",
       "\n",
       "                                      attention_mask   \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \\\n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "         pred_Department Name                 pred_prob_Department Name  \n",
       "0     [Tops, Intimate, Trend]  [0.99437934, 0.0026560943, 0.0013421137]  \n",
       "1  [Bottoms, Intimate, Trend]   [0.9904045, 0.0038873425, 0.0037708243]  \n",
       "2  [Bottoms, Intimate, Trend]      [0.9855661, 0.00844732, 0.004315549]  \n",
       "3   [Tops, Intimate, Jackets]     [0.9917563, 0.003145057, 0.002268775]  \n",
       "4     [Tops, Intimate, Trend]    [0.9927677, 0.002915126, 0.0016307276]  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_predicted = _test_dset_predicted.to_pandas()\n",
    "\n",
    "df_test_predicted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want to make a prediction on a small amount of data (single sentence, or a few sentences), we can use `ModelController.predict_raw_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have some metadatas (Title and Division Name), we need to define a dictionary (to imitate a DatasetDict)\n",
    "raw_content={'Review Text': 'This shirt is so comfortable I love it!',\n",
    "             'Title': 'Great shirt',\n",
    "             'Division Name': 'general'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't use metadata, just create a string instead, e.g.\n",
    "\n",
    "```raw_content='This shirt is so comfortable I love it!'```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f55c8231e24f0497c6fae362856ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e050743a6a03415aac119748756657e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c6fb185aa74d9eac6110d49a98270b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51881ab399d4991b87de66caab8d4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de9f9c7c2784faabf37b6f982dac3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a06fe5c0df04f958519bb9e1ca72d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result = controller.predict_raw_text(raw_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Title</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>pred_Department Name</th>\n",
       "      <th>pred_prob_Department Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>general . great shirt . this shirt is so comfo...</td>\n",
       "      <td>great shirt</td>\n",
       "      <td>general</td>\n",
       "      <td>[0, 15841, 479, 372, 6399, 479, 42, 6399, 16, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>Tops</td>\n",
       "      <td>0.994505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text        Title   \n",
       "0  general . great shirt . this shirt is so comfo...  great shirt  \\\n",
       "\n",
       "  Division Name                                          input_ids   \n",
       "0       general  [0, 15841, 479, 372, 6399, 479, 42, 6399, 16, ...  \\\n",
       "\n",
       "                                     attention_mask pred_Department Name   \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]                 Tops  \\\n",
       "\n",
       "   pred_prob_Department Name  \n",
       "0                   0.994505  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289e0540c71345dd93cfc92bd7dcc8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea096457ce144ff29253f12446eebf2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c0cdb952de4e0eab75a4bd9c90b843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e1249903e441e79e574c2a7b7d7242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7b819d7fb64102bb9f3419cc10750d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa290ce9e3c49f8af3fdc79a48cb8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result = controller.predict_raw_text(raw_content,topk=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Title</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>pred_Department Name</th>\n",
       "      <th>pred_prob_Department Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>general . great shirt . this shirt is so comfo...</td>\n",
       "      <td>great shirt</td>\n",
       "      <td>general</td>\n",
       "      <td>[0, 15841, 479, 372, 6399, 479, 42, 6399, 16, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[Tops, Intimate, Trend]</td>\n",
       "      <td>[0.99450463, 0.0026445058, 0.0013354575]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text        Title   \n",
       "0  general . great shirt . this shirt is so comfo...  great shirt  \\\n",
       "\n",
       "  Division Name                                          input_ids   \n",
       "0       general  [0, 15841, 479, 372, 6399, 479, 42, 6399, 16, ...  \\\n",
       "\n",
       "                                     attention_mask     pred_Department Name   \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  [Tops, Intimate, Trend]  \\\n",
       "\n",
       "                  pred_prob_Department Name  \n",
       "0  [0.99450463, 0.0026445058, 0.0013354575]  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions, using only Tokenized DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load trained model\n",
    "\n",
    "trained_model = RobertaForSequenceClassification.from_pretrained('./sample_weights/model_progress',num_labels=6).to('cuda:0')\n",
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score]\n",
    "controller = ModelController(trained_model,metric_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Title', 'Review Text', 'Division Name', 'Department Name', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 18102\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Title', 'Review Text', 'Division Name', 'Department Name', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4526\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_ddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'Source', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 4780\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'Source', 'input_ids', 'token_type_ids', 'attention_mask', 'pred_L1', 'pred_prob_L1'],\n",
       "        num_rows: 447\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_ddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_label_name = 'L1'\n",
    "my_class_predefined = ['Buyer complained seller',\n",
    " 'Commercial',\n",
    " 'Delivery',\n",
    " 'Feature',\n",
    " 'Order/Item',\n",
    " 'Others',\n",
    " 'Payment',\n",
    " 'Return/Refund',\n",
    " 'Services',\n",
    " 'Shopee account']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/447 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_val = controller.predict_ddict(main_ddict,\n",
    "                                  ds_type='validation',\n",
    "                                  is_multilabel=False,\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  label_names = my_label_name,\n",
    "                                  class_names_predefined=my_class_predefined\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - Ch∆°i gam r·∫•t l√† l√°c</td>\n",
       "      <td>3</td>\n",
       "      <td>google play</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>0.837496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google play - Zq</td>\n",
       "      <td>5</td>\n",
       "      <td>google play</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.927602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non owned - L√†n s√≥ng k·ªπ thu·∫≠t s·ªë v√† s·ª± l·ª±a ch·ªç...</td>\n",
       "      <td>5</td>\n",
       "      <td>non owned</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.918241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google play - H√†ng qu·ªëc t·∫ø kh√¥ng c√≤n ship COD ...</td>\n",
       "      <td>6</td>\n",
       "      <td>google play</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.804539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - Qu√° t·ªá . Giao h√†ng ch·∫≠m nh∆∞ r√πa ...</td>\n",
       "      <td>2</td>\n",
       "      <td>google play</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.758327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label       Source   \n",
       "0                  google play - Ch∆°i gam r·∫•t l√† l√°c      3  google play  \\\n",
       "1                                   google play - Zq      5  google play   \n",
       "2  non owned - L√†n s√≥ng k·ªπ thu·∫≠t s·ªë v√† s·ª± l·ª±a ch·ªç...      5    non owned   \n",
       "3  google play - H√†ng qu·ªëc t·∫ø kh√¥ng c√≤n ship COD ...      6  google play   \n",
       "4  google play - Qu√° t·ªá . Giao h√†ng ch·∫≠m nh∆∞ r√πa ...      2  google play   \n",
       "\n",
       "      pred_L1  pred_prob_L1  \n",
       "0  Commercial      0.837496  \n",
       "1      Others      0.927602  \n",
       "2      Others      0.918241  \n",
       "3    Delivery      0.804539  \n",
       "4    Delivery      0.758327  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text', 'Source', 'input_ids', 'token_type_ids', 'attention_mask', 'pred_L1', 'pred_prob_L1'],\n",
       "        num_rows: 2269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ddict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be cumbersome to preprocess your test data the same way you preprocess your validation set, without the use of tdm (which stores the preprocess pipeline). In short, you need to produce the test datasetdict `test_ddict` containing processed `'input_ids', 'token_type_ids', 'attention_mask'`, then call\n",
    "\n",
    "```python\n",
    "df_results = controller.predict_ddict(ddict=test_ddict,\n",
    "                                      ds_type='test',\n",
    "                                      is_multilabel=False,\n",
    "                                      tokenizer=tokenizer,\n",
    "                                      label_names = my_label_name,\n",
    "                                      class_names_predefined=my_class_predefined     \n",
    "                                     )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experiment: Roberta Custom Single-Head Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "from that_nlp_library.models.roberta.classifiers import *\n",
    "from that_nlp_library.model_main import *\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will specify a (or a list) of GPUs for training\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train EnviBert using TDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend']]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdc.label_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(tdc.label_lists[0])\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our model and model controller. First, we will initialize the pretrained `body` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.roberta.modeling_roberta import RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='nguyenvulebinh/envibert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nguyenvulebinh/envibert were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "envibert_body = RobertaModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can define a simple class as the head for our classification task, something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassificationHead(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 config, # HuggingFace model configuration\n",
    "                 classifier_dropout=0.1, # Dropout ratio (for dropout layer right before the last nn.Linear)\n",
    "                 num_labels=None, # Number of label output. Every classification class must have this exact variable\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(classifier_dropout)\n",
    "        self.out_proj = torch.nn.Linear(config.hidden_size, num_labels)\n",
    "    def forward(self, inp, **kwargs):\n",
    "        x = inp\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading body weights. This assumes the body is the very first first-layer block of your custom architecture\n"
     ]
    }
   ],
   "source": [
    "_model_kwargs={\n",
    "    # overall model hyperparams\n",
    "    'is_multilabel':tdm.is_multilabel, # False\n",
    "    'is_multihead':tdm.is_multihead, # False\n",
    "    'head_class_sizes':num_classes,\n",
    "    'head_class': SimpleClassificationHead,\n",
    "    # classfication head hyperparams\n",
    "    'classifier_dropout':0.1 \n",
    "}\n",
    "\n",
    "model = model_init_classification(model_class = RobertaBaseForSequenceClassification,\n",
    "                                  cpoint_path = 'nguyenvulebinh/envibert', \n",
    "                                  output_hidden_states=False, # since we are not using 'hidden layer contatenation' technique\n",
    "                                  seed=42,\n",
    "                                  body_model=envibert_body,\n",
    "                                  model_kwargs = _model_kwargs)\n",
    "\n",
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score] # we will use both f1_macro and accuracy score as metrics\n",
    "controller = ModelController(model,tdm,metric_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can start training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1194' max='1194' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1194/1194 01:04, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score L1</th>\n",
       "      <th>Accuracy Score L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.059704</td>\n",
       "      <td>0.350748</td>\n",
       "      <td>0.677852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.007712</td>\n",
       "      <td>0.462641</td>\n",
       "      <td>0.697987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 8e-5\n",
    "bs=4\n",
    "wd=0.01\n",
    "epochs= 2\n",
    "\n",
    "controller.fit(epochs,lr,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=compute_metrics_classification,\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging your training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can log your training using HuggingFace:\n",
    "\n",
    "- Supported platforms are \"azure_ml\", \"comet_ml\", \"mlflow\", \"neptune\", \"tensorboard\",\"clearml\" and \"wandb\"\n",
    "\n",
    "- References:\n",
    "\n",
    "    - https://huggingface.co/docs/transformers/v4.28.0/en/main_classes/trainer#transformers.TrainingArguments\n",
    "    \n",
    "    - https://docs.wandb.ai/guides/integrations/huggingface#:~:text=Logging%20your%20Hugging%20Face%20model,every%20save_steps%20in%20the%20TrainingArguments%20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "controller.fit(epochs,lr,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=compute_metrics_classification,\n",
    "               hf_report_to='wandb'\n",
    "              )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save your model weights at the end of your training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "controller.trainer.model.save_pretrained('./sample_weights/model_progress')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can save your weights at every epochs during your training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "controller.fit(epochs,lr,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=True,\n",
    "               o_dir='sample_weights',\n",
    "               compute_metrics=compute_metrics_classification,\n",
    "              )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train EnviBert with tokenized DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part assumes you already have your tokenized datasetdict. You must have your tokenizer as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaTokenizer(name_or_path='', vocab_size=59993, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that your DatasetDict must contain tokens besides raw text (which typically includes 'input_ids', 'token_type_ids', 'attention_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'Source', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 4780\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'Source', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 447\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_ddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='nguyenvulebinh/envibert'\n",
    "_model_kwargs={\n",
    "    # overall model hyperparams\n",
    "    'is_multilabel':False, # False\n",
    "    'is_multihead':False, # False\n",
    "    'head_class_sizes':num_classes,\n",
    "    'head_class': SimpleClassificationHead,\n",
    "    # classfication head hyperparams\n",
    "    'classifier_dropout':0.1 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envibert_body = RobertaModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nguyenvulebinh/envibert were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading body weights. This assumes the body is the very first first-layer block of your custom architecture\n"
     ]
    }
   ],
   "source": [
    "model = model_init_classification(model_class = RobertaBaseForSequenceClassification,\n",
    "                                  cpoint_path = 'nguyenvulebinh/envibert', \n",
    "                                  output_hidden_states=False, # since we are not using 'hidden layer contatenation' technique\n",
    "                                  seed=42,\n",
    "                                  body_model=envibert_body,\n",
    "                                  model_kwargs = _model_kwargs)\n",
    "\n",
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score] # we will use both f1_macro and accuracy score as metrics\n",
    "controller = ModelController(model,\n",
    "                             metric_funcs=metric_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1194' max='1194' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1194/1194 01:06, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score L1</th>\n",
       "      <th>Accuracy Score L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.059704</td>\n",
       "      <td>0.350748</td>\n",
       "      <td>0.677852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.007712</td>\n",
       "      <td>0.462641</td>\n",
       "      <td>0.697987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 8e-5\n",
    "bs=4\n",
    "wd=0.01\n",
    "epochs= 2\n",
    "\n",
    "controller.fit(epochs,lr,\n",
    "               ddict=main_ddict, # Put in your tokenized datasetdict here\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=compute_metrics_classification,\n",
    "               tokenizer=tokenizer,\n",
    "               label_names='L1'\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.trainer.model.save_pretrained('./sample_weights/model_progress')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using trained model, using TDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_multilabel': False,\n",
       " 'is_multihead': False,\n",
       " 'head_class_sizes': 10,\n",
       " 'head_class': __main__.SimpleClassificationHead,\n",
       " 'classifier_dropout': 0.1}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_model_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sample_weights/model_progress were not used when initializing RobertaBaseForSequenceClassification: ['body_model.pooler.dense.weight', 'body_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaBaseForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaBaseForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "trained_model = model_init_classification(model_class = RobertaBaseForSequenceClassification,\n",
    "                                          cpoint_path = Path('./sample_weights/model_progress'), \n",
    "                                          output_hidden_states=False,\n",
    "                                          seed=42,\n",
    "                                          model_kwargs = _model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaBaseForSequenceClassification(\n",
       "  (body_model): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(59993, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classification_head): SimpleClassificationHead(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score] # we will use both f1_macro and accuracy score as metrics\n",
    "controller = ModelController(trained_model,tdm,metric_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Train/Validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction on all validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/447 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_val = controller.predict_ddict(ds_type='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - Ch∆°i gam r·∫•t l√† l√°c</td>\n",
       "      <td>3</td>\n",
       "      <td>google play</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>0.837496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google play - Zq</td>\n",
       "      <td>5</td>\n",
       "      <td>google play</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.927602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non owned - L√†n s√≥ng k·ªπ thu·∫≠t s·ªë v√† s·ª± l·ª±a ch·ªç...</td>\n",
       "      <td>5</td>\n",
       "      <td>non owned</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.918241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google play - H√†ng qu·ªëc t·∫ø kh√¥ng c√≤n ship COD ...</td>\n",
       "      <td>6</td>\n",
       "      <td>google play</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.804539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - Qu√° t·ªá . Giao h√†ng ch·∫≠m nh∆∞ r√πa ...</td>\n",
       "      <td>2</td>\n",
       "      <td>google play</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.758327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label       Source   \n",
       "0                  google play - Ch∆°i gam r·∫•t l√† l√°c      3  google play  \\\n",
       "1                                   google play - Zq      5  google play   \n",
       "2  non owned - L√†n s√≥ng k·ªπ thu·∫≠t s·ªë v√† s·ª± l·ª±a ch·ªç...      5    non owned   \n",
       "3  google play - H√†ng qu·ªëc t·∫ø kh√¥ng c√≤n ship COD ...      6  google play   \n",
       "4  google play - Qu√° t·ªá . Giao h√†ng ch·∫≠m nh∆∞ r√πa ...      2  google play   \n",
       "\n",
       "      pred_L1  pred_prob_L1  \n",
       "0  Commercial      0.837496  \n",
       "1      Others      0.927602  \n",
       "2      Others      0.918241  \n",
       "3    Delivery      0.804539  \n",
       "4    Delivery      0.758327  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the label index to string, we can use the ```label_lists``` attribute of tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - Ch∆°i gam r·∫•t l√† l√°c</td>\n",
       "      <td>Feature</td>\n",
       "      <td>google play</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>0.837496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google play - Zq</td>\n",
       "      <td>Others</td>\n",
       "      <td>google play</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.927602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non owned - L√†n s√≥ng k·ªπ thu·∫≠t s·ªë v√† s·ª± l·ª±a ch·ªç...</td>\n",
       "      <td>Others</td>\n",
       "      <td>non owned</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.918241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google play - H√†ng qu·ªëc t·∫ø kh√¥ng c√≤n ship COD ...</td>\n",
       "      <td>Payment</td>\n",
       "      <td>google play</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.804539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - Qu√° t·ªá . Giao h√†ng ch·∫≠m nh∆∞ r√πa ...</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>google play</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.758327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label       Source   \n",
       "0                  google play - Ch∆°i gam r·∫•t l√† l√°c   Feature  google play  \\\n",
       "1                                   google play - Zq    Others  google play   \n",
       "2  non owned - L√†n s√≥ng k·ªπ thu·∫≠t s·ªë v√† s·ª± l·ª±a ch·ªç...    Others    non owned   \n",
       "3  google play - H√†ng qu·ªëc t·∫ø kh√¥ng c√≤n ship COD ...   Payment  google play   \n",
       "4  google play - Qu√° t·ªá . Giao h√†ng ch·∫≠m nh∆∞ r√πa ...  Delivery  google play   \n",
       "\n",
       "      pred_L1  pred_prob_L1  \n",
       "0  Commercial      0.837496  \n",
       "1      Others      0.927602  \n",
       "2      Others      0.918241  \n",
       "3    Delivery      0.804539  \n",
       "4    Delivery      0.758327  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['label']= df_val['label'].apply(lambda x: tdm.label_lists[0][x]).values\n",
    "\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try to get your metric to see if it matches your last traing epoch's above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4634417008698494"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_val.label,df_val.pred_L1,average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also make predictions on all training set, by changing argument ```ds_type``` to \"train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go through details on how to make a prediction on a completely new and raw dataset using our trained model. For now, let's reuse the sample csv and pretend it's our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Input Validation Precheck -----\n",
      "DataFrame contains duplicated values!\n",
      "-----> Number of duplications: 16 rows\n"
     ]
    }
   ],
   "source": [
    "df_test = TextDataMain.from_csv(Path('sample_data')/'sample_large.csv',return_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove all the labels and unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = df_test['L1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['L1','L2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google Play</td>\n",
       "      <td>App ncc l√∫c n√†o cx lag ƒë∆°, ph·∫ßn t√¨m ki·∫øm th√¨ v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non Owned</td>\n",
       "      <td>..‚ùóÔ∏è G√ìC THANH L√ù T√≠nh ra r·∫ª h∆°n c·∫£ mua #Shope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google Play</td>\n",
       "      <td>M·∫Øc g√¨ ng∆∞·ªùi ta ƒë·∫∑t h√†ng to√†n l·ªói üòÉ????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owned</td>\n",
       "      <td>#GhienShopeePayawardT8 Khi b·∫°n ch∆°i shopee qu√°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google Play</td>\n",
       "      <td>R·∫•t b·ª©c x√∫c khi d√πng . m√£ gi·∫£m gi√° ng∆∞·ªùi d√πng ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source                                            Content\n",
       "0  Google Play  App ncc l√∫c n√†o cx lag ƒë∆°, ph·∫ßn t√¨m ki·∫øm th√¨ v...\n",
       "1    Non Owned  ..‚ùóÔ∏è G√ìC THANH L√ù T√≠nh ra r·∫ª h∆°n c·∫£ mua #Shope...\n",
       "2  Google Play            M·∫Øc g√¨ ng∆∞·ªùi ta ƒë·∫∑t h√†ng to√†n l·ªói üòÉ????\n",
       "3        Owned  #GhienShopeePayawardT8 Khi b·∫°n ch∆°i shopee qu√°...\n",
       "4  Google Play  R·∫•t b·ª©c x√∫c khi d√πng . m√£ gi·∫£m gi√° ng∆∞·ªùi d√πng ..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a DatasetDict for this test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Getting Test Set --------------------\n",
      "----- Input Validation Precheck -----\n",
      "DataFrame contains duplicated values!\n",
      "-----> Number of duplications: 19 rows\n",
      "-------------------- Start Test Set Transformation --------------------\n",
      "----- Metadata Simple Processing & Concatenating to Main Content -----\n",
      "-------------------- Text Transformation --------------------\n",
      "----- text_normalize -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2269/2269 [00:00<00:00, 3954.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Test Leak Checking --------------------\n",
      "- Before leak check\n",
      "Size: 2269\n",
      "- After leak check\n",
      "Size: 0\n",
      "- Number of rows leaked: 2269, or 100.00% of the original validation (or test) data\n",
      "-------------------- Construct DatasetDict --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ddict = tdm.get_test_datasetdict_from_df(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the ***Leak Check*** we did in TextDataMain? Our ```df_test``` only has 70 rows, and it also shows that 70 rows of our data is leaked (100%), which is correct because this test dataset is actually a small sample of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text', 'Source', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ddict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test data has been processed + transformed (but not augmented) the same way as the validation set. Now we can start making the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "controller = ModelController(trained_model,tdm)\n",
    "df_result = controller.predict_ddict(ddict=test_ddict,ds_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - App ncc l√∫c n√†o cx lag ƒë∆° , ph·∫ßn...</td>\n",
       "      <td>google play</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.878221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non owned - .. ‚ùó Ô∏è G√ìC THANH L√ù T√≠nh ra r·∫ª h∆°n...</td>\n",
       "      <td>non owned</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.930981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google play - M·∫Øc g√¨ ng∆∞·ªùi ta ƒë·∫∑t h√†ng to√†n l·ªó...</td>\n",
       "      <td>google play</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.849374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owned - # GhienShopeePayawardT8 Khi b·∫°n ch∆°i s...</td>\n",
       "      <td>owned</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>0.915552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - R·∫•t b·ª©c x√∫c khi d√πng . m√£ gi·∫£m g...</td>\n",
       "      <td>google play</td>\n",
       "      <td>Shopee account</td>\n",
       "      <td>0.571471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       Source   \n",
       "0  google play - App ncc l√∫c n√†o cx lag ƒë∆° , ph·∫ßn...  google play  \\\n",
       "1  non owned - .. ‚ùó Ô∏è G√ìC THANH L√ù T√≠nh ra r·∫ª h∆°n...    non owned   \n",
       "2  google play - M·∫Øc g√¨ ng∆∞·ªùi ta ƒë·∫∑t h√†ng to√†n l·ªó...  google play   \n",
       "3  owned - # GhienShopeePayawardT8 Khi b·∫°n ch∆°i s...        owned   \n",
       "4  google play - R·∫•t b·ª©c x√∫c khi d√πng . m√£ gi·∫£m g...  google play   \n",
       "\n",
       "          pred_L1  pred_prob_L1  \n",
       "0         Feature      0.878221  \n",
       "1          Others      0.930981  \n",
       "2         Feature      0.849374  \n",
       "3      Commercial      0.915552  \n",
       "4  Shopee account      0.571471  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly check the f1 score to make sure everything works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5303012712104336"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(true_label,df_result.pred_L1,average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are getting the predictions on the entire training+validation set, the F1 score is expected to be slightly higher than validation's F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even predict top k results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "      <th>pred_L1_top1</th>\n",
       "      <th>pred_L1_top2</th>\n",
       "      <th>pred_L1_top3</th>\n",
       "      <th>pred_prob_L1_top1</th>\n",
       "      <th>pred_prob_L1_top2</th>\n",
       "      <th>pred_prob_L1_top3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - App ncc l√∫c n√†o cx lag ƒë∆° , ph·∫ßn...</td>\n",
       "      <td>google play</td>\n",
       "      <td>[3, 5, 9]</td>\n",
       "      <td>[0.87822074, 0.023822138, 0.02159522]</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Others</td>\n",
       "      <td>Shopee account</td>\n",
       "      <td>0.878221</td>\n",
       "      <td>0.023822</td>\n",
       "      <td>0.021595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non owned - .. ‚ùó Ô∏è G√ìC THANH L√ù T√≠nh ra r·∫ª h∆°n...</td>\n",
       "      <td>non owned</td>\n",
       "      <td>[5, 1, 0]</td>\n",
       "      <td>[0.9309808, 0.015578598, 0.009805982]</td>\n",
       "      <td>Others</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Buyer complained seller</td>\n",
       "      <td>0.930981</td>\n",
       "      <td>0.015579</td>\n",
       "      <td>0.009806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google play - M·∫Øc g√¨ ng∆∞·ªùi ta ƒë·∫∑t h√†ng to√†n l·ªó...</td>\n",
       "      <td>google play</td>\n",
       "      <td>[3, 5, 9]</td>\n",
       "      <td>[0.8493735, 0.050054528, 0.021759989]</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Others</td>\n",
       "      <td>Shopee account</td>\n",
       "      <td>0.849374</td>\n",
       "      <td>0.050055</td>\n",
       "      <td>0.021760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owned - # GhienShopeePayawardT8 Khi b·∫°n ch∆°i s...</td>\n",
       "      <td>owned</td>\n",
       "      <td>[1, 6, 7]</td>\n",
       "      <td>[0.9155516, 0.01255093, 0.010521941]</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Payment</td>\n",
       "      <td>Return/Refund</td>\n",
       "      <td>0.915552</td>\n",
       "      <td>0.012551</td>\n",
       "      <td>0.010522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - R·∫•t b·ª©c x√∫c khi d√πng . m√£ gi·∫£m g...</td>\n",
       "      <td>google play</td>\n",
       "      <td>[9, 3, 1]</td>\n",
       "      <td>[0.57147133, 0.25687057, 0.03061041]</td>\n",
       "      <td>Shopee account</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>0.571471</td>\n",
       "      <td>0.256871</td>\n",
       "      <td>0.030610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       Source    pred_L1   \n",
       "0  google play - App ncc l√∫c n√†o cx lag ƒë∆° , ph·∫ßn...  google play  [3, 5, 9]  \\\n",
       "1  non owned - .. ‚ùó Ô∏è G√ìC THANH L√ù T√≠nh ra r·∫ª h∆°n...    non owned  [5, 1, 0]   \n",
       "2  google play - M·∫Øc g√¨ ng∆∞·ªùi ta ƒë·∫∑t h√†ng to√†n l·ªó...  google play  [3, 5, 9]   \n",
       "3  owned - # GhienShopeePayawardT8 Khi b·∫°n ch∆°i s...        owned  [1, 6, 7]   \n",
       "4  google play - R·∫•t b·ª©c x√∫c khi d√πng . m√£ gi·∫£m g...  google play  [9, 3, 1]   \n",
       "\n",
       "                            pred_prob_L1    pred_L1_top1 pred_L1_top2   \n",
       "0  [0.87822074, 0.023822138, 0.02159522]         Feature       Others  \\\n",
       "1  [0.9309808, 0.015578598, 0.009805982]          Others   Commercial   \n",
       "2  [0.8493735, 0.050054528, 0.021759989]         Feature       Others   \n",
       "3   [0.9155516, 0.01255093, 0.010521941]      Commercial      Payment   \n",
       "4   [0.57147133, 0.25687057, 0.03061041]  Shopee account      Feature   \n",
       "\n",
       "              pred_L1_top3  pred_prob_L1_top1  pred_prob_L1_top2   \n",
       "0           Shopee account           0.878221           0.023822  \\\n",
       "1  Buyer complained seller           0.930981           0.015579   \n",
       "2           Shopee account           0.849374           0.050055   \n",
       "3            Return/Refund           0.915552           0.012551   \n",
       "4               Commercial           0.571471           0.256871   \n",
       "\n",
       "   pred_prob_L1_top3  \n",
       "0           0.021595  \n",
       "1           0.009806  \n",
       "2           0.021760  \n",
       "3           0.010522  \n",
       "4           0.030610  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = controller.predict_ddict(ddict=test_ddict,ds_type='test',topk=3)\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want to make a prediction on a small amount of data (single sentence, or a few sentences), we can use `ModelController.predict_raw_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have some metadatas, we need to define a dictionary (to imitate a DatasetDict)\n",
    "raw_content={\n",
    "    'Source': 'Google play',\n",
    "    'Content':'T√¥i kh√¥ng th√≠ch Shopee.T·∫°i v√¨ d√πng app r·∫•t ch·∫≠m,lag banh nh√† l·∫ßu, th·∫≠m ch√≠ log in c√≤n kh√¥ng ƒëc'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't use metadata, we can use something like this: \n",
    "\n",
    "```raw_content='T√¥i kh√¥ng th√≠ch Shopee.T·∫°i v√¨ d√πng app r·∫•t ch·∫≠m,lag banh nh√† l·∫ßu, th·∫≠m ch√≠ log in c√≤n kh√¥ng ƒëc'```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 4718.00it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - T√¥i kh√¥ng th√≠ch Shopee . T·∫°i v√¨ ...</td>\n",
       "      <td>google play</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.876843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       Source  pred_L1   \n",
       "0  google play - T√¥i kh√¥ng th√≠ch Shopee . T·∫°i v√¨ ...  google play  Feature  \\\n",
       "\n",
       "   pred_prob_L1  \n",
       "0      0.876843  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = controller.predict_raw_text(raw_content,topk=1)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using trained model, using tokenized DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "model_name='nguyenvulebinh/envibert'\n",
    "_model_kwargs={\n",
    "    # overall model hyperparams\n",
    "    'is_multilabel':False, # False\n",
    "    'is_multihead':False, # False\n",
    "    'head_class_sizes':num_classes,\n",
    "    'head_class': SimpleClassificationHead,\n",
    "    # classfication head hyperparams\n",
    "    'classifier_dropout':0.1 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sample_weights/model_progress were not used when initializing RobertaBaseForSequenceClassification: ['body_model.pooler.dense.weight', 'body_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaBaseForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaBaseForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "trained_model = model_init_classification(model_class = RobertaBaseForSequenceClassification,\n",
    "                                          cpoint_path = Path('./sample_weights/model_progress'), \n",
    "                                          output_hidden_states=False,\n",
    "                                          seed=42,\n",
    "                                          model_kwargs = _model_kwargs)\n",
    "\n",
    "\n",
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score]\n",
    "controller = ModelController(trained_model,metric_funcs) # notice that we don't use tdm here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'Source', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 4780\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'Source', 'input_ids', 'token_type_ids', 'attention_mask', 'pred_L1', 'pred_prob_L1'],\n",
       "        num_rows: 447\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_ddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_label_name = 'L1'\n",
    "my_class_predefined = ['Buyer complained seller',\n",
    " 'Commercial',\n",
    " 'Delivery',\n",
    " 'Feature',\n",
    " 'Order/Item',\n",
    " 'Others',\n",
    " 'Payment',\n",
    " 'Return/Refund',\n",
    " 'Services',\n",
    " 'Shopee account']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/447 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_val = controller.predict_ddict(main_ddict,\n",
    "                                  ds_type='validation',\n",
    "                                  is_multilabel=False,\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  label_names = my_label_name,\n",
    "                                  class_names_predefined=my_class_predefined\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - Ch∆°i gam r·∫•t l√† l√°c</td>\n",
       "      <td>3</td>\n",
       "      <td>google play</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>0.837496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google play - Zq</td>\n",
       "      <td>5</td>\n",
       "      <td>google play</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.927602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non owned - L√†n s√≥ng k·ªπ thu·∫≠t s·ªë v√† s·ª± l·ª±a ch·ªç...</td>\n",
       "      <td>5</td>\n",
       "      <td>non owned</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.918241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google play - H√†ng qu·ªëc t·∫ø kh√¥ng c√≤n ship COD ...</td>\n",
       "      <td>6</td>\n",
       "      <td>google play</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.804539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - Qu√° t·ªá . Giao h√†ng ch·∫≠m nh∆∞ r√πa ...</td>\n",
       "      <td>2</td>\n",
       "      <td>google play</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.758327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label       Source   \n",
       "0                  google play - Ch∆°i gam r·∫•t l√† l√°c      3  google play  \\\n",
       "1                                   google play - Zq      5  google play   \n",
       "2  non owned - L√†n s√≥ng k·ªπ thu·∫≠t s·ªë v√† s·ª± l·ª±a ch·ªç...      5    non owned   \n",
       "3  google play - H√†ng qu·ªëc t·∫ø kh√¥ng c√≤n ship COD ...      6  google play   \n",
       "4  google play - Qu√° t·ªá . Giao h√†ng ch·∫≠m nh∆∞ r√πa ...      2  google play   \n",
       "\n",
       "      pred_L1  pred_prob_L1  \n",
       "0  Commercial      0.837496  \n",
       "1      Others      0.927602  \n",
       "2      Others      0.918241  \n",
       "3    Delivery      0.804539  \n",
       "4    Delivery      0.758327  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text', 'Source', 'input_ids', 'token_type_ids', 'attention_mask', 'pred_L1', 'pred_prob_L1'],\n",
       "        num_rows: 2269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ddict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be cumbersome to preprocess your test data the same way you preprocess your validation set, without the use of tdm (which stores the preprocess pipeline). In short, you need to produce the test datasetdict `test_ddict` containing processed `'input_ids', 'token_type_ids', 'attention_mask'`, then call\n",
    "\n",
    "```python\n",
    "df_results = controller.predict_ddict(ddict=test_ddict,\n",
    "                                      ds_type='test',\n",
    "                                      is_multilabel=False,\n",
    "                                      tokenizer=tokenizer,\n",
    "                                      label_names = my_label_name,\n",
    "                                      class_names_predefined=my_class_predefined     \n",
    "                                     )\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
