{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Controller Tutorial: EnviBert model with Deep Hierarchical Classification\n",
    "\n",
    "> This notebook contains some example of how to use the EnviBert-based models in this NLP library\n",
    "\n",
    "- skip_showdoc: true\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will walk through other cases of classification: multi-head and multi-label. Since we will showcase the capabiilty of this label in these cases, there won't be as detailed as [this tutorial](https://anhquan0412.github.io/that-nlp-library/model_main_envibert.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from that_nlp_library.text_transformation import *\n",
    "from that_nlp_library.text_augmentation import *\n",
    "from that_nlp_library.text_main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from underthesea import text_normalize\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from importlib.machinery import SourceFileLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some necessary text augmentations and text transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For Text Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_tfms=[text_normalize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For Text Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_nonown_tfm = partial(sampling_with_condition,query='Source==\"non owned\"',frac=0.5,seed=42,apply_to_all=False)\n",
    "over_nonown_tfm.__name__ = 'Oversampling Non Owned'\n",
    "\n",
    "over_own_tfm = partial(sampling_with_condition,query='Source==\"owned\"',frac=2,seed=42,apply_to_all=False)\n",
    "over_own_tfm.__name__ = 'Oversampling Owned'\n",
    "\n",
    "over_hc_tfm = partial(sampling_with_condition,query='Source==\"hc search\"',frac=2.5,seed=42,apply_to_all=False)\n",
    "over_hc_tfm.__name__ = 'Oversampling HC search'\n",
    "\n",
    "remove_accent_tfm = partial(remove_vnmese_accent,frac=1,seed=42,apply_to_all=True)\n",
    "remove_accent_tfm.__name__ = 'Add No-Accent Text'\n",
    "\n",
    "aug_tfms = [over_nonown_tfm,over_own_tfm,over_hc_tfm,remove_accent_tfm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load and preprocess our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('secret_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Input Validation Precheck -----\n",
      "DataFrame contains missing values!\n",
      "-----> List of columns and the number of missing values for each\n",
      "is_valid    65804\n",
      "dtype: int64\n",
      "DataFrame contains duplicated values!\n",
      "-----> Number of duplications: 7 rows\n"
     ]
    }
   ],
   "source": [
    "df = TextDataMain.from_csv(DATA_PATH/'buyer_listening_with_all_raw_data_w2223.csv',return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Group</th>\n",
       "      <th>Source</th>\n",
       "      <th>Content</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>L4</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>T·∫°i sao c·ª© hi·ªán th√¥ng b√°o</td>\n",
       "      <td>Services</td>\n",
       "      <td>Shopee communication channels</td>\n",
       "      <td>Annoying pop-up ads</td>\n",
       "      <td>Non-tech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>Mlem</td>\n",
       "      <td>Others</td>\n",
       "      <td>Cannot defined</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>1 s·ªë s·∫£n ph·∫©m trong gi·ªè h√†ng v·ª´a ƒëc c·∫≠p nh·∫≠t t...</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Cart &amp; Order</td>\n",
       "      <td>Cart issues/suggestions</td>\n",
       "      <td>Tech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Week        Group       Source   \n",
       "0   1.0  Google Play  Google Play  \\\n",
       "1   1.0  Google Play  Google Play   \n",
       "2   1.0  Google Play  Google Play   \n",
       "\n",
       "                                             Content        L1   \n",
       "0                          T·∫°i sao c·ª© hi·ªán th√¥ng b√°o  Services  \\\n",
       "1                                               Mlem    Others   \n",
       "2  1 s·ªë s·∫£n ph·∫©m trong gi·ªè h√†ng v·ª´a ƒëc c·∫≠p nh·∫≠t t...   Feature   \n",
       "\n",
       "                              L2                       L3        L4  is_valid   \n",
       "0  Shopee communication channels      Annoying pop-up ads  Non-tech       NaN  \\\n",
       "1                 Cannot defined                        -         -       NaN   \n",
       "2                   Cart & Order  Cart issues/suggestions      Tech       NaN   \n",
       "\n",
       "   iteration  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick preprocess of data and train/validation split. Due to custom logic, we will sample our data here instead of using the `train_ratio` from the `to_datasetdict` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rare = df[df.L2.isin(['Chatbot', 'Commercial Others'])].copy()\n",
    "\n",
    "df_final = pd.concat([df.query('iteration==1').sample(500,random_state=42),\n",
    "                      df.query('iteration>=7 & iteration<13').sample(1200,random_state=42),\n",
    "                      df_rare,\n",
    "                      df.query('iteration>=13'),\n",
    "                     ],axis=0).reset_index(drop=True)\n",
    "\n",
    "val_idxs = df_final[df_final.iteration>=13].index.values # from week 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Input Validation Precheck -----\n",
      "DataFrame contains missing values!\n",
      "-----> List of columns and the number of missing values for each\n",
      "is_valid    498\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tdm = TextDataMain(df_final,\n",
    "                    main_content='Content',\n",
    "                    metadatas='Source',\n",
    "                    label_names=['L1','L2'],\n",
    "                    val_ratio=val_idxs,\n",
    "                    split_cols='L2',\n",
    "                    content_tfms = txt_tfms,\n",
    "                    aug_tfms = aug_tfms,\n",
    "                    process_metadatas=True,\n",
    "                    seed=42,\n",
    "                    shuffle_trn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our tokenizer for EnviBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir=Path('./envibert_tokenizer')\n",
    "tokenizer = SourceFileLoader(\"envibert.tokenizer\", \n",
    "                             str(cache_dir/'envibert_tokenizer.py')).load_module().RobertaTokenizer(cache_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our DatasetDict from TextDataMain (as our `ModelController` class can also work with DatasetDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start Main Text Processing --------------------\n",
      "----- Metadata Simple Processing & Concatenating to Main Content -----\n",
      "----- Label Encoding -----\n",
      "-------------------- Text Transformation --------------------\n",
      "----- text_normalize -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6649/6649 [00:01<00:00, 3560.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train Test Split --------------------\n",
      "Previous Validation Percentage: 74.101%\n",
      "- Before leak check\n",
      "Size: 4927\n",
      "- After leak check\n",
      "Size: 4885\n",
      "- Number of rows leaked: 42, or 0.85% of the original validation (or test) data\n",
      "Current Validation Percentage: 73.47%\n",
      "-------------------- Text Augmentation --------------------\n",
      "Train data size before augmentation: 1764\n",
      "----- Oversampling Non Owned -----\n",
      "Train data size after THIS augmentation: 2229\n",
      "----- Oversampling Owned -----\n",
      "Train data size after THIS augmentation: 2789\n",
      "----- Oversampling HC search -----\n",
      "Train data size after THIS augmentation: 2904\n",
      "----- Add No-Accent Text -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2904/2904 [00:00<00:00, 10469.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size after THIS augmentation: 5808\n",
      "Train data size after ALL augmentation: 5808\n",
      "-------------------- Map Tokenize Function --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5808 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4885 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main_ddict= tdm.to_datasetdict(tokenizer,\n",
    "                               max_length=512,\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'Source', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 5808\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'Source', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 4885\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_ddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 12], [5, 12], [5, 12], [2, 23], [3, 5]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_ddict['validation']['label'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experiment: EnviBert Multi-Head Classification (with Hidden Layer Concatenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from that_nlp_library.models.roberta.deep_hierarchical_classifiers import *\n",
    "from that_nlp_library.model_main import *\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import os\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will specify a (or a list) of GPUs for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build DHC Conditional Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = tdm.df[tdm.label_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  L1  L2\n",
       "0  1  59\n",
       "1  5  12\n",
       "2  1  59\n",
       "3  1  43\n",
       "4  5  12"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhc_mask = build_DHC_conditional_mask(df_labels,*tdm.label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 66])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhc_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the first row of the mask (for level 1 label \"Buyer Complained Seller\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhc_mask[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing the first portion for level 2, show string for True mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer service (didn't respond/impolite)\n",
      "Illegal/counterfeit products\n",
      "Product description\n",
      "Product quality\n",
      "Sellers cancelled order without any advanced notice/reason\n",
      "Sellers cheated Buyers (Sellers tried to reach me outside of Shopee App)\n",
      "Sellers packed fake orders\n"
     ]
    }
   ],
   "source": [
    "for i in torch.where(dhc_mask[0]==1)[0]:\n",
    "    print(tdm.label_lists[1][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train EnviBert (with hidden layer concatenation), using TDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nguyenvulebinh/envibert were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name='nguyenvulebinh/envibert'\n",
    "envibert_body = RobertaModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading body weights. This assumes the body is the very first first-layer block of your custom architecture\n"
     ]
    }
   ],
   "source": [
    "_model_kwargs={\n",
    "    'dhc_mask':dhc_mask,\n",
    "    'classifier_dropout':0.1,\n",
    "    'last_hidden_size':768,  \n",
    "    'linear_l1_size':389,\n",
    "    'linear_l2_size':417,\n",
    "    'lloss_weight':1.0,\n",
    "    'dloss_weight':0.8,\n",
    "    'layer2concat':4,\n",
    "}\n",
    "\n",
    "model = model_init_classification(model_class = RobertaHSCDHCSequenceClassification,\n",
    "                                  cpoint_path = model_name, \n",
    "                                  output_hidden_states=True, # since we are not using 'hidden layer contatenation' technique\n",
    "                                  seed=42,\n",
    "                                  body_model=envibert_body,\n",
    "                                  model_kwargs = _model_kwargs)\n",
    "\n",
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score]\n",
    "controller = ModelController(model,tdm,metric_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can start training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2904' max='2904' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2904/2904 03:21, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score L1</th>\n",
       "      <th>Accuracy Score L1</th>\n",
       "      <th>F1 Score L2</th>\n",
       "      <th>Accuracy Score L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>9.726516</td>\n",
       "      <td>0.240784</td>\n",
       "      <td>0.536540</td>\n",
       "      <td>0.032214</td>\n",
       "      <td>0.232958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.853000</td>\n",
       "      <td>9.363424</td>\n",
       "      <td>0.409587</td>\n",
       "      <td>0.610645</td>\n",
       "      <td>0.067087</td>\n",
       "      <td>0.328147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.853000</td>\n",
       "      <td>9.608892</td>\n",
       "      <td>0.463691</td>\n",
       "      <td>0.668987</td>\n",
       "      <td>0.092133</td>\n",
       "      <td>0.390993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.093800</td>\n",
       "      <td>9.744572</td>\n",
       "      <td>0.473580</td>\n",
       "      <td>0.663664</td>\n",
       "      <td>0.099278</td>\n",
       "      <td>0.415353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 9e-5\n",
    "bs=4\n",
    "wd=0.01\n",
    "epochs= 4\n",
    "\n",
    "controller.fit(epochs,lr,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=compute_metrics_separate_singleheads,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.trainer.model.save_pretrained('./sample_weights/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using trained model, using TDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dhc_mask': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.]]),\n",
       " 'classifier_dropout': 0.1,\n",
       " 'last_hidden_size': 768,\n",
       " 'linear_l1_size': 389,\n",
       " 'linear_l2_size': 417,\n",
       " 'lloss_weight': 1.0,\n",
       " 'dloss_weight': 0.8,\n",
       " 'layer2concat': 4}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_model_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sample_weights/my_model were not used when initializing RobertaHSCDHCSequenceClassification: ['body_model.pooler.dense.weight', 'body_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaHSCDHCSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaHSCDHCSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "trained_model = model_init_classification(model_class = RobertaHSCDHCSequenceClassification,\n",
    "                                          cpoint_path = Path('./sample_weights/my_model'), \n",
    "                                          output_hidden_states=True,\n",
    "                                          seed=42,\n",
    "                                          model_kwargs = _model_kwargs)\n",
    "\n",
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score]\n",
    "controller = ModelController(trained_model,tdm,metric_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Train/Validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction on all validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4885 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_val = controller.predict_ddict(ds_type='validation',is_dhc=True,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "      <th>pred_L2</th>\n",
       "      <th>pred_prob_L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - lam phien</td>\n",
       "      <td>[5, 12]</td>\n",
       "      <td>google play</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.880263</td>\n",
       "      <td>App performance</td>\n",
       "      <td>0.696242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google play - .. t . √Ä m√† h·ªç n·ªØ ∆∞u m</td>\n",
       "      <td>[5, 12]</td>\n",
       "      <td>google play</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.781973</td>\n",
       "      <td>App performance</td>\n",
       "      <td>0.684697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google play - Cc l√πa dao</td>\n",
       "      <td>[5, 12]</td>\n",
       "      <td>google play</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.986321</td>\n",
       "      <td>Cannot defined</td>\n",
       "      <td>0.979061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google play - M·∫∑t h√†ng sp m√¨nh ƒë·ªÅu nh·ª° v·ªõi Gia...</td>\n",
       "      <td>[2, 23]</td>\n",
       "      <td>google play</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.910066</td>\n",
       "      <td>Delivery time</td>\n",
       "      <td>0.616661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - Ch∆∞a t·ªëi ∆∞u t·ªët cho Android Oppo...</td>\n",
       "      <td>[3, 5]</td>\n",
       "      <td>google play</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.588300</td>\n",
       "      <td>Cannot defined</td>\n",
       "      <td>0.617693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label       Source   \n",
       "0                            google play - lam phien  [5, 12]  google play  \\\n",
       "1               google play - .. t . √Ä m√† h·ªç n·ªØ ∆∞u m  [5, 12]  google play   \n",
       "2                           google play - Cc l√πa dao  [5, 12]  google play   \n",
       "3  google play - M·∫∑t h√†ng sp m√¨nh ƒë·ªÅu nh·ª° v·ªõi Gia...  [2, 23]  google play   \n",
       "4  google play - Ch∆∞a t·ªëi ∆∞u t·ªët cho Android Oppo...   [3, 5]  google play   \n",
       "\n",
       "    pred_L1  pred_prob_L1          pred_L2  pred_prob_L2  \n",
       "0   Feature      0.880263  App performance      0.696242  \n",
       "1   Feature      0.781973  App performance      0.684697  \n",
       "2    Others      0.986321   Cannot defined      0.979061  \n",
       "3  Delivery      0.910066    Delivery time      0.616661  \n",
       "4    Others      0.588300   Cannot defined      0.617693  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the label index to string, we can use the ```label_lists``` attribute of tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[['label_L1','label_L2']] = pd.DataFrame(df_val.label.tolist(), index= df_val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "      <th>pred_L2</th>\n",
       "      <th>pred_prob_L2</th>\n",
       "      <th>label_L1</th>\n",
       "      <th>label_L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - lam phien</td>\n",
       "      <td>[5, 12]</td>\n",
       "      <td>google play</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.880263</td>\n",
       "      <td>App performance</td>\n",
       "      <td>0.696242</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google play - .. t . √Ä m√† h·ªç n·ªØ ∆∞u m</td>\n",
       "      <td>[5, 12]</td>\n",
       "      <td>google play</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.781973</td>\n",
       "      <td>App performance</td>\n",
       "      <td>0.684697</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google play - Cc l√πa dao</td>\n",
       "      <td>[5, 12]</td>\n",
       "      <td>google play</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.986321</td>\n",
       "      <td>Cannot defined</td>\n",
       "      <td>0.979061</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google play - M·∫∑t h√†ng sp m√¨nh ƒë·ªÅu nh·ª° v·ªõi Gia...</td>\n",
       "      <td>[2, 23]</td>\n",
       "      <td>google play</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.910066</td>\n",
       "      <td>Delivery time</td>\n",
       "      <td>0.616661</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - Ch∆∞a t·ªëi ∆∞u t·ªët cho Android Oppo...</td>\n",
       "      <td>[3, 5]</td>\n",
       "      <td>google play</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.588300</td>\n",
       "      <td>Cannot defined</td>\n",
       "      <td>0.617693</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label       Source   \n",
       "0                            google play - lam phien  [5, 12]  google play  \\\n",
       "1               google play - .. t . √Ä m√† h·ªç n·ªØ ∆∞u m  [5, 12]  google play   \n",
       "2                           google play - Cc l√πa dao  [5, 12]  google play   \n",
       "3  google play - M·∫∑t h√†ng sp m√¨nh ƒë·ªÅu nh·ª° v·ªõi Gia...  [2, 23]  google play   \n",
       "4  google play - Ch∆∞a t·ªëi ∆∞u t·ªët cho Android Oppo...   [3, 5]  google play   \n",
       "\n",
       "    pred_L1  pred_prob_L1          pred_L2  pred_prob_L2  label_L1  label_L2  \n",
       "0   Feature      0.880263  App performance      0.696242         5        12  \n",
       "1   Feature      0.781973  App performance      0.684697         5        12  \n",
       "2    Others      0.986321   Cannot defined      0.979061         5        12  \n",
       "3  Delivery      0.910066    Delivery time      0.616661         2        23  \n",
       "4    Others      0.588300   Cannot defined      0.617693         3         5  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['label_L1']= df_val['label_L1'].apply(lambda x: tdm.label_lists[0][x]).values\n",
    "df_val['label_L2']= df_val['label_L2'].apply(lambda x: tdm.label_lists[1][x]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47357980728239585, 0.09925006584798883)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_val.label_L1,df_val.pred_L1,average='macro'),f1_score(df_val.label_L2,df_val.pred_L2,average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go through details on how to make a prediction on a completely new and raw dataset using our trained model. For now, let's reuse the sample csv and pretend it's our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Input Validation Precheck -----\n",
      "DataFrame contains duplicated values!\n",
      "-----> Number of duplications: 16 rows\n"
     ]
    }
   ],
   "source": [
    "df_test = TextDataMain.from_csv(Path('sample_data')/'sample_large.csv',return_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added the required columns as we defined in training process, and remove all the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['L1','L2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google Play</td>\n",
       "      <td>App ncc l√∫c n√†o cx lag ƒë∆°, ph·∫ßn t√¨m ki·∫øm th√¨ v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non Owned</td>\n",
       "      <td>..‚ùóÔ∏è G√ìC THANH L√ù T√≠nh ra r·∫ª h∆°n c·∫£ mua #Shope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google Play</td>\n",
       "      <td>M·∫Øc g√¨ ng∆∞·ªùi ta ƒë·∫∑t h√†ng to√†n l·ªói üòÉ????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owned</td>\n",
       "      <td>#GhienShopeePayawardT8 Khi b·∫°n ch∆°i shopee qu√°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google Play</td>\n",
       "      <td>R·∫•t b·ª©c x√∫c khi d√πng . m√£ gi·∫£m gi√° ng∆∞·ªùi d√πng ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source                                            Content\n",
       "0  Google Play  App ncc l√∫c n√†o cx lag ƒë∆°, ph·∫ßn t√¨m ki·∫øm th√¨ v...\n",
       "1    Non Owned  ..‚ùóÔ∏è G√ìC THANH L√ù T√≠nh ra r·∫ª h∆°n c·∫£ mua #Shope...\n",
       "2  Google Play            M·∫Øc g√¨ ng∆∞·ªùi ta ƒë·∫∑t h√†ng to√†n l·ªói üòÉ????\n",
       "3        Owned  #GhienShopeePayawardT8 Khi b·∫°n ch∆°i shopee qu√°...\n",
       "4  Google Play  R·∫•t b·ª©c x√∫c khi d√πng . m√£ gi·∫£m gi√° ng∆∞·ªùi d√πng ..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a DatasetDict for this test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Getting Test Set --------------------\n",
      "----- Input Validation Precheck -----\n",
      "DataFrame contains duplicated values!\n",
      "-----> Number of duplications: 19 rows\n",
      "-------------------- Start Test Set Transformation --------------------\n",
      "----- Metadata Simple Processing & Concatenating to Main Content -----\n",
      "-------------------- Text Transformation --------------------\n",
      "----- text_normalize -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2269/2269 [00:00<00:00, 3940.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Test Leak Checking --------------------\n",
      "- Before leak check\n",
      "Size: 2269\n",
      "- After leak check\n",
      "Size: 2080\n",
      "- Number of rows leaked: 189, or 8.33% of the original validation (or test) data\n",
      "-------------------- Construct DatasetDict --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ddict = tdm.get_test_datasetdict_from_df(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text', 'Source', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ddict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test data has been processed + transformed (but not augmented) the same way as the validation set. Now we can start making the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "controller = ModelController(model,tdm)\n",
    "df_result = controller.predict_ddict(ddict=test_ddict,ds_type='test',is_dhc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "      <th>pred_L2</th>\n",
       "      <th>pred_prob_L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - App ncc l√∫c n√†o cx lag ƒë∆° , ph·∫ßn...</td>\n",
       "      <td>google play</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.903318</td>\n",
       "      <td>App performance</td>\n",
       "      <td>0.674870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non owned - .. ‚ùó Ô∏è G√ìC THANH L√ù T√≠nh ra r·∫ª h∆°n...</td>\n",
       "      <td>non owned</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.998537</td>\n",
       "      <td>Cannot defined</td>\n",
       "      <td>0.995626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google play - M·∫Øc g√¨ ng∆∞·ªùi ta ƒë·∫∑t h√†ng to√†n l·ªó...</td>\n",
       "      <td>google play</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.715968</td>\n",
       "      <td>App performance</td>\n",
       "      <td>0.529486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owned - # GhienShopeePayawardT8 Khi b·∫°n ch∆°i s...</td>\n",
       "      <td>owned</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>0.989516</td>\n",
       "      <td>Shopee Programs</td>\n",
       "      <td>0.993086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - R·∫•t b·ª©c x√∫c khi d√πng . m√£ gi·∫£m g...</td>\n",
       "      <td>google play</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.840763</td>\n",
       "      <td>Apply Voucher</td>\n",
       "      <td>0.310494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       Source     pred_L1   \n",
       "0  google play - App ncc l√∫c n√†o cx lag ƒë∆° , ph·∫ßn...  google play     Feature  \\\n",
       "1  non owned - .. ‚ùó Ô∏è G√ìC THANH L√ù T√≠nh ra r·∫ª h∆°n...    non owned      Others   \n",
       "2  google play - M·∫Øc g√¨ ng∆∞·ªùi ta ƒë·∫∑t h√†ng to√†n l·ªó...  google play     Feature   \n",
       "3  owned - # GhienShopeePayawardT8 Khi b·∫°n ch∆°i s...        owned  Commercial   \n",
       "4  google play - R·∫•t b·ª©c x√∫c khi d√πng . m√£ gi·∫£m g...  google play     Feature   \n",
       "\n",
       "   pred_prob_L1          pred_L2  pred_prob_L2  \n",
       "0      0.903318  App performance      0.674870  \n",
       "1      0.998537   Cannot defined      0.995626  \n",
       "2      0.715968  App performance      0.529486  \n",
       "3      0.989516  Shopee Programs      0.993086  \n",
       "4      0.840763    Apply Voucher      0.310494  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even predict top k results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "      <th>pred_L2</th>\n",
       "      <th>pred_prob_L2</th>\n",
       "      <th>pred_L1_top1</th>\n",
       "      <th>pred_L1_top2</th>\n",
       "      <th>pred_L1_top3</th>\n",
       "      <th>pred_prob_L1_top1</th>\n",
       "      <th>pred_prob_L1_top2</th>\n",
       "      <th>pred_prob_L1_top3</th>\n",
       "      <th>pred_L2_top1</th>\n",
       "      <th>pred_L2_top2</th>\n",
       "      <th>pred_L2_top3</th>\n",
       "      <th>pred_prob_L2_top1</th>\n",
       "      <th>pred_prob_L2_top2</th>\n",
       "      <th>pred_prob_L2_top3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - App ncc l√∫c n√†o cx lag ƒë∆° , ph·∫ßn...</td>\n",
       "      <td>google play</td>\n",
       "      <td>[3, 9, 4]</td>\n",
       "      <td>[0.90331787, 0.070163645, 0.013683925]</td>\n",
       "      <td>[5, 6, 64]</td>\n",
       "      <td>[0.6748701, 0.12654907, 0.05017495]</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Shopee account</td>\n",
       "      <td>Order/Item</td>\n",
       "      <td>0.903318</td>\n",
       "      <td>0.070164</td>\n",
       "      <td>0.013684</td>\n",
       "      <td>App performance</td>\n",
       "      <td>Apply Voucher</td>\n",
       "      <td>Sign up/Log in</td>\n",
       "      <td>0.674870</td>\n",
       "      <td>0.126549</td>\n",
       "      <td>0.050175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non owned - .. ‚ùó Ô∏è G√ìC THANH L√ù T√≠nh ra r·∫ª h∆°n...</td>\n",
       "      <td>non owned</td>\n",
       "      <td>[5, 3, 2]</td>\n",
       "      <td>[0.9985366, 0.0007172561, 0.00040264206]</td>\n",
       "      <td>[12, 9, 5]</td>\n",
       "      <td>[0.99562645, 0.0017475911, 0.0010105681]</td>\n",
       "      <td>Others</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.998537</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>Cannot defined</td>\n",
       "      <td>Branding</td>\n",
       "      <td>App performance</td>\n",
       "      <td>0.995626</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.001011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google play - M·∫Øc g√¨ ng∆∞·ªùi ta ƒë·∫∑t h√†ng to√†n l·ªó...</td>\n",
       "      <td>google play</td>\n",
       "      <td>[3, 5, 4]</td>\n",
       "      <td>[0.7159677, 0.2576615, 0.010411925]</td>\n",
       "      <td>[5, 12, 6]</td>\n",
       "      <td>[0.52948564, 0.31033903, 0.07395215]</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Others</td>\n",
       "      <td>Order/Item</td>\n",
       "      <td>0.715968</td>\n",
       "      <td>0.257661</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>App performance</td>\n",
       "      <td>Cannot defined</td>\n",
       "      <td>Apply Voucher</td>\n",
       "      <td>0.529486</td>\n",
       "      <td>0.310339</td>\n",
       "      <td>0.073952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owned - # GhienShopeePayawardT8 Khi b·∫°n ch∆°i s...</td>\n",
       "      <td>owned</td>\n",
       "      <td>[1, 6, 0]</td>\n",
       "      <td>[0.9895163, 0.009675543, 0.00036532234]</td>\n",
       "      <td>[59, 63, 29]</td>\n",
       "      <td>[0.993086, 0.003024094, 0.0012311569]</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Payment</td>\n",
       "      <td>Buyer complained seller</td>\n",
       "      <td>0.989516</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>Shopee Programs</td>\n",
       "      <td>ShopeePay</td>\n",
       "      <td>Games/Minigames</td>\n",
       "      <td>0.993086</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.001231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - R·∫•t b·ª©c x√∫c khi d√πng . m√£ gi·∫£m g...</td>\n",
       "      <td>google play</td>\n",
       "      <td>[3, 9, 4]</td>\n",
       "      <td>[0.8407633, 0.102363825, 0.034727756]</td>\n",
       "      <td>[6, 5, 64]</td>\n",
       "      <td>[0.3104941, 0.3058795, 0.09680278]</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Shopee account</td>\n",
       "      <td>Order/Item</td>\n",
       "      <td>0.840763</td>\n",
       "      <td>0.102364</td>\n",
       "      <td>0.034728</td>\n",
       "      <td>Apply Voucher</td>\n",
       "      <td>App performance</td>\n",
       "      <td>Sign up/Log in</td>\n",
       "      <td>0.310494</td>\n",
       "      <td>0.305880</td>\n",
       "      <td>0.096803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       Source    pred_L1   \n",
       "0  google play - App ncc l√∫c n√†o cx lag ƒë∆° , ph·∫ßn...  google play  [3, 9, 4]  \\\n",
       "1  non owned - .. ‚ùó Ô∏è G√ìC THANH L√ù T√≠nh ra r·∫ª h∆°n...    non owned  [5, 3, 2]   \n",
       "2  google play - M·∫Øc g√¨ ng∆∞·ªùi ta ƒë·∫∑t h√†ng to√†n l·ªó...  google play  [3, 5, 4]   \n",
       "3  owned - # GhienShopeePayawardT8 Khi b·∫°n ch∆°i s...        owned  [1, 6, 0]   \n",
       "4  google play - R·∫•t b·ª©c x√∫c khi d√πng . m√£ gi·∫£m g...  google play  [3, 9, 4]   \n",
       "\n",
       "                               pred_prob_L1       pred_L2   \n",
       "0    [0.90331787, 0.070163645, 0.013683925]    [5, 6, 64]  \\\n",
       "1  [0.9985366, 0.0007172561, 0.00040264206]    [12, 9, 5]   \n",
       "2       [0.7159677, 0.2576615, 0.010411925]    [5, 12, 6]   \n",
       "3   [0.9895163, 0.009675543, 0.00036532234]  [59, 63, 29]   \n",
       "4     [0.8407633, 0.102363825, 0.034727756]    [6, 5, 64]   \n",
       "\n",
       "                               pred_prob_L2 pred_L1_top1    pred_L1_top2   \n",
       "0       [0.6748701, 0.12654907, 0.05017495]      Feature  Shopee account  \\\n",
       "1  [0.99562645, 0.0017475911, 0.0010105681]       Others         Feature   \n",
       "2      [0.52948564, 0.31033903, 0.07395215]      Feature          Others   \n",
       "3     [0.993086, 0.003024094, 0.0012311569]   Commercial         Payment   \n",
       "4        [0.3104941, 0.3058795, 0.09680278]      Feature  Shopee account   \n",
       "\n",
       "              pred_L1_top3  pred_prob_L1_top1  pred_prob_L1_top2   \n",
       "0               Order/Item           0.903318           0.070164  \\\n",
       "1                 Delivery           0.998537           0.000717   \n",
       "2               Order/Item           0.715968           0.257661   \n",
       "3  Buyer complained seller           0.989516           0.009676   \n",
       "4               Order/Item           0.840763           0.102364   \n",
       "\n",
       "   pred_prob_L1_top3     pred_L2_top1     pred_L2_top2     pred_L2_top3   \n",
       "0           0.013684  App performance    Apply Voucher   Sign up/Log in  \\\n",
       "1           0.000403   Cannot defined         Branding  App performance   \n",
       "2           0.010412  App performance   Cannot defined    Apply Voucher   \n",
       "3           0.000365  Shopee Programs        ShopeePay  Games/Minigames   \n",
       "4           0.034728    Apply Voucher  App performance   Sign up/Log in   \n",
       "\n",
       "   pred_prob_L2_top1  pred_prob_L2_top2  pred_prob_L2_top3  \n",
       "0           0.674870           0.126549           0.050175  \n",
       "1           0.995626           0.001748           0.001011  \n",
       "2           0.529486           0.310339           0.073952  \n",
       "3           0.993086           0.003024           0.001231  \n",
       "4           0.310494           0.305880           0.096803  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = controller.predict_ddict(ddict=test_ddict,ds_type='test',topk=3,is_dhc=True)\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want to make a prediction on a small amount of data (single sentence, or a few sentences), we can use `ModelController.predict_raw_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have some metadatas, we need to define a dictionary (to imitate a DatasetDict)\n",
    "raw_content={\n",
    "    'Source': 'Google play',\n",
    "    'Content':'T√¥i kh√¥ng th√≠ch Shopee.T·∫°i v√¨ d√πng app r·∫•t ch·∫≠m,lag banh nh√† l·∫ßu, th·∫≠m ch√≠ log in c√≤n kh√¥ng ƒëc'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't use metadata, we can use something like this: \n",
    "\n",
    "```raw_content='T√¥i kh√¥ng th√≠ch Shopee.T·∫°i v√¨ d√πng app r·∫•t ch·∫≠m,lag banh nh√† l·∫ßu, th·∫≠m ch√≠ log in c√≤n kh√¥ng ƒëc'```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 4777.11it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Source</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "      <th>pred_L2</th>\n",
       "      <th>pred_prob_L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - T√¥i kh√¥ng th√≠ch Shopee . T·∫°i v√¨ ...</td>\n",
       "      <td>google play</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.975475</td>\n",
       "      <td>App performance</td>\n",
       "      <td>0.919566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       Source  pred_L1   \n",
       "0  google play - T√¥i kh√¥ng th√≠ch Shopee . T·∫°i v√¨ ...  google play  Feature  \\\n",
       "\n",
       "   pred_prob_L1          pred_L2  pred_prob_L2  \n",
       "0      0.975475  App performance      0.919566  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = controller.predict_raw_text(raw_content,topk=1,is_dhc=True)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try different model architecture (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from that_nlp_library.models.classifiers import *\n",
    "from that_nlp_library.models.deep_hierarchical_classifiers import *\n",
    "from that_nlp_library.model_main import *\n",
    "from that_nlp_library.models.classifiers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = tdm.df[tdm.label_names]\n",
    "\n",
    "dhc_mask = build_DHC_conditional_mask(df_labels,*tdm.label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nguyenvulebinh/envibert were not used when initializing RobertaHSCDHCSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaHSCDHCSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaHSCDHCSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaHSCDHCSequenceClassification were not initialized from the model checkpoint at nguyenvulebinh/envibert and are newly initialized: ['linear_L2_logit.bias', 'linear_L1.weight', 'linear_L2_logit.weight', 'linear_L1_logit.bias', 'root_representation.pre_classifier.weight', 'linear_L2.weight', 'linear_L1.bias', 'linear_L1_logit.weight', 'root_representation.pre_classifier.bias', 'linear_L2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2906' max='2906' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2906/2906 03:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score L1</th>\n",
       "      <th>Accuracy Score L1</th>\n",
       "      <th>F1 Score L2</th>\n",
       "      <th>Accuracy Score L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.445967</td>\n",
       "      <td>0.555450</td>\n",
       "      <td>0.740786</td>\n",
       "      <td>0.152149</td>\n",
       "      <td>0.603176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.725500</td>\n",
       "      <td>7.214032</td>\n",
       "      <td>0.628025</td>\n",
       "      <td>0.763686</td>\n",
       "      <td>0.213925</td>\n",
       "      <td>0.654158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name='nguyenvulebinh/envibert'\n",
    "\n",
    "_model_kwargs={\n",
    "    'dhc_mask':dhc_mask,\n",
    "    'classifier_dropout':0.1,\n",
    "    'last_hidden_size':768,  \n",
    "    'linear_l1_size':389,\n",
    "    'linear_l2_size':417,\n",
    "    'lloss_weight':1.0,\n",
    "    'dloss_weight':0.8,\n",
    "    \n",
    "}\n",
    "\n",
    "model = model_init_classification(model_class = RobertaHSCDHCSequenceClassification,\n",
    "                                  cpoint_path = 'nguyenvulebinh/envibert', \n",
    "                                  output_hidden_states=True, # since we are using 'hidden layer contatenation'\n",
    "                                  seed=42,\n",
    "                                  model_kwargs = _model_kwargs)\n",
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score]\n",
    "controller = ModelController(model,tdm,metric_funcs)\n",
    "\n",
    "lr = 7e-5\n",
    "bs=8\n",
    "wd=0.01\n",
    "epochs= 2\n",
    "\n",
    "controller.fit(epochs,lr,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=compute_metrics_separate_singleheads,\n",
    "               head_sizes=[len(tdm.label_lists[0]),len(tdm.label_lists[1])]\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2906' max='2906' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2906/2906 03:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score L1</th>\n",
       "      <th>Accuracy Score L1</th>\n",
       "      <th>F1 Score L2</th>\n",
       "      <th>Accuracy Score L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.323869</td>\n",
       "      <td>0.546260</td>\n",
       "      <td>0.737066</td>\n",
       "      <td>0.142331</td>\n",
       "      <td>0.594609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.539800</td>\n",
       "      <td>2.057805</td>\n",
       "      <td>0.617023</td>\n",
       "      <td>0.762307</td>\n",
       "      <td>0.216919</td>\n",
       "      <td>0.656498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name='nguyenvulebinh/envibert'\n",
    "\n",
    "_model_kwargs={\n",
    "    'dhc_mask':dhc_mask,\n",
    "    'classifier_dropout':0.1,\n",
    "    'last_hidden_size':768,  \n",
    "    'linear_l1_size':389,\n",
    "    'linear_l2_size':417,\n",
    "    'lloss_weight':1.0,\n",
    "    'dloss_weight':0,\n",
    "    \n",
    "}\n",
    "\n",
    "model = model_init_classification(model_class = RobertaHSCDHCSequenceClassification,\n",
    "                                  cpoint_path = 'nguyenvulebinh/envibert', \n",
    "                                  output_hidden_states=True, # since we are using 'hidden layer contatenation'\n",
    "                                  seed=42,\n",
    "                                  model_kwargs = _model_kwargs)\n",
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score]\n",
    "controller = ModelController(model,tdm,metric_funcs)\n",
    "\n",
    "lr = 7e-5\n",
    "bs=8\n",
    "wd=0.01\n",
    "epochs= 2\n",
    "\n",
    "controller.fit(epochs,lr,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=compute_metrics_separate_singleheads,\n",
    "               head_sizes=[len(tdm.label_lists[0]),len(tdm.label_lists[1])]\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nguyenvulebinh/envibert were not used when initializing RobertaHSCSimpleDHCSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaHSCSimpleDHCSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaHSCSimpleDHCSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaHSCSimpleDHCSequenceClassification were not initialized from the model checkpoint at nguyenvulebinh/envibert and are newly initialized: ['linear_L2_logit.bias', 'linear_L2_logit.weight', 'linear_L1_logit.bias', 'linear_L2.weight', 'linear_L1_logit.weight', 'linear_L2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2906' max='2906' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2906/2906 03:25, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score L1</th>\n",
       "      <th>Accuracy Score L1</th>\n",
       "      <th>F1 Score L2</th>\n",
       "      <th>Accuracy Score L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.617188</td>\n",
       "      <td>0.609794</td>\n",
       "      <td>0.741120</td>\n",
       "      <td>0.087502</td>\n",
       "      <td>0.542332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.910900</td>\n",
       "      <td>7.381319</td>\n",
       "      <td>0.670410</td>\n",
       "      <td>0.768282</td>\n",
       "      <td>0.133683</td>\n",
       "      <td>0.608692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name='nguyenvulebinh/envibert'\n",
    "\n",
    "_model_kwargs={\n",
    "    'dhc_mask':dhc_mask,\n",
    "    'lloss_weight':1.0,\n",
    "    'dloss_weight':0.8,\n",
    "    \n",
    "}\n",
    "\n",
    "model = model_init_classification(model_class = RobertaHSCSimpleDHCSequenceClassification,\n",
    "                                  cpoint_path = 'nguyenvulebinh/envibert', \n",
    "                                  output_hidden_states=True, # since we are using 'hidden layer contatenation'\n",
    "                                  seed=42,\n",
    "                                  model_kwargs = _model_kwargs)\n",
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score]\n",
    "controller = ModelController(model,tdm,metric_funcs)\n",
    "\n",
    "lr = 7e-5\n",
    "bs=8\n",
    "wd=0.01\n",
    "epochs= 2\n",
    "\n",
    "controller.fit(epochs,lr,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=compute_metrics_separate_singleheads,\n",
    "               head_sizes=[len(tdm.label_lists[0]),len(tdm.label_lists[1])]\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nguyenvulebinh/envibert were not used when initializing RobertaHSCSimpleDHCSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaHSCSimpleDHCSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaHSCSimpleDHCSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaHSCSimpleDHCSequenceClassification were not initialized from the model checkpoint at nguyenvulebinh/envibert and are newly initialized: ['linear_L2_logit.bias', 'linear_L2_logit.weight', 'linear_L1_logit.bias', 'linear_L2.weight', 'linear_L1_logit.weight', 'linear_L2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2906' max='2906' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2906/2906 03:28, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score L1</th>\n",
       "      <th>Accuracy Score L1</th>\n",
       "      <th>F1 Score L2</th>\n",
       "      <th>Accuracy Score L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.511302</td>\n",
       "      <td>0.604820</td>\n",
       "      <td>0.737568</td>\n",
       "      <td>0.080265</td>\n",
       "      <td>0.540827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.747700</td>\n",
       "      <td>2.248143</td>\n",
       "      <td>0.667460</td>\n",
       "      <td>0.765692</td>\n",
       "      <td>0.131651</td>\n",
       "      <td>0.606895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2372: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name='nguyenvulebinh/envibert'\n",
    "\n",
    "_model_kwargs={\n",
    "    'dhc_mask':dhc_mask,\n",
    "    'lloss_weight':1.0,\n",
    "    'dloss_weight':0,\n",
    "    \n",
    "}\n",
    "\n",
    "model = model_init_classification(model_class = RobertaHSCSimpleDHCSequenceClassification,\n",
    "                                  cpoint_path = 'nguyenvulebinh/envibert', \n",
    "                                  output_hidden_states=True, # since we are using 'hidden layer contatenation'\n",
    "                                  seed=42,\n",
    "                                  model_kwargs = _model_kwargs)\n",
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score]\n",
    "controller = ModelController(model,tdm,metric_funcs)\n",
    "\n",
    "lr = 7e-5\n",
    "bs=8\n",
    "wd=0.01\n",
    "epochs= 2\n",
    "\n",
    "controller.fit(epochs,lr,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=compute_metrics_separate_singleheads,\n",
    "               head_sizes=[len(tdm.label_lists[0]),len(tdm.label_lists[1])]\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
