{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd4c6a0",
   "metadata": {},
   "source": [
    "# Text Processing Benchmark\n",
    "\n",
    "> This module contains some benchmarks for `TextDataController`\n",
    "\n",
    "- skip_showdoc: true\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1093e303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets                  2.11.0                   pypi_0    pypi\r\n",
      "transformers              4.28.1                   pypi_0    pypi\r\n"
     ]
    }
   ],
   "source": [
    "# !conda list | grep 'datasets\\|transformers'\n",
    "# datasets                  2.11.0                   pypi_0    pypi\n",
    "# transformers              4.28.1                   pypi_0    pypi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dac5384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from that_nlp_library.text_transformation import *\n",
    "from that_nlp_library.text_augmentation import *\n",
    "from that_nlp_library.text_main import *\n",
    "from importlib.machinery import SourceFileLoader\n",
    "from datasets import load_dataset,enable_caching,disable_caching\n",
    "from transformers import RobertaTokenizer\n",
    "import os\n",
    "import time\n",
    "from underthesea import text_normalize\n",
    "import nlpaug.augmenter.char as nac\n",
    "from functools import partial\n",
    "import random\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f43eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_caching() # disable huggingface caching to get a fair benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d04e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmarking(tdc,bs,tokenizer,n=10,shuffle_trn=True):\n",
    "    time1 = time.time()\n",
    "    tdc.process_and_tokenize(tokenizer,max_length=512,shuffle_trn=shuffle_trn)\n",
    "    time2 = time.time() \n",
    "    print(f'Time it takes to process + tokenize training texts: {(time2-time1):.3f} s')\n",
    "    for i,v in enumerate(tdc.main_ddict['train']):\n",
    "        if n is not None and i==bs*n: break\n",
    "    time3 = time.time()\n",
    "    if n is not None:\n",
    "        print(f'Time it takes to go through {n*bs} items: {(time3-time2):.3f} s')\n",
    "    else:\n",
    "        print(f'Time it takes to go through all items): {(time3-time2):.3f} s')\n",
    "\n",
    "#     print(f'Total time: {(time3-time1):.3f} s')\n",
    "def benchmarking_and_memory_usage(tdc,bs,tokenizer,n=10,shuffle_trn=True):\n",
    "    mem_usage = memory_usage((benchmarking,[tdc,bs,tokenizer,n,shuffle_trn]))\n",
    "    print(f'Maximum memory usage: {max(mem_usage):.3f} MiB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4816400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_aug_stochastic(x,aug=None,p=0.5):\n",
    "    results = aug.augment(x)\n",
    "    if not isinstance(x,list): return results[0] if random.random()<p else x\n",
    "    return [a if random.random()<p else b for a,b in zip(results,x)]\n",
    "\n",
    "aug = nac.KeyboardAug(aug_char_max=3,aug_char_p=0.1,aug_word_p=0.07)\n",
    "nearby_aug_func = partial(nlp_aug_stochastic,aug=aug,p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7dacd",
   "metadata": {},
   "source": [
    "## Benchmark on medium-size dataset (~117k rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a037f770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117430"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "len(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa62b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7bb28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ef0f74",
   "metadata": {},
   "source": [
    "### Without iterable dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353603df",
   "metadata": {},
   "source": [
    "With filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd89e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 37.038 s\n",
      "Time it takes to go through 1280 items: 0.155 s\n",
      "Maximum memory usage: 762.734 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         val_ratio=None,\n",
    "                         is_batched=True,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=False,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d0f0e",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe4e06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 40.147 s\n",
      "Time it takes to go through 1280 items: 0.181 s\n",
      "Maximum memory usage: 806.473 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         val_ratio=None,\n",
    "                         is_batched=True,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=False,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f789954",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a062e907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 62.309 s\n",
      "Time it takes to go through 1280 items: 0.183 s\n",
      "Maximum memory usage: 859.008 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         is_batched=True,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=False,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc360da",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation + no shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0343c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 59.452 s\n",
      "Time it takes to go through 1280 items: 0.184 s\n",
      "Maximum memory usage: 867.031 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         is_batched=True,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=False,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer,shuffle_trn=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6e9dd0",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation + higher batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e33e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 61.862 s\n",
      "Time it takes to go through 20480 items: 3.067 s\n",
      "Maximum memory usage: 785.172 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         is_batched=True,\n",
    "                         batch_size=2048,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=False,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,2048,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17d02bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe69c661",
   "metadata": {},
   "source": [
    "### With iterable dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18355b6",
   "metadata": {},
   "source": [
    "With filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba99f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 2.850 s\n",
      "Time it takes to go through 1280 items: 0.464 s\n",
      "Maximum memory usage: 799.742 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         val_ratio=None,\n",
    "                         is_batched=True,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83052e2d",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e60b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 2.623 s\n",
      "Time it takes to go through 1280 items: 0.544 s\n",
      "Maximum memory usage: 838.613 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         val_ratio=None,\n",
    "                         is_batched=True,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1a7b92",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db76e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 22.310 s\n",
      "Time it takes to go through 1280 items: 0.562 s\n",
      "Maximum memory usage: 891.176 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         is_batched=True,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1410b5",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation + no shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb723349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 22.421 s\n",
      "Time it takes to go through 1280 items: 0.474 s\n",
      "Maximum memory usage: 892.000 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         is_batched=True,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer,shuffle_trn=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8055af74",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation + higher batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76b02f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 21.645 s\n",
      "Time it takes to go through 20480 items: 7.809 s\n",
      "Maximum memory usage: 768.688 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         is_batched=True,\n",
    "                         batch_size=2048,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,2048,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cb1033",
   "metadata": {},
   "source": [
    "### With streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f5775",
   "metadata": {},
   "source": [
    "With filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b19313a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.002 s\n",
      "Time it takes to go through 1280 items: 1.244 s\n",
      "Maximum memory usage: 752.238 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "                         val_ratio=None,\n",
    "                         is_batched=True,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eb2d0b",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278410bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.002 s\n",
      "Time it takes to go through 1280 items: 1.365 s\n",
      "Maximum memory usage: 829.074 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         val_ratio=None,\n",
    "                         is_batched=True,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073b200c",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b90335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.084 s\n",
      "Time it takes to go through 1280 items: 95.443 s\n",
      "Maximum memory usage: 6955.020 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         is_batched=True,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a6f1b4",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation + no shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42ed1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.080 s\n",
      "Time it takes to go through 1280 items: 11.529 s\n",
      "Maximum memory usage: 6841.391 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         is_batched=True,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer,shuffle_trn=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a473bf4f",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation + higher batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031a450a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.079 s\n",
      "Time it takes to go through 2000 items: 63.094 s\n",
      "Maximum memory usage: 37318.242 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         is_batched=True,\n",
    "                         batch_size=200,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,200,tokenizer,shuffle_trn=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d492467",
   "metadata": {},
   "source": [
    "## Improving processing time with caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aaa469",
   "metadata": {},
   "source": [
    "The worst processing time is recorded with an non-iterable training set, with the following preprocessing: 2-column filtering, 2-column metadatas, 2 content transformations, 2 content augmentation; the total preprocessing time is ~62s for 117k dataset. However, this results in the best data iteration time: 0.183s for going through 1280 items.\n",
    "\n",
    "With caching, we can significantly reduce the preprocessing time. That means, you only need to do all preprocessings once; all subsequent call will take advatages of this cached result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79301ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_caching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedd6c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-a8e48b2fdcc1675b_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-7f67ed2247bad412_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-8895dee11a0750d6_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-7cb19b4a6f7bb9bc_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-8d6c7bf742ea98e4_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-48a8c757ecb89ade_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-896ddc2616d23c5e_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-e0a802a1bedd79b5_*_of_00004.arrow\n",
      "Loading cached shuffled indices for dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-eae3d3101ec08ba5.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-baf7b5167460c6dd.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 1.471 s\n",
      "Time it takes to go through 1280 items: 0.176 s\n",
      "Maximum memory usage: 874.715 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         is_batched=True,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=False,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29814812",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57cffede",
   "metadata": {},
   "source": [
    "With CPU batch size of 128, and data iteration of 1280 items (10 batches)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fd1675a",
   "metadata": {},
   "source": [
    "1. Time to process + tokenize. Unit: seconds\n",
    "\n",
    "|  | Filtering | + 2-column metadatas | + 2 tfms and 2 augs | + no train shuffling |\n",
    "|------------------------------|-------------------------|-------------------------|-----------------|--------------------|\n",
    "| no iterable training         | 37.038                  | 40.147                  | 62.309          | 59.452             |\n",
    "| iterable training            | 2.85                    | 2.623                   | 22.31           | 22.421             |\n",
    "| streaming                    | 0.002                   | 0.002                   | 0.084           | 0.08               |\n",
    "\n",
    "2. Time to loop through 1280 items (10 batches). Unit: seconds\n",
    "\n",
    "|                              | Filtering | + 2-column metadatas | + 2 tfms and 2 augs | + no train shuffling |\n",
    "|------------------------------|-------------------------|-----------------|--------------------|------------------------------------|\n",
    "| no iterable training         | 0.155                    | 0.181           | 0.183              | 0.184                              |\n",
    "| iterable training            | 0.464                    | 0.544           | 0.562              | 0.474                              |\n",
    "| streaming                    | 1.244                    | 1.365           | 95.443             | 11.529                             |\n",
    "\n",
    "3. Maximum memory usage. Unit: megabytes\n",
    "\n",
    "|                              | Filtering | + 2-column metadatas | + 2 tfms and 2 augs | + no train shuffling |\n",
    "|------------------------------|-------------------------|-----------------|--------------------|------------------------------------|\n",
    "| no iterable training         | 762.734 | 806.473                  | 859.008         | 867.031            | \n",
    "| iterable training            |799.742 | 838.613                  | 891.176         | 892                |\n",
    "| streaming                    | 752.238 | 829.074                  | 6955.02         | 6841.391           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5f08f4",
   "metadata": {},
   "source": [
    "## Tips and tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee16de1",
   "metadata": {},
   "source": [
    "- For non-streaming data, the best way to minimize processing and iteration time is:\n",
    "    - Use non-iterable training (which means don't turn training set into an Iterable Dataset)\n",
    "    - Turn on dataset caching, and run the processing step once for it to be cached\n",
    "- If caching is not an option, then use iterable training (turn trainingset into an Iterable Dataset)\n",
    "- The more content transformations and augmentations added, the slower the process + iteration. This is especially true for streaming data\n",
    "- For streaming data, which might be the slowest option, here are a few things to speed up the whole pipeline:\n",
    "    - Try to define and create a validation set split in your dataset; don't use the validation split functionality of `TextDataController\n",
    "    - Minimize the amount of content transformation and content augmentation\n",
    "    - Turn off `shuffle_trn`\n",
    "    - Set a smaller CPU batch size. E.g. in my 64gb RAM machine, and this dataset of 117k rows, I can only set batch size up to 200 to avoid memory error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d86d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
