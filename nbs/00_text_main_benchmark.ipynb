{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60547fd5",
   "metadata": {},
   "source": [
    "# Text Processing Benchmark\n",
    "\n",
    "> This module contains some benchmarks for `TextDataController`\n",
    "\n",
    "- skip_showdoc: true\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a07a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda list | grep 'datasets\\|transformers'\n",
    "# datasets                  2.11.0                   pypi_0    pypi\n",
    "# transformers              4.28.1                   pypi_0    pypi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd5c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from that_nlp_library.text_transformation import *\n",
    "from that_nlp_library.text_augmentation import *\n",
    "from that_nlp_library.text_main import *\n",
    "from importlib.machinery import SourceFileLoader\n",
    "from datasets import load_dataset,enable_caching,disable_caching\n",
    "from transformers import RobertaTokenizer\n",
    "import os\n",
    "import time\n",
    "from underthesea import text_normalize\n",
    "import nlpaug.augmenter.char as nac\n",
    "from functools import partial\n",
    "import random\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e473d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_caching() # disable huggingface caching to get a fair benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0504f25",
   "metadata": {},
   "source": [
    "## Benchmark on medium-size dataset (~117k rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecaa5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117430"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "len(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba166813",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cdee5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1174"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=len(dset)//100\n",
    "bs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e6ac5f",
   "metadata": {},
   "source": [
    "### Non-streaming dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33355fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmarking(tdc,tokenizer,n=10,shuffle_trn=True):\n",
    "    time1 = time.time()\n",
    "    tdc.process_and_tokenize(tokenizer,max_length=512,shuffle_trn=shuffle_trn)\n",
    "    time2 = time.time() \n",
    "    print(f'Time it takes to process + tokenize training texts: {(time2-time1):.3f} s')\n",
    "    for i,v in enumerate(tdc.main_ddict['train']):\n",
    "        if n is not None and i==tdc.batch_size*n: break\n",
    "    time3 = time.time()\n",
    "    if n is not None:\n",
    "        print(f'Time it takes to go through {n*tdc.batch_size} items: {(time3-time2):.3f} s')\n",
    "    else:\n",
    "        print(f'Time it takes to go through all items: {(time3-time2):.3f} s')\n",
    "\n",
    "#     print(f'Total time: {(time3-time1):.3f} s')\n",
    "def benchmarking_and_memory_usage(tdc,tokenizer,n=10,shuffle_trn=True):\n",
    "    mem_usage = memory_usage((benchmarking,[tdc,tokenizer,n,shuffle_trn]))\n",
    "    print(f'Maximum memory usage: {max(mem_usage):.3f} MiB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b7445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_aug_stochastic(x,aug=None,p=0.5):\n",
    "    results = aug.augment(x)\n",
    "    if not isinstance(x,list): return results[0] if random.random()<p else x\n",
    "    return [a if random.random()<p else b for a,b in zip(results,x)]\n",
    "\n",
    "aug = nac.KeyboardAug(aug_char_max=3,aug_char_p=0.1,aug_word_p=0.07)\n",
    "nearby_aug_func = partial(nlp_aug_stochastic,aug=aug,p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c687dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56031598",
   "metadata": {},
   "source": [
    "With filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6677bd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 14.905 s\n",
      "Time it takes to go through 11740 items: 1.496 s\n",
      "Maximum memory usage: 763.004 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a68d2d",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf02abe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 15.518 s\n",
      "Time it takes to go through 11740 items: 1.755 s\n",
      "Maximum memory usage: 780.414 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f3bad1",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf2944b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 35.544 s\n",
      "Time it takes to go through 11740 items: 1.843 s\n",
      "Maximum memory usage: 774.332 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8379ff2",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation + no shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9049824a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 34.666 s\n",
      "Time it takes to go through 11740 items: 1.758 s\n",
      "Maximum memory usage: 789.406 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,tokenizer,shuffle_trn=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf093e",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation + higher batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a37b6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 35.632 s\n",
      "Time it takes to go through 35220 items: 5.409 s\n",
      "Maximum memory usage: 814.371 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs*3,\n",
    "                         seed=42,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774ec51a",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation + iterate the whole dataset (1 epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7089a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1174"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf037a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 35.284 s\n",
      "Time it takes to go through all items: 16.821 s\n",
      "Maximum memory usage: 824.852 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,tokenizer,n=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bca66f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c9b932e",
   "metadata": {},
   "source": [
    "### With streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d2a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmarking_streaming(tdc,tokenizer,n=10):\n",
    "    time1 = time.time()\n",
    "    tdc.process_and_tokenize(tokenizer,max_length=512)\n",
    "    time2 = time.time() \n",
    "    print(f'Time it takes to process + tokenize training texts: {(time2-time1):.3f} s')\n",
    "    for i,v in enumerate(tdc.main_ddict['train']):\n",
    "        if n is not None and i==tdc.batch_size*n: break\n",
    "    time3 = time.time()\n",
    "    if n is not None:\n",
    "        print(f'Time it takes to go through {n*tdc.batch_size} items: {(time3-time2):.3f} s')\n",
    "    else:\n",
    "        print(f'Time it takes to go through all items: {(time3-time2):.3f} s')\n",
    "\n",
    "def benchmarking_and_memory_usage_streaming(tdc,tokenizer,n=10):\n",
    "    mem_usage = memory_usage((benchmarking,[tdc,tokenizer,n]))\n",
    "    print(f'Maximum memory usage: {max(mem_usage):.3f} MiB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b974a8cc",
   "metadata": {},
   "source": [
    "With filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b58fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.842 s\n",
      "Time it takes to go through 11740 items: 4.709 s\n",
      "Maximum memory usage: 767.066 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "\n",
    "tdc = TextDataControllerStreaming(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "                         batch_size=bs,\n",
    "                         num_proc=4,\n",
    "                         seed=42,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage_streaming(tdc,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df06d695",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff352d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.886 s\n",
      "Time it takes to go through 11740 items: 4.889 s\n",
      "Maximum memory usage: 790.480 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "\n",
    "tdc = TextDataControllerStreaming(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         batch_size=bs,\n",
    "                         num_proc=4,\n",
    "                         seed=42,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage_streaming(tdc,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58158748",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6653b8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.914 s\n",
      "Time it takes to go through 11740 items: 12.926 s\n",
      "Maximum memory usage: 804.312 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "\n",
    "tdc = TextDataControllerStreaming(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower],\n",
    "                         batch_size=bs,\n",
    "                         num_proc=4,\n",
    "                         seed=42,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage_streaming(tdc,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206229d4",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation + higher batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa7762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.952 s\n",
      "Time it takes to go through 35220 items: 38.854 s\n",
      "Maximum memory usage: 993.641 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "\n",
    "tdc = TextDataControllerStreaming(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower],\n",
    "                         batch_size=bs*3,\n",
    "                         num_proc=4,\n",
    "                         seed=42,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage_streaming(tdc,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d40885",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation + iterate the whole dataset (1 epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d49f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.825 s\n",
      "Time it takes to go through all items: 121.332 s\n",
      "Maximum memory usage: 771.711 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "\n",
    "tdc = TextDataControllerStreaming(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower],\n",
    "                         batch_size=bs,\n",
    "                         num_proc=4,\n",
    "                         seed=42,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage_streaming(tdc,tokenizer,n=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63f8a8c",
   "metadata": {},
   "source": [
    "### Test the effect of batch size and num_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6893cbfa",
   "metadata": {},
   "source": [
    "For non-streaming dataste, text processing + tokenization are the most time-consuming tasks, thus we will check how different batch size and num proc will affect these tasks' running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a76d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 36.516 s\n",
      "Time it takes to go through all items: 16.576 s\n",
      "Maximum memory usage: 997.777 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=128,\n",
    "                         num_proc=4,\n",
    "                         seed=42,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,tokenizer,n=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb78cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 35.601 s\n",
      "Time it takes to go through all items: 16.904 s\n",
      "Maximum memory usage: 987.270 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=1000,\n",
    "                         num_proc=4,\n",
    "                         seed=42,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,tokenizer,n=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cba18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=24):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=24):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices (num_proc=24):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 29.681 s\n",
      "Time it takes to go through all items: 16.793 s\n",
      "Maximum memory usage: 989.348 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=24*50, #1200\n",
    "                         num_proc=24,\n",
    "                         seed=42,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,tokenizer,n=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace009b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=24):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=24):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices (num_proc=24):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 29.924 s\n",
      "Time it takes to go through all items: 17.506 s\n",
      "Maximum memory usage: 994.566 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=24*400, #9600\n",
    "                         num_proc=24,\n",
    "                         seed=42,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,tokenizer,n=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90887c31",
   "metadata": {},
   "source": [
    "Conclusion: increase BOTH batch size and num_proc can help decrease the processing + tokenization time, but the relationship between batch size, num_proc and running time are not linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7873c3",
   "metadata": {},
   "source": [
    "## Improving processing time with caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c898e3",
   "metadata": {},
   "source": [
    "The worst processing time is recorded with non-streaming training set, with the following preprocessing: 2-column filtering, 2-column metadatas, 2 content transformations, 2 content augmentation.\n",
    "\n",
    "With caching, we can significantly reduce the preprocessing time. That means, you only need to do all preprocessings once; all subsequent call will take advatages of this cached result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349c7de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_caching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a8c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-0aed8574c094e4fd_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-b781a4a73d06caf5_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-0f85d6db4165d6ef_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-420893192d8b876f_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-ee3f2ca19acd2369_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-27d1b7f9046ec1b4_*_of_00004.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=1000,\n",
    "                         num_proc=4,\n",
    "                         seed=42,\n",
    "                         verbose=False\n",
    "                        )\n",
    "tdc.process_and_tokenize(tokenizer,max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a1cbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d025b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-0aed8574c094e4fd_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-b781a4a73d06caf5_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-0f85d6db4165d6ef_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-420893192d8b876f_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-ee3f2ca19acd2369_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-27d1b7f9046ec1b4_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-57d938bbd364f406_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-10afb2ec3cb12852_*_of_00004.arrow\n",
      "Loading cached shuffled indices for dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-5d8840c40fe75896.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-030424c28049222f_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-fe4290971e8d1087_*_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.979 s\n",
      "Time it takes to go through all items: 16.824 s\n",
      "Maximum memory usage: 823.531 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=1000,\n",
    "                         num_proc=4,\n",
    "                         seed=42,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,tokenizer,n=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f980a",
   "metadata": {},
   "source": [
    "If you cached, then you only need 0.979s to load the data back from caches, instead of wait for 35.284s to do the process all over again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b938c259",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a19267b",
   "metadata": {},
   "source": [
    "| Process + Tokenize Time (117k records), batchsize = 1174 | Filter, train shuffling | And 2 metadatas | And 2 tfms + 2 augs | Batchsize=1174 x 3 | Batchsize=1174 |\n",
    "|----------------------------------------------------------|-------------------------|-----------------|---------------------|--------------------|----------------|\n",
    "| Non-streaming training                                   | 14.94                   | 15.518          | 35.544              | 35.632             | 35.284         |\n",
    "| Streaming                                                | 0.842                    | 0.886           | 0.914               | 0.952              | 0.825          |\n",
    "| Ratio Non-streaming/Streaming                            | 17.74                    | 17.51           | 38.89               | 37.43              | 42.77          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71c90cd",
   "metadata": {},
   "source": [
    "| Run 10 batches time (1174*10) | Filter, train shuffling | And 2 metadatas | And 2 tfms + 2 augs | Total items iterated: 1174 * 10 * 3 | 1 epoch iterated: 117430 items |\n",
    "|-------------------------------|-------------------------|-----------------|---------------------|---------------------------------|--------------------------------|\n",
    "| Non-streaming training        | 1.496                    | 1.755           | 1.843               | 5.409                            | 16.821                         |\n",
    "| Streaming                     | 4.709                    | 4.889           | 12.926              | 38.854                           | 121.332                        |\n",
    "| Ratio Streaming/Non-Streaming | 3.15                     | 2.79            | 7.01                | 7.18                             | 7.21                           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49405616",
   "metadata": {},
   "source": [
    "| Total Time (Process+Tokenize+Iterate) | Filter, train shuffling | And 2 metadatas | And 2 tfms + 2 augs | Total items iterated: 1174 * 10 * 3 | 1 epoch iterated: 117430 items |\n",
    "|---------------------------------------|-------------------------|-----------------|---------------------|---------------------------------|--------------------------------|\n",
    "| Non-streaming training                | 16.436                   | 17.273          | 37.387              | 41.041                           | 52.105                         |\n",
    "| Streaming                             | 5.551                    | 5.775           | 13.84               | 39.806                           | 122.157                        |\n",
    "| Ratio Non-streaming/Streaming         | 2.96                     | 2.99            | 2.7                 | 1.03                             | 0.43                           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1857bfd",
   "metadata": {},
   "source": [
    "| Total memory use                    | Filter, train shuffling | And 2 metadatas | And 2 tfms + 2 augs | Total items iterated: 1174 * 10 * 3 | 1 epoch iterated: 117430 items |\n",
    "|-------------------------------------|-------------------------|-----------------|---------------------|---------------------------------|--------------------------------|\n",
    "| Non-streaming training              | 763                      | 780             | 774                 | 814                              | 825                            |\n",
    "| Streaming                           | 767                      | 790             | 804                 | 993                              | 772                            |\n",
    "| Ratio Streaming/Non-Streaming       | 1.01                     | 1.01            | 1.04                | 1.22                             | 0.94                           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1fa464",
   "metadata": {},
   "source": [
    "## Tips and tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb0db40",
   "metadata": {},
   "source": [
    "- For non-streaming data, the best way to minimize processing and iteration time is:\n",
    "    - Turn on dataset caching, and run the processing step once for it to be cached\n",
    "- The more content transformations and augmentations added, the slower the process + iteration. This is especially true for streaming data\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
