{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Controller Tutorial: EnviBert model (Single Head)\n",
    "\n",
    "> This notebook contains some example of how to use the EnviBert-based models in this NLP library\n",
    "\n",
    "- skip_showdoc: true\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will walk through other cases of classification: multi-head and multi-label. Since we will showcase the capabiilty of this label in these cases, there won't be as detailed as [this tutorial](https://anhquan0412.github.io/that-nlp-library/model_main_envibert.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from that_nlp_library.text_transformation import *\n",
    "from that_nlp_library.text_augmentation import *\n",
    "from that_nlp_library.text_main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from underthesea import text_normalize\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from importlib.machinery import SourceFileLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some necessary text augmentations and text transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For Text Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_tfms=[text_normalize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For Text Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_nonown_tfm = partial(sampling_with_condition,query='Source==\"non owned\"',frac=0.5,seed=42,apply_to_all=False)\n",
    "over_nonown_tfm.__name__ = 'Oversampling Non Owned'\n",
    "\n",
    "over_own_tfm = partial(sampling_with_condition,query='Source==\"owned\"',frac=2,seed=42,apply_to_all=False)\n",
    "over_own_tfm.__name__ = 'Oversampling Owned'\n",
    "\n",
    "over_hc_tfm = partial(sampling_with_condition,query='Source==\"hc search\"',frac=2.5,seed=42,apply_to_all=False)\n",
    "over_hc_tfm.__name__ = 'Oversampling HC search'\n",
    "\n",
    "remove_accent_tfm = partial(remove_vnmese_accent,frac=1,seed=42,apply_to_all=True)\n",
    "remove_accent_tfm.__name__ = 'Add No-Accent Text'\n",
    "\n",
    "aug_tfms = [over_nonown_tfm,over_own_tfm,over_hc_tfm,remove_accent_tfm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load and preprocess our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('secret_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Input Validation Precheck -----\n",
      "DataFrame contains missing values!\n",
      "-----> List of columns and the number of missing values for each\n",
      "is_valid    65804\n",
      "dtype: int64\n",
      "DataFrame contains duplicated values!\n",
      "-----> Number of duplications: 7 rows\n"
     ]
    }
   ],
   "source": [
    "df = TextDataMain.from_csv(DATA_PATH/'buyer_listening_with_all_raw_data_w2223.csv',return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Group</th>\n",
       "      <th>Source</th>\n",
       "      <th>Content</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>L4</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>Tại sao cứ hiện thông báo</td>\n",
       "      <td>Services</td>\n",
       "      <td>Shopee communication channels</td>\n",
       "      <td>Annoying pop-up ads</td>\n",
       "      <td>Non-tech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>Mlem</td>\n",
       "      <td>Others</td>\n",
       "      <td>Cannot defined</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>1 số sản phẩm trong giỏ hàng vừa đc cập nhật t...</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Cart &amp; Order</td>\n",
       "      <td>Cart issues/suggestions</td>\n",
       "      <td>Tech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Week        Group       Source   \n",
       "0   1.0  Google Play  Google Play  \\\n",
       "1   1.0  Google Play  Google Play   \n",
       "2   1.0  Google Play  Google Play   \n",
       "\n",
       "                                             Content        L1   \n",
       "0                          Tại sao cứ hiện thông báo  Services  \\\n",
       "1                                               Mlem    Others   \n",
       "2  1 số sản phẩm trong giỏ hàng vừa đc cập nhật t...   Feature   \n",
       "\n",
       "                              L2                       L3        L4  is_valid   \n",
       "0  Shopee communication channels      Annoying pop-up ads  Non-tech       NaN  \\\n",
       "1                 Cannot defined                        -         -       NaN   \n",
       "2                   Cart & Order  Cart issues/suggestions      Tech       NaN   \n",
       "\n",
       "   iteration  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick preprocess of data and train/validation split. Due to custom logic, we will sample our data here instead of using the `train_ratio` from the `to_datasetdict` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rare = df[df.L2.isin(['Chatbot', 'Commercial Others'])].copy()\n",
    "\n",
    "df_final = pd.concat([df.query('iteration==1').sample(500,random_state=42),\n",
    "                      df.query('iteration>=7 & iteration<13').sample(1200,random_state=42),\n",
    "                      df_rare,\n",
    "                      df.query('iteration>=13'),\n",
    "                     ],axis=0).reset_index(drop=True)\n",
    "\n",
    "val_idxs = df_final[df_final.iteration>=13].index.values # from week 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Input Validation Precheck -----\n",
      "DataFrame contains missing values!\n",
      "-----> List of columns and the number of missing values for each\n",
      "is_valid    498\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tdm = TextDataMain(df_final,\n",
    "                    main_content='Content',\n",
    "                    metadatas='Source',\n",
    "                    label_names='L1',\n",
    "                    val_ratio=val_idxs,\n",
    "                    split_cols='L1',\n",
    "                    content_tfms = txt_tfms,\n",
    "                    aug_tfms = aug_tfms,\n",
    "                    process_metadatas=True,\n",
    "                    seed=42,\n",
    "                    cols_to_keep=['Content','Source','iteration','L1'], \n",
    "                   # Note that the text column (e.g.`Content`) must be the first item in the `cols_to_keep`\n",
    "                    shuffle_trn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our tokenizer for EnviBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir=Path('./envibert_tokenizer')\n",
    "tokenizer = SourceFileLoader(\"envibert.tokenizer\", \n",
    "                             str(cache_dir/'envibert_tokenizer.py')).load_module().RobertaTokenizer(cache_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our DatasetDict from TextDataMain (as our `ModelController` class can also work with DatasetDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start Main Text Processing --------------------\n",
      "----- Metadata Simple Processing & Concatenating to Main Content -----\n",
      "----- Label Encoding -----\n",
      "-------------------- Text Transformation --------------------\n",
      "----- text_normalize -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 6649/6649 [00:01<00:00, 3640.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train Test Split --------------------\n",
      "Previous Validation Percentage: 74.101%\n",
      "- Before leak check\n",
      "Size: 4927\n",
      "- After leak check\n",
      "Size: 4885\n",
      "- Number of rows leaked: 42, or 0.85% of the original validation (or test) data\n",
      "Current Validation Percentage: 73.47%\n",
      "-------------------- Text Augmentation --------------------\n",
      "Train data size before augmentation: 1764\n",
      "----- Oversampling Non Owned -----\n",
      "Train data size after THIS augmentation: 2229\n",
      "----- Oversampling Owned -----\n",
      "Train data size after THIS augmentation: 2789\n",
      "----- Oversampling HC search -----\n",
      "Train data size after THIS augmentation: 2904\n",
      "----- Add No-Accent Text -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 2904/2904 [00:00<00:00, 10205.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size after THIS augmentation: 5808\n",
      "Train data size after ALL augmentation: 5808\n",
      "-------------------- Map Tokenize Function --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5808 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4885 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main_ddict= tdm.to_datasetdict(tokenizer,\n",
    "                               max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'Source', 'iteration', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 5808\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'Source', 'iteration', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 4885\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_ddict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experiment: EnviBert Multi-Head Classification (with Hidden Layer Concatenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "from that_nlp_library.models.roberta.classifiers import *\n",
    "from that_nlp_library.model_main import *\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import os\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will specify a (or a list) of GPUs for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train EnviBert (with hidden layer concatenation), using TDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our model controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nguyenvulebinh/envibert were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name='nguyenvulebinh/envibert'\n",
    "envibert_body = RobertaModel.from_pretrained(model_name)\n",
    "num_classes = len(tdm.label_lists[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading body weights. This assumes the body is the very first first-layer block of your custom architecture\n"
     ]
    }
   ],
   "source": [
    "_model_kwargs={\n",
    "    # overall model hyperparams\n",
    "    'layer2concat':4,\n",
    "    'is_multilabel':tdm.is_multilabel, # False\n",
    "    'is_multihead':tdm.is_multihead, # False\n",
    "    'head_class_sizes':num_classes,\n",
    "    'head_class': ConcatHeadSimple,\n",
    "    # classfication head hyperparams\n",
    "    'classifier_dropout':0.1 \n",
    "}\n",
    "\n",
    "model = model_init_classification(model_class = RobertaHiddenStateConcatForSequenceClassification,\n",
    "                                  cpoint_path = model_name, \n",
    "                                  output_hidden_states=True, # since we are not using 'hidden layer contatenation' technique\n",
    "                                  seed=42,\n",
    "                                  body_model=envibert_body,\n",
    "                                  model_kwargs = _model_kwargs)\n",
    "\n",
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score] # we will use both f1_macro and accuracy score as metrics\n",
    "controller = ModelController(model,tdm,metric_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can start training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2904' max='2904' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2904/2904 03:19, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score L1</th>\n",
       "      <th>Accuracy Score L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.372778</td>\n",
       "      <td>0.344335</td>\n",
       "      <td>0.621085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.789100</td>\n",
       "      <td>1.375100</td>\n",
       "      <td>0.450448</td>\n",
       "      <td>0.637871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.789100</td>\n",
       "      <td>1.668144</td>\n",
       "      <td>0.501494</td>\n",
       "      <td>0.670420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>1.773287</td>\n",
       "      <td>0.503311</td>\n",
       "      <td>0.671238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 8.2e-5\n",
    "bs=4\n",
    "wd=0.01\n",
    "epochs= 4\n",
    "\n",
    "controller.fit(epochs,lr,\n",
    "               batch_size=bs,\n",
    "               weight_decay=wd,\n",
    "               save_checkpoint=False,\n",
    "               compute_metrics=compute_metrics_classification,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.trainer.model.save_pretrained('./sample_weights/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using trained model, using TDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer2concat': 4,\n",
       " 'is_multilabel': False,\n",
       " 'is_multihead': False,\n",
       " 'head_class_sizes': 10,\n",
       " 'head_class': that_nlp_library.models.roberta.classifiers.ConcatHeadSimple,\n",
       " 'classifier_dropout': 0.1}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_model_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sample_weights/my_model were not used when initializing RobertaHiddenStateConcatForSequenceClassification: ['body_model.pooler.dense.weight', 'body_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaHiddenStateConcatForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaHiddenStateConcatForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "trained_model = model_init_classification(model_class = RobertaHiddenStateConcatForSequenceClassification,\n",
    "                                          cpoint_path = Path('./sample_weights/my_model'), \n",
    "                                          output_hidden_states=True,\n",
    "                                          seed=42,\n",
    "                                          model_kwargs = _model_kwargs)\n",
    "\n",
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score]\n",
    "controller = ModelController(trained_model,tdm,metric_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Train/Validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction on all validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4885 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_val = controller.predict_ddict(ds_type='validation',batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Source</th>\n",
       "      <th>iteration</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - lam phien</td>\n",
       "      <td>5</td>\n",
       "      <td>google play</td>\n",
       "      <td>13</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.991197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google play - .. t . À mà họ nữ ưu m</td>\n",
       "      <td>5</td>\n",
       "      <td>google play</td>\n",
       "      <td>13</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.850162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google play - Cc lùa dao</td>\n",
       "      <td>5</td>\n",
       "      <td>google play</td>\n",
       "      <td>13</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.998358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google play - Mặt hàng sp mình đều nhỡ với Gia...</td>\n",
       "      <td>2</td>\n",
       "      <td>google play</td>\n",
       "      <td>13</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.984496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - Chưa tối ưu tốt cho Android Oppo...</td>\n",
       "      <td>3</td>\n",
       "      <td>google play</td>\n",
       "      <td>13</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.983986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label       Source   \n",
       "0                            google play - lam phien      5  google play  \\\n",
       "1               google play - .. t . À mà họ nữ ưu m      5  google play   \n",
       "2                           google play - Cc lùa dao      5  google play   \n",
       "3  google play - Mặt hàng sp mình đều nhỡ với Gia...      2  google play   \n",
       "4  google play - Chưa tối ưu tốt cho Android Oppo...      3  google play   \n",
       "\n",
       "   iteration   pred_L1  pred_prob_L1  \n",
       "0         13   Feature      0.991197  \n",
       "1         13    Others      0.850162  \n",
       "2         13    Others      0.998358  \n",
       "3         13  Delivery      0.984496  \n",
       "4         13   Feature      0.983986  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the label index to string, we can use the ```label_lists``` attribute of tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['label']= df_val['label'].apply(lambda x: tdm.label_lists[0][x]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5034901410417664"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_val.label,df_val.pred_L1,average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go through details on how to make a prediction on a completely new and raw dataset using our trained model. For now, let's reuse the sample csv and pretend it's our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Input Validation Precheck -----\n",
      "DataFrame contains duplicated values!\n",
      "-----> Number of duplications: 16 rows\n"
     ]
    }
   ],
   "source": [
    "df_test = TextDataMain.from_csv(Path('sample_data')/'sample_large.csv',return_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added the required columns as we defined in training process, and remove all the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['L1','L2'],axis=1)\n",
    "df_test['iteration']=df_val.iteration.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Content</th>\n",
       "      <th>iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google Play</td>\n",
       "      <td>App ncc lúc nào cx lag đơ, phần tìm kiếm thì v...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non Owned</td>\n",
       "      <td>..❗️ GÓC THANH LÝ Tính ra rẻ hơn cả mua #Shope...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google Play</td>\n",
       "      <td>Mắc gì người ta đặt hàng toàn lỗi 😃????</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owned</td>\n",
       "      <td>#GhienShopeePayawardT8 Khi bạn chơi shopee quá...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google Play</td>\n",
       "      <td>Rất bức xúc khi dùng . mã giảm giá người dùng ...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source                                            Content  iteration\n",
       "0  Google Play  App ncc lúc nào cx lag đơ, phần tìm kiếm thì v...         21\n",
       "1    Non Owned  ..❗️ GÓC THANH LÝ Tính ra rẻ hơn cả mua #Shope...         21\n",
       "2  Google Play            Mắc gì người ta đặt hàng toàn lỗi 😃????         21\n",
       "3        Owned  #GhienShopeePayawardT8 Khi bạn chơi shopee quá...         21\n",
       "4  Google Play  Rất bức xúc khi dùng . mã giảm giá người dùng ...         21"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a DatasetDict for this test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Getting Test Set --------------------\n",
      "----- Input Validation Precheck -----\n",
      "DataFrame contains duplicated values!\n",
      "-----> Number of duplications: 19 rows\n",
      "-------------------- Start Test Set Transformation --------------------\n",
      "----- Metadata Simple Processing & Concatenating to Main Content -----\n",
      "-------------------- Text Transformation --------------------\n",
      "----- text_normalize -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2269/2269 [00:00<00:00, 3120.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Test Leak Checking --------------------\n",
      "- Before leak check\n",
      "Size: 2269\n",
      "- After leak check\n",
      "Size: 2080\n",
      "- Number of rows leaked: 189, or 8.33% of the original validation (or test) data\n",
      "-------------------- Construct DatasetDict --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ddict = tdm.get_test_datasetdict_from_df(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text', 'Source', 'iteration', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ddict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test data has been processed + transformed (but not augmented) the same way as the validation set. Now we can start making the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "controller = ModelController(model,tdm)\n",
    "df_result = controller.predict_ddict(ddict=test_ddict,ds_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Source</th>\n",
       "      <th>iteration</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - App ncc lúc nào cx lag đơ , phần...</td>\n",
       "      <td>google play</td>\n",
       "      <td>21</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.997287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non owned - .. ❗ ️ GÓC THANH LÝ Tính ra rẻ hơn...</td>\n",
       "      <td>non owned</td>\n",
       "      <td>21</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.999744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google play - Mắc gì người ta đặt hàng toàn lỗ...</td>\n",
       "      <td>google play</td>\n",
       "      <td>21</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.959076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owned - # GhienShopeePayawardT8 Khi bạn chơi s...</td>\n",
       "      <td>owned</td>\n",
       "      <td>21</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>0.999123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - Rất bức xúc khi dùng . mã giảm g...</td>\n",
       "      <td>google play</td>\n",
       "      <td>21</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.997365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       Source  iteration   \n",
       "0  google play - App ncc lúc nào cx lag đơ , phần...  google play         21  \\\n",
       "1  non owned - .. ❗ ️ GÓC THANH LÝ Tính ra rẻ hơn...    non owned         21   \n",
       "2  google play - Mắc gì người ta đặt hàng toàn lỗ...  google play         21   \n",
       "3  owned - # GhienShopeePayawardT8 Khi bạn chơi s...        owned         21   \n",
       "4  google play - Rất bức xúc khi dùng . mã giảm g...  google play         21   \n",
       "\n",
       "      pred_L1  pred_prob_L1  \n",
       "0     Feature      0.997287  \n",
       "1      Others      0.999744  \n",
       "2     Feature      0.959076  \n",
       "3  Commercial      0.999123  \n",
       "4     Feature      0.997365  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even predict top k results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Start making predictions --------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Source</th>\n",
       "      <th>iteration</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "      <th>pred_L1_top1</th>\n",
       "      <th>pred_L1_top2</th>\n",
       "      <th>pred_L1_top3</th>\n",
       "      <th>pred_prob_L1_top1</th>\n",
       "      <th>pred_prob_L1_top2</th>\n",
       "      <th>pred_prob_L1_top3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - App ncc lúc nào cx lag đơ , phần...</td>\n",
       "      <td>google play</td>\n",
       "      <td>21</td>\n",
       "      <td>[3, 9, 5]</td>\n",
       "      <td>[0.99728715, 0.0009524937, 0.00058025133]</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Shopee account</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.997287</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non owned - .. ❗ ️ GÓC THANH LÝ Tính ra rẻ hơn...</td>\n",
       "      <td>non owned</td>\n",
       "      <td>21</td>\n",
       "      <td>[5, 1, 3]</td>\n",
       "      <td>[0.9997445, 8.3330306e-05, 4.366889e-05]</td>\n",
       "      <td>Others</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.999744</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google play - Mắc gì người ta đặt hàng toàn lỗ...</td>\n",
       "      <td>google play</td>\n",
       "      <td>21</td>\n",
       "      <td>[3, 5, 9]</td>\n",
       "      <td>[0.95907587, 0.03484495, 0.0030704038]</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Others</td>\n",
       "      <td>Shopee account</td>\n",
       "      <td>0.959076</td>\n",
       "      <td>0.034845</td>\n",
       "      <td>0.003070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owned - # GhienShopeePayawardT8 Khi bạn chơi s...</td>\n",
       "      <td>owned</td>\n",
       "      <td>21</td>\n",
       "      <td>[1, 6, 3]</td>\n",
       "      <td>[0.99912256, 0.0005796181, 6.469468e-05]</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Payment</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.999123</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google play - Rất bức xúc khi dùng . mã giảm g...</td>\n",
       "      <td>google play</td>\n",
       "      <td>21</td>\n",
       "      <td>[3, 9, 5]</td>\n",
       "      <td>[0.9973652, 0.0006989358, 0.00043120742]</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Shopee account</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.997365</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.000431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       Source  iteration   \n",
       "0  google play - App ncc lúc nào cx lag đơ , phần...  google play         21  \\\n",
       "1  non owned - .. ❗ ️ GÓC THANH LÝ Tính ra rẻ hơn...    non owned         21   \n",
       "2  google play - Mắc gì người ta đặt hàng toàn lỗ...  google play         21   \n",
       "3  owned - # GhienShopeePayawardT8 Khi bạn chơi s...        owned         21   \n",
       "4  google play - Rất bức xúc khi dùng . mã giảm g...  google play         21   \n",
       "\n",
       "     pred_L1                               pred_prob_L1 pred_L1_top1   \n",
       "0  [3, 9, 5]  [0.99728715, 0.0009524937, 0.00058025133]      Feature  \\\n",
       "1  [5, 1, 3]   [0.9997445, 8.3330306e-05, 4.366889e-05]       Others   \n",
       "2  [3, 5, 9]     [0.95907587, 0.03484495, 0.0030704038]      Feature   \n",
       "3  [1, 6, 3]   [0.99912256, 0.0005796181, 6.469468e-05]   Commercial   \n",
       "4  [3, 9, 5]   [0.9973652, 0.0006989358, 0.00043120742]      Feature   \n",
       "\n",
       "     pred_L1_top2    pred_L1_top3  pred_prob_L1_top1  pred_prob_L1_top2   \n",
       "0  Shopee account          Others           0.997287           0.000952  \\\n",
       "1      Commercial         Feature           0.999744           0.000083   \n",
       "2          Others  Shopee account           0.959076           0.034845   \n",
       "3         Payment         Feature           0.999123           0.000580   \n",
       "4  Shopee account          Others           0.997365           0.000699   \n",
       "\n",
       "   pred_prob_L1_top3  \n",
       "0           0.000580  \n",
       "1           0.000044  \n",
       "2           0.003070  \n",
       "3           0.000065  \n",
       "4           0.000431  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = controller.predict_ddict(ddict=test_ddict,ds_type='test',topk=3)\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want to make a prediction on a small amount of data (single sentence, or a few sentences), we can use `ModelController.predict_raw_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have some metadatas, we need to define a dictionary (to imitate a DatasetDict)\n",
    "raw_content={\n",
    "    'Source': 'Google play',\n",
    "    'iteration':21,\n",
    "    'Content':'Tôi không thích Shopee.Tại vì dùng app rất chậm,lag banh nhà lầu, thậm chí log in còn không đc'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't use metadata, we can use something like this: \n",
    "\n",
    "```raw_content='Tôi không thích Shopee.Tại vì dùng app rất chậm,lag banh nhà lầu, thậm chí log in còn không đc'```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 4981.36it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Source</th>\n",
       "      <th>iteration</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - Tôi không thích Shopee . Tại vì ...</td>\n",
       "      <td>google play</td>\n",
       "      <td>21</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.997374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       Source  iteration   \n",
       "0  google play - Tôi không thích Shopee . Tại vì ...  google play         21  \\\n",
       "\n",
       "   pred_L1  pred_prob_L1  \n",
       "0  Feature      0.997374  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = controller.predict_raw_text(raw_content,topk=1)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 6887.20it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Source</th>\n",
       "      <th>iteration</th>\n",
       "      <th>pred_L1</th>\n",
       "      <th>pred_prob_L1</th>\n",
       "      <th>pred_L1_top1</th>\n",
       "      <th>pred_L1_top2</th>\n",
       "      <th>pred_prob_L1_top1</th>\n",
       "      <th>pred_prob_L1_top2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google play - Tôi không thích Shopee . Tại vì ...</td>\n",
       "      <td>google play</td>\n",
       "      <td>21</td>\n",
       "      <td>[3, 9]</td>\n",
       "      <td>[0.99737394, 0.00059575593]</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Shopee account</td>\n",
       "      <td>0.997374</td>\n",
       "      <td>0.000596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>owned - App này xài được . Mua đồ rẻ ghê , đượ...</td>\n",
       "      <td>owned</td>\n",
       "      <td>21</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>[0.99925727, 0.00019265412]</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Feature</td>\n",
       "      <td>0.999257</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       Source  iteration   \n",
       "0  google play - Tôi không thích Shopee . Tại vì ...  google play         21  \\\n",
       "1  owned - App này xài được . Mua đồ rẻ ghê , đượ...        owned         21   \n",
       "\n",
       "  pred_L1                 pred_prob_L1 pred_L1_top1    pred_L1_top2   \n",
       "0  [3, 9]  [0.99737394, 0.00059575593]      Feature  Shopee account  \\\n",
       "1  [1, 3]  [0.99925727, 0.00019265412]   Commercial         Feature   \n",
       "\n",
       "   pred_prob_L1_top1  pred_prob_L1_top2  \n",
       "0           0.997374           0.000596  \n",
       "1           0.999257           0.000193  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_content={\n",
    "    'Source': ['Google play','Owned'],\n",
    "    'iteration':[21,21],\n",
    "    'Content':['Tôi không thích Shopee.Tại vì dùng app rất chậm,lag banh nhà lầu, thậm chí log in còn không đc',\n",
    "               'App này xài được. Mua đồ rẻ ghê, được voucher nhiều nữa']\n",
    "            }\n",
    "df_result = controller.predict_raw_text(raw_content,topk=2)\n",
    "df_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
