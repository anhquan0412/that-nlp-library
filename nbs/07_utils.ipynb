{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils\n",
    "\n",
    "> This module contains some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from tqdm import tqdm\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "from functools import partial, reduce\n",
    "import dill as pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Callable, Any\n",
    "from collections.abc import Iterable\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HiddenPrints:\n",
    "    \"To hide print command when called\"\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def val2iterable(val,lsize=1,t='list'):\n",
    "    \"Convert an element (nonlist value) to an iterable. Currently support list and nparray\"\n",
    "    if not isinstance(val, Iterable) or isinstance(val,str):\n",
    "        if t=='list': val=[val for i in range(lsize)]\n",
    "        elif t=='nparray': val=np.repeat(val,lsize)\n",
    "        else:\n",
    "            raise ValueError('Unrecognized iterable to convert to')\n",
    "    return val\n",
    "\n",
    "def create_dir(path_dir):\n",
    "    \"Create directory if needed\"\n",
    "    path_dir = Path(path_dir)\n",
    "    if not path_dir.exists():\n",
    "        path_dir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def check_and_get_attribute(obj,attr_name):\n",
    "    if hasattr(obj,attr_name): return getattr(obj,attr_name)\n",
    "    else: raise ValueError(f\"Missing required argument: {attr_name}\")\n",
    "            \n",
    "def callable_name(any_callable: Callable[..., Any]) -> str:\n",
    "    \"To get name of any callable\"\n",
    "    if hasattr(any_callable, '__name__'):\n",
    "        return any_callable.__name__\n",
    "    if isinstance(any_callable, partial):\n",
    "        return any_callable.func.__name__\n",
    "\n",
    "    return str(any_callable)\n",
    "\n",
    "def print_msg(msg,dash_num=5,verbose=True):\n",
    "    if verbose:\n",
    "        print('-'*dash_num+' '+msg+' '+ '-'*dash_num)\n",
    "\n",
    "def seed_notorch(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "def seed_everything(seed=42):\n",
    "    seed_notorch(seed=seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "def save_to_pickle(my_list,fname,parent='pickle_files'):\n",
    "    if fname[-4:]!='.pkl': fname+='.pkl'\n",
    "    p = Path(parent)\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    fname = p/fname\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(my_list, f)\n",
    "        \n",
    "def load_pickle(fname,parent='pickle_files'):\n",
    "    if fname[-4:]!='.pkl': fname+='.pkl'\n",
    "    with open(Path(parent)/fname,'rb') as f:\n",
    "        my_list = pickle.load(f)\n",
    "    return my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def check_input_validation(df:pd.DataFrame,verbose=True):\n",
    "    verboseprint = print if verbose else lambda *a, **k: None\n",
    "    print_msg('Input Validation Precheck',verbose)\n",
    "    # check whether index is sorted\n",
    "    correct_idxs = np.arange(df.shape[0])\n",
    "    curr_idxs = df.index.values\n",
    "    if not np.array_equal(correct_idxs,curr_idxs):\n",
    "        verboseprint(\"DataFrame Index is not RangeIndex, and will be converted\")\n",
    "        df.index = correct_idxs\n",
    "\n",
    "    # Do a NA check:\n",
    "    na_check = df.isna().sum(axis=0)\n",
    "    na_check = na_check[na_check!=0]\n",
    "    if na_check.shape[0]!=0:\n",
    "        verboseprint(\"Data contains missing values!\")\n",
    "        verboseprint('-----> List of columns and the number of missing values for each')\n",
    "        verboseprint(na_check)\n",
    "\n",
    "    # Do a row duplication check\n",
    "    _df = df.copy().astype(str)\n",
    "    dup_check = _df.value_counts(dropna=False)\n",
    "    dup_check=dup_check[dup_check>1]\n",
    "    if dup_check.shape[0]!=0:\n",
    "        verboseprint(\"Data contains duplicated values!\")\n",
    "        verboseprint(f'-----> Number of duplications: {(dup_check.values-1).sum()} rows')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def check_text_leaking(trn_txt:list,\n",
    "                       test_txt:list,verbose=True):\n",
    "    verboseprint = print if verbose else lambda *a, **k: None\n",
    "    test_txt_leaked = {i.strip().lower() for i in trn_txt} & {j.strip().lower() for j in test_txt}\n",
    "    len_leaked = len(test_txt_leaked)\n",
    "    verboseprint(f'- Number of rows leaked: {len_leaked}, which is {100*len_leaked/len(trn_txt):.2f}% of training set')\n",
    "    return test_txt_leaked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def none2emptystr(x):\n",
    "    if x is None: return ''\n",
    "    return str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lambda_batch(inp, # HuggingFace Dataset\n",
    "                     feature, # Feature name.\n",
    "                     func, # The function to apply\n",
    "                     is_batched, # Whether batching is applied\n",
    "                    ):\n",
    "    return [func(v) for v in inp[feature]] if is_batched else func(inp[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lambda_map_batch(inp, # HuggingFace Dataset\n",
    "                     feature, # Feature name.\n",
    "                     func, # The function to apply\n",
    "                     is_batched, # Whether batching is applied\n",
    "                     output_feature=None, # New feature output, if different from 'feature'\n",
    "                     is_func_batched=False # Whether the func above only works with batch\n",
    "                    ):\n",
    "    results={}\n",
    "    if output_feature is None: output_feature = feature\n",
    "    if not is_func_batched:\n",
    "        results[output_feature] = lambda_batch(inp,feature,func,is_batched)\n",
    "    else:\n",
    "        results[output_feature] = func(inp[feature]) if is_batched else func([inp[feature]])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def augmentation_helper(inp,text_name,func):\n",
    "    # inp[text_name] will be list\n",
    "    inp[text_name]=[func(v) for v in val2iterable(inp[text_name])]\n",
    "    return inp\n",
    "\n",
    "def augmentation_stream_generator(dset,text_name,func):\n",
    "    for inp in dset:\n",
    "        # inp[text_name] will be a single item\n",
    "        inp[text_name]=func(inp[text_name])\n",
    "        yield inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def func_all(x, functions):\n",
    "    return reduce(lambda acc, func: func(acc), functions, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    A numerically stable version of the logistic sigmoid function.\n",
    "    \n",
    "    Source: assignment3 of cs231n\n",
    "    \"\"\"\n",
    "    pos_mask = (x >= 0)\n",
    "    neg_mask = (x < 0)\n",
    "    z = np.zeros_like(x)\n",
    "    z[pos_mask] = np.exp(-x[pos_mask])\n",
    "    z[neg_mask] = np.exp(x[neg_mask])\n",
    "    top = np.ones_like(x)\n",
    "    top[neg_mask] = z[neg_mask]\n",
    "    return top / (1 + z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/fastai_v2/lib/python3.10/site-packages/nbdev/export.py:54: UserWarning: Notebook '/home/quan/kwon/that-nlp-library/nbs/00_text_main.ipynb' uses `#|export` without `#|default_exp` cell.\n",
      "Note nbdev2 no longer supports nbdev1 syntax. Run `nbdev_migrate` to upgrade.\n",
      "See https://nbdev.fast.ai/getting_started.html for more information.\n",
      "  warn(f\"Notebook '{nbname}' uses `#|export` without `#|default_exp` cell.\\n\"\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
