{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to that-nlp-library\n",
    "\n",
    "> Aim to be one of the most convenient library for common NLP tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install that_nlp_library\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is advised that you manually install torch (with your compatible cuda version if you GPU). Typically it's\n",
    "\n",
    "```sh\n",
    "pip3 install torch\n",
    "```\n",
    "\n",
    "Visit [Pytorch page](https://pytorch.org/) for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. High-Level Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For supervised learning, the main pipeline contains 2 parts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`TextDataController`**: For High-Speed and Customizable Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a list of processings that you can use (in order). You also can skip any processing if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of the Text Controller for a classification task (predict `Division Name`), without any text preprocessing. The code will also tokenize your text field.\n",
    "\n",
    "```python3\n",
    "tdc = TextDataController.from_csv('sample_data/Womens_Clothing_Reviews.csv',\n",
    "                                  main_text='Review Text',\n",
    "                                  label_names='Division Name',\n",
    "                                  sup_types='classification',                                  \n",
    "                                 )\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "tdc.process_and_tokenize(tokenizer,max_length=100,shuffle_trn=True)\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is an example when all processings are applied\n",
    "\n",
    "\n",
    "```python3\n",
    "\n",
    "# define a custom augmentation function\n",
    "from underthesea import text_normalize\n",
    "import nlpaug.augmenter.char as nac\n",
    "\n",
    "def nlp_aug(x,aug=None):\n",
    "    results = aug.augment(x)\n",
    "    if not isinstance(x,list): return results[0]\n",
    "    return results\n",
    "aug = nac.KeyboardAug(aug_char_max=3,aug_char_p=0.1,aug_word_p=0.07)\n",
    "nearby_aug_func = partial(nlp_aug,aug=aug)\n",
    "\n",
    "# initialize the TextDataController\n",
    "tdc = TextDataController.from_csv(dset,\n",
    "                                  main_text='Review Text',\n",
    "                                  \n",
    "                                  # metadatas\n",
    "                                  metadatas='Title',\n",
    "                                  \n",
    "                                  # label\n",
    "                                  label_names='Division Name',\n",
    "                                  sup_types='classification',\n",
    "                                  label_tfm_dict={'Division Name': lambda x: x if x!='Initmates' else 'Intimates'},\n",
    "                                  \n",
    "                                  # row filter\n",
    "                                  filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                               'Division Name': lambda x: x is not None,\n",
    "                                              },\n",
    "                                              \n",
    "                                  # text transformation\n",
    "                                  content_transformation=[text_normalize,str.lower],\n",
    "                                  \n",
    "                                  # validation split\n",
    "                                  val_ratio=0.2,\n",
    "                                  stratify_cols=['Division Name'],\n",
    "                                  \n",
    "                                  # upsampling\n",
    "                                  upsampling_list=[('Division Name',lambda x: x=='Intimates')]\n",
    "                                  \n",
    "                                  # text augmentation\n",
    "                                  content_augmentations=nearby_aug_func\n",
    "                                 )\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "tdc.process_and_tokenize(tokenizer,max_length=100,shuffle_trn=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an in-depth tutorial on Text Controller for Supervised Learning (`TextDataController`), please visit [here](https://anhquan0412.github.io/that-nlp-library/text_main.html)\n",
    "\n",
    "This library also supports a **streamed version of Text Controller** (`TextDataControllerStreaming`), allowing you to work with data without having it entirely on your memory. You can still perform all the processings in the non-streamed version, except for *Train/Validation split* (which means you have to define your validation set beforehand), and *Upsampling*. \n",
    "\n",
    "For more details on **streaming**, visit [how to create a streamed dataset](https://anhquan0412.github.io/that-nlp-library/text_main_streaming.html) and [how to train a model with a streamed dataset](https://anhquan0412.github.io/that-nlp-library/roberta_singlehead_for_streaming)\n",
    "\n",
    "If you are curious on the time and space efficiency between streamed and non-streamed version, visit the benchmark [here](https://anhquan0412.github.io/that-nlp-library/text_main_benchmark.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`ModelController`**: For customizable model training/inference/interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of using `ModelController` to train a simple 6-class classification RoBERTa model, with the data and the preprocessing steps stored in our previous `TextDataController` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python3\n",
    "\n",
    "# Load the model from HuggingFace, with the number of classes defined in our TextDataController object\n",
    "num_labels = len(tdc.label_lists[0])\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base',num_labels=num_labels)\n",
    "\n",
    "\n",
    "# Create the `ModelController` object\n",
    "controller = ModelController(model,data_store=tdc,seed=42)\n",
    "\n",
    "# You can define multiple metrics for model evaluation\n",
    "metric_funcs = [partial(f1_score,average='macro'),accuracy_score] \n",
    "\n",
    "# Training the model for 3 epochs, and save all checkpoints to 'my_saved_weights' directory\n",
    "controller.fit(epochs = 3,\n",
    "               learning_rate = 1e-4,\n",
    "               metric_funcs = metric_funcs,\n",
    "               batch_size = 32,\n",
    "               save_checkpoint=True,\n",
    "               o_dir='my_saved_weights',\n",
    "               compute_metrics=compute_metrics\n",
    "              )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library can perform the following:\n",
    "\n",
    "- **[Classification](https://anhquan0412.github.io/that-nlp-library/model_classification_tutorial.html)**\n",
    "\n",
    "- **[Regression](https://anhquan0412.github.io/that-nlp-library/roberta_multihead_regression.html)**\n",
    "\n",
    "- **[Multilabel classification](https://anhquan0412.github.io/that-nlp-library/roberta_multilabel.html)**\n",
    "\n",
    "- **[Multiheads](https://anhquan0412.github.io//that-nlp-library/roberta_multihead.html)**, where each head can be either classification or regression\n",
    "\n",
    "    - \"Multihead\" is when your model needs to predict multiple outputs at once, for example, given a sentence (e.g. a review on an e-commerce site), you have to predict what category the sentence is about, and the sentiment of the sentence, and maybe the rating of the sentence.\n",
    "\n",
    "    - For the above example, this is a 3-head problem: classification (for category), classification (for sentiment), and regression (for rating from 1 to 5)\n",
    "   \n",
    "   \n",
    "- For 2-head classification where there’s hierarchical relationship between the first output and the second output (e.g. the first output is level 1 clothing category, and the second output is the level 2 clothing subcategory), you can utilize two specific approaches for this use-case: training with [conditional probability](https://anhquan0412.github.io/that-nlp-library/roberta_conditional_prob.html), or with [deep hierarchical classification](https://anhquan0412.github.io/that-nlp-library/roberta_dhc.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoupling of Text Controller and Model Controller\n",
    "\n",
    "In this library, you can utilize `TextDataController` only to handle all the text processings, and have the final processed-HuggingFace-DatasetDict returned to you. But if you have your own processed DatasetDict, you can skip the `TextDataController` and use only the `ModelController` for training your data. There’s a quick tutorial on this decoupling [here](https://anhquan0412.github.io/that-nlp-library/model_classification_tutorial.html#b-train-model-with-only-a-tokenized-datasetdict-no-textdatacontroller)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For language modeling, the main pipeline also contains 2 parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`TextDataLMController`**: Text Data Controller for Language Model\n",
    "\n",
    "Similarly to `TextDataController`, `TextDataLMController` also provide a list of processings (except for *Label Processing*, *Upsampling* and *Text Augmentation*). The controller also allows tokenization line-by-line or by token concatenation. \n",
    "\n",
    "Visit the tutorial [here](https://anhquan0412.github.io/that-nlp-library/text_main_lm.html)\n",
    "\n",
    "There’s also a streamed version (`TextDataLMControllerStreaming`). Here is a [tutorial on how to train a language model with a streamed dataset](https://anhquan0412.github.io/that-nlp-library/roberta_lm_for_streaming.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`ModelLMController`**: Language Model Controller\n",
    "\n",
    "The library can train a [masked language modeling](https://anhquan0412.github.io/that-nlp-library/model_lm_roberta_tutorial.html) (BERT, RoBERTa …) or a [causal language model](https://anhquan0412.github.io/that-nlp-library/model_lm_gpt2_tutorial.html) (GPT) either from scratch or from existing pretrained language models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden States Extraction\n",
    "\n",
    "The library also allow you to [extract the hidden states](https://anhquan0412.github.io/that-nlp-library/hidden_states.html) of your choice, for further analysis or other downstream tasks that requires a vector representation of your text input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Documentation\n",
    "\n",
    "Visit [https://anhquan0412.github.io/that-nlp-library/](https://anhquan0412.github.io/that-nlp-library/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
