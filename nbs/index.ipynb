{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to that-nlp-library\n",
    "\n",
    "> Aim to be one of the most convenient library for common NLP tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install that_nlp_library\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is advised that you manually install torch (with your compatible cuda version if you GPU). Typically it's\n",
    "\n",
    "```sh\n",
    "pip3 install torch --index-url https://download.pytorch.org/whl/cu118\n",
    "```\n",
    "\n",
    "Visit [Pytorch page](https://pytorch.org/) for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-Level Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For supervised learning, the main pipeline contains 2 parts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Text Data Controller: `TextDataController` (for text processing)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a list of processings that you can use (in order). You also can skip any processing if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/text_processings.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of the Text Controller for a classification task (predict `Division Name`), without any text preprocessing. The code will also tokenize your text field.\n",
    "\n",
    "```python3\n",
    "tdc = TextDataController.from_csv('sample_data/Womens_Clothing_Reviews.csv',\n",
    "                                  main_text='Review Text',\n",
    "                                  label_names='Division Name',\n",
    "                                  sup_types='classification',                                  \n",
    "                                 )\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "tdc.process_and_tokenize(tokenizer,max_length=100,shuffle_trn=True)\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is an example when all processings are applied\n",
    "```python3\n",
    "from underthesea import text_normalize\n",
    "import nlpaug.augmenter.char as nac\n",
    "\n",
    "# define the augmentation function\n",
    "def nlp_aug(x,aug=None):\n",
    "    results = aug.augment(x)\n",
    "    if not isinstance(x,list): return results[0]\n",
    "    return results\n",
    "aug = nac.KeyboardAug(aug_char_max=3,aug_char_p=0.1,aug_word_p=0.07)\n",
    "nearby_aug_func = partial(nlp_aug,aug=aug)\n",
    "\n",
    "# initialize the TextDataController\n",
    "tdc = TextDataController.from_csv(dset,\n",
    "                                  main_text='Review Text',\n",
    "                                  \n",
    "                                  # metadatas\n",
    "                                  metadatas='Title',\n",
    "                                  \n",
    "                                  # label\n",
    "                                  label_names='Division Name',\n",
    "                                  sup_types='classification',\n",
    "                                  label_tfm_dict={'Division Name': lambda x: x if x!='Initmates' else 'Intimates'},\n",
    "                                  \n",
    "                                  # row filter\n",
    "                                  filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                               'Division Name': lambda x: x is not None,\n",
    "                                              },\n",
    "                                              \n",
    "                                  # text transformation\n",
    "                                  content_transformation=[text_normalize,str.lower],\n",
    "                                  \n",
    "                                  # validation split\n",
    "                                  val_ratio=0.2,\n",
    "                                  stratify_cols=['Division Name'],\n",
    "                                  \n",
    "                                  # upsampling\n",
    "                                  upsampling_list=[('Division Name',lambda x: x=='Intimates')]\n",
    "                                  \n",
    "                                  # text augmentation\n",
    "                                  content_augmentations=nearby_aug_func\n",
    "                                 )\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "tdc.process_and_tokenize(tokenizer,max_length=100,shuffle_trn=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an in-depth tutorial on Text Controller for Supervised Learning (`TextDataController`), please visit [here](https://anhquan0412.github.io/that-nlp-library/text_main.html)\n",
    "\n",
    "This library also a **streamed version of Text Controller** (`TextDataControllerStreaming`), allowing you to work with data without having it entirely on your hard drive. You can still perform all the processings in the non-streamed version, except for **Train/Validation split** (which means you have to define your validation set beforehand), and **Upsampling**. \n",
    "\n",
    "For more details on **streaming**, visit [how to create a streamed dataset](https://anhquan0412.github.io/that-nlp-library/text_main_streaming.html) and [how to train a model with a streamed dataset](https://anhquan0412.github.io/that-nlp-library/roberta_singlehead_for_streaming)\n",
    "\n",
    "If you are curious on the time and space efficiency between streamed and non-streamed version, visit the benchmark [here](https://anhquan0412.github.io/that-nlp-library/text_main_benchmark.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model and `ModelController`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library can perform the following:\n",
    "\n",
    "- **Classification ([simple tutorial](https://anhquan0412.github.io/that-nlp-library/model_classification_tutorial.html))**\n",
    "\n",
    "- **[Regression](https://anhquan0412.github.io/that-nlp-library/roberta_multihead_regression.html)**\n",
    "\n",
    "- **[Multilabel classification](https://anhquan0412.github.io/that-nlp-library/roberta_multilabel.html)**\n",
    "\n",
    "- **[Multiheads](https://anhquan0412.github.io//that-nlp-library/roberta_multihead.html)**, where each head can be either classification or regression\n",
    "\n",
    "    - \"Multihead\" is when your model needs to predict multiple outputs at once, for example, given a sentence (e.g. a review on an e-commerce site), you have to predict what category the sentence is about, and the sentiment of the sentence, and maybe the rating of the sentence.\n",
    "\n",
    "    - For the above example, this is a 3-head problem: classification (for category), classification (for sentiment), and regression (for rating from 1 to 5)\n",
    "   \n",
    "   \n",
    "- For 2-head classification where there’s hierarchical relationship between the first output and the second output (e.g. the first output is level 1 clothing category, and the second output is the level 2 clothing subcategory), you can utilize two specific approaches for this use-case: training with [conditional probability](https://anhquan0412.github.io/that-nlp-library/roberta_conditional_prob.html), or with [deep hierarchical classification](https://anhquan0412.github.io/that-nlp-library/roberta_dhc.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoupling of Text Controller and Model Controller\n",
    "\n",
    "In this library, you can either use `TextDataController` only to handle all the text processings, and have the final processed-HuggingFace-DatasetDict returned to you. But if you have your own processed DatasetDict, you can skip the text controller and use only the `ModelController` for training your data. There’s a quick tutorial on this decoupling [here](https://anhquan0412.github.io/that-nlp-library/model_classification_tutorial.html#train-model-with-only-a-tokenized-datasetdict-no-textdatacontroller)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For language modeling, the main pipeline also contains 2 parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Data Controlelr for Language Model: `TextDataLMController`\n",
    "\n",
    "Similarly to `TextDatController`, `TextDataLMController` also provide a list of processings (except for **Label Processing**, **Upsampling** and **Text Augmentation**). The controller also allow tokenization line-by-line or by token concatenation. \n",
    "Visit the tutorial [here](https://anhquan0412.github.io/that-nlp-library/text_main_lm.html)\n",
    "\n",
    "There’s also a streamed version (`TextDataLMControllerStreaming`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Model Controller: `ModelLMController`\n",
    "\n",
    "The library can train a [masked language modeling](https://anhquan0412.github.io/that-nlp-library/model_lm_roberta_tutorial.html) (BERT, roBERTa …) or a [causal language model](https://anhquan0412.github.io/that-nlp-library/model_lm_gpt2_tutorial.html) (GPT) either from scratch or from existing pretrained language models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden States Extraction\n",
    "\n",
    "The library also allow you to [extract the hidden states](https://anhquan0412.github.io/that-nlp-library/hidden_states.html) of your choice, for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "\n",
    "Visit [https://anhquan0412.github.io/that-nlp-library/](https://anhquan0412.github.io/that-nlp-library/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
