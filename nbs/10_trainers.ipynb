{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c7090c",
   "metadata": {},
   "source": [
    "# Trainer\n",
    "\n",
    "> This module contains code to build custom HuggingFace Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a435658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179fb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04814bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from transformers import Trainer,get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858517a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_cosine_restart_class(warmup_ratio=0.1,num_cycles=2):\n",
    "    \"\"\"\n",
    "    Class getter for a Trainer that consists of Cosine Restart with Muptiple Cycles LR Scheduler\n",
    "    \n",
    "    Source: https://discuss.huggingface.co/t/how-do-use-lr-scheduler/4046/8\n",
    "    \"\"\"\n",
    "    class CustomTrainer(Trainer):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            self.warmup_ratio=warmup_ratio\n",
    "            self.num_cycles=num_cycles\n",
    "            super().__init__(*args, **kwargs)\n",
    "\n",
    "        def create_optimizer_and_scheduler(self, num_training_steps):\n",
    "            self.optimizer = AdamW(self.model.parameters(),\n",
    "                                   lr=self.args.learning_rate,\n",
    "                                   weight_decay=self.args.weight_decay)\n",
    "            self.lr_scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(\n",
    "                 self.optimizer, int(self.warmup_ratio*num_training_steps), num_training_steps, num_cycles=self.num_cycles)    \n",
    "    return CustomTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a524ccf",
   "metadata": {},
   "source": [
    "This can be used as a Trainer for any tasks, either supervised (classification/regression/multilabel ...) or semi-supervised (language model) on any model, either vanilla or customed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf58513",
   "metadata": {},
   "source": [
    "Example: Training a `RobertaHiddenStateConcatForSequenceClassification` model with Cosine Restart LR scheduler for **2 cycles** with **warmup ratio of 0.01**\n",
    "\n",
    "```python3\n",
    "model_name='roberta-base'\n",
    "roberta_body = RobertaModel.from_pretrained(model_name)\n",
    "\n",
    "model = model_init_classification(model_class = RobertaHiddenStateConcatForSequenceClassification,\n",
    "                                  cpoint_path = model_name, \n",
    "                                  output_hidden_states=True,\n",
    "                                  seed=seed,\n",
    "                                  body_model=roberta_body,\n",
    "                                  model_kwargs = _model_kwargs)\n",
    "controller = ModelController(model,tdc,seed=seed)\n",
    "\n",
    "metric_funcs = partial(f1_score,average='macro')\n",
    "trainer_class = get_cosine_restart_class(warmup_ratio=0.01,num_cycles=2)\n",
    "\n",
    "controller.fit(epochs=8,\n",
    "               learning_rate=1e-4,\n",
    "               batch_size=64,\n",
    "               save_checkpoint=False,\n",
    "               metric_funcs=metric_funcs,\n",
    "               trainer_class=trainer_class,\n",
    "               compute_metrics=compute_metrics,\n",
    "              )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d476e79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e44599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
