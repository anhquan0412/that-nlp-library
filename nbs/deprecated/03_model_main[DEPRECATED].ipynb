{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Main Functions and Controller \n",
    "\n",
    "> For an in-depth tutorial, click [here](https://anhquan0412.github.io/that-nlp-library/model_main_envibert.html)\n",
    "\n",
    "- skip_showdoc: true\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-nlp-library/blob/main/that_nlp_library/model_main.py#L23){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### model_init_classification\n",
       "\n",
       ">      model_init_classification (model_class, cpoint_path,\n",
       ">                                 output_hidden_states:bool, device=None,\n",
       ">                                 seed=42, body_model=None, model_kwargs={})\n",
       "\n",
       "To initialize a classification model, either from an existing HuggingFace model or custom architecture\n",
       "\n",
       "Can be used for binary, multi-class single-head, multi-class \"two-head\", and multi-label clasisifcation\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model_class |  |  | Model's class object, e.g. RobertaHiddenStateConcatForSequenceClassification |\n",
       "| cpoint_path |  |  | Either model string name on HuggingFace, or the path to model checkpoint |\n",
       "| output_hidden_states | bool |  | To whether output the model hidden states or not. Useful when you try to build a custom classification head |\n",
       "| device | NoneType | None | Device to train on |\n",
       "| seed | int | 42 | Random seed |\n",
       "| body_model | NoneType | None | If not none, we use this to initialize model's body. If you only want to load the model checkpoint in cpoint_path, leave this as none |\n",
       "| model_kwargs | dict | {} | Keyword arguments for model (both head and body) |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-nlp-library/blob/main/that_nlp_library/model_main.py#L23){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### model_init_classification\n",
       "\n",
       ">      model_init_classification (model_class, cpoint_path,\n",
       ">                                 output_hidden_states:bool, device=None,\n",
       ">                                 seed=42, body_model=None, model_kwargs={})\n",
       "\n",
       "To initialize a classification model, either from an existing HuggingFace model or custom architecture\n",
       "\n",
       "Can be used for binary, multi-class single-head, multi-class \"two-head\", and multi-label clasisifcation\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model_class |  |  | Model's class object, e.g. RobertaHiddenStateConcatForSequenceClassification |\n",
       "| cpoint_path |  |  | Either model string name on HuggingFace, or the path to model checkpoint |\n",
       "| output_hidden_states | bool |  | To whether output the model hidden states or not. Useful when you try to build a custom classification head |\n",
       "| device | NoneType | None | Device to train on |\n",
       "| seed | int | 42 | Random seed |\n",
       "| body_model | NoneType | None | If not none, we use this to initialize model's body. If you only want to load the model checkpoint in cpoint_path, leave this as none |\n",
       "| model_kwargs | dict | {} | Keyword arguments for model (both head and body) |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(model_init_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-nlp-library/blob/main/that_nlp_library/model_main.py#L57){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### compute_metrics_classification\n",
       "\n",
       ">      compute_metrics_classification (pred, metric_funcs=[], head_sizes=[],\n",
       ">                                      label_names=[], is_multilabel=False,\n",
       ">                                      multilabel_threshold=0.5)\n",
       "\n",
       "Return a dictionary of metric name and its values. Can handle both multiclass and multilabel    \n",
       "\n",
       "Reference: https://github.com/huggingface/transformers/blob/dbc12269ed5546b2da9236b9f1078b95b6a4d3d5/src/transformers/trainer_utils.py#LL100C22-L100C22\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| pred |  |  | An EvalPrediction object from HuggingFace (which is a named tuple with ```predictions``` and ```label_ids``` attributes) |\n",
       "| metric_funcs | list | [] | A list of metric functions to evaluate |\n",
       "| head_sizes | list | [] | Class size for each head, |\n",
       "| label_names | list | [] | Names of the label (dependent variable) columns |\n",
       "| is_multilabel | bool | False | Whether this is a multilabel classification |\n",
       "| multilabel_threshold | float | 0.5 | Threshold for multilabel (>= threshold is positive) |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-nlp-library/blob/main/that_nlp_library/model_main.py#L57){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### compute_metrics_classification\n",
       "\n",
       ">      compute_metrics_classification (pred, metric_funcs=[], head_sizes=[],\n",
       ">                                      label_names=[], is_multilabel=False,\n",
       ">                                      multilabel_threshold=0.5)\n",
       "\n",
       "Return a dictionary of metric name and its values. Can handle both multiclass and multilabel    \n",
       "\n",
       "Reference: https://github.com/huggingface/transformers/blob/dbc12269ed5546b2da9236b9f1078b95b6a4d3d5/src/transformers/trainer_utils.py#LL100C22-L100C22\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| pred |  |  | An EvalPrediction object from HuggingFace (which is a named tuple with ```predictions``` and ```label_ids``` attributes) |\n",
       "| metric_funcs | list | [] | A list of metric functions to evaluate |\n",
       "| head_sizes | list | [] | Class size for each head, |\n",
       "| label_names | list | [] | Names of the label (dependent variable) columns |\n",
       "| is_multilabel | bool | False | Whether this is a multilabel classification |\n",
       "| multilabel_threshold | float | 0.5 | Threshold for multilabel (>= threshold is positive) |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(compute_metrics_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics_separate_singleheads(pred, # An EvalPrediction object from HuggingFace (which is a named tuple with ```predictions``` and ```label_ids``` attributes)\n",
    "                              metric_funcs=[], # A list of metric functions to evaluate\n",
    "                              label_names=[], # Names of the label (dependent variable) columns\n",
    "                              **kwargs\n",
    "                             ):\n",
    "    \"\"\"\n",
    "    Return a dictionary of metric name and its values. Can handle both multiclass and multilabel\n",
    "    \"\"\"\n",
    "    # pred: EvalPrediction object \n",
    "    # (which is a named tuple with predictions and label_ids attributes)\n",
    "    labels = pred.label_ids # (bs,number of head separately)\n",
    "    assert labels.shape[1]==len(label_names)\n",
    "    \n",
    "    results={}\n",
    "    metric_funcs = val2iterable(metric_funcs)\n",
    "    \n",
    "    for i in range(len(label_names)):\n",
    "        _label = labels[:,i]\n",
    "        _pred = pred.predictions[i].argmax(-1)\n",
    "        for m_func in metric_funcs:\n",
    "            m_name = callable_name(m_func)\n",
    "            results[f'{m_name}_{label_names[i]}']=m_func(_label,_pred)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-nlp-library/blob/main/that_nlp_library/model_main.py#L94){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### compute_metrics_separate_singleheads\n",
       "\n",
       ">      compute_metrics_separate_singleheads (pred, metric_funcs=[],\n",
       ">                                            label_names=[], **kwargs)\n",
       "\n",
       "Return a dictionary of metric name and its values. Can handle both multiclass and multilabel\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| pred |  |  | An EvalPrediction object from HuggingFace (which is a named tuple with ```predictions``` and ```label_ids``` attributes) |\n",
       "| metric_funcs | list | [] | A list of metric functions to evaluate |\n",
       "| label_names | list | [] | Names of the label (dependent variable) columns |\n",
       "| kwargs |  |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-nlp-library/blob/main/that_nlp_library/model_main.py#L94){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### compute_metrics_separate_singleheads\n",
       "\n",
       ">      compute_metrics_separate_singleheads (pred, metric_funcs=[],\n",
       ">                                            label_names=[], **kwargs)\n",
       "\n",
       "Return a dictionary of metric name and its values. Can handle both multiclass and multilabel\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| pred |  |  | An EvalPrediction object from HuggingFace (which is a named tuple with ```predictions``` and ```label_ids``` attributes) |\n",
       "| metric_funcs | list | [] | A list of metric functions to evaluate |\n",
       "| label_names | list | [] | Names of the label (dependent variable) columns |\n",
       "| kwargs |  |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(compute_metrics_separate_singleheads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_for_classification(logits, # output of the last linear layer, before any softmax/sigmoid. Size: (bs,class_size)\n",
    "                            labels, # determined by your datasetdict. Size: (bs,number_of_head)\n",
    "                            is_multilabel=False, # Whether this is a multilabel classification\n",
    "                            is_multihead=False, # Whether this is a multihead (multi-level) classification\n",
    "                            head_sizes=[], # class size for each head\n",
    "                            head_weights=[], # loss weight for each head\n",
    "                           ):\n",
    "    \"\"\"\n",
    "    The general loss function for classification\n",
    "    \n",
    "    - If is_multilabel is ```False``` and is_multihead is ```False```: One-Head Classification, e.g. You predict 1 out of n class\n",
    "    \n",
    "    - If is_multilabel is ```False``` and is_multihead is ```True```: Multi-Head Classification, e.g. You predict 1 out of n classes at Level 1, \n",
    "    and 1 out of m classes at Level 2\n",
    "    \n",
    "    - If is_multilabel is ```True``` and is_multihead is ```False```: One-Head Multi-Label Classification, e.g. You predict x out of n class (x>=1)\n",
    "    \n",
    "    - If is_multilabel is ```True``` and is_multihead is ```True```: Not supported!\n",
    "    \n",
    "    \"\"\"\n",
    "    if is_multilabel and is_multihead: raise ValueError('Multi-Label and Multi-Head problem is not supported')\n",
    "    head_sizes = val2iterable(head_sizes)\n",
    "    loss=0\n",
    "    if not is_multilabel:\n",
    "        if not is_multihead:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, head_sizes[0]), labels.view(-1))\n",
    "        else:\n",
    "            assert len(head_sizes)==len(head_weights),\"For MultiHead, make sure len of head_sizes and head_weights equal\"\n",
    "            for i,(_size,_weight) in enumerate(zip(head_sizes,head_weights)):\n",
    "                start= 0 if i==0 else start+head_sizes[i-1]\n",
    "                end = start + _size\n",
    "                loss_fct = torch.nn.CrossEntropyLoss()\n",
    "                loss = loss + _weight*loss_fct(logits[:,start:end].view(-1,_size),\n",
    "                                               labels[:,i].view(-1))\n",
    "    else:\n",
    "        if not is_multihead:\n",
    "            loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "#             label_1hot = torch.nn.functional.one_hot(labels.view(-1),num_classes=head_sizes[0])\n",
    "            loss = loss_fct(logits,\n",
    "                            labels.float())\n",
    "        else:\n",
    "            raise ValueError('Multi-Head with Multi-Label classification is not supported. Have you lost your mind?')\n",
    "#             assert len(head_sizes)==len(head_weights),\"For MultiHead, make sure len of head_sizes and head_weights equal\"\n",
    "#             for i,(_size,_weight) in enumerate(zip(head_sizes,head_weights)):\n",
    "#                 start= 0 if i==0 else start+head_sizes[i-1]\n",
    "#                 end = start + _size\n",
    "#                 loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "#                 loss = loss + _weight*loss_fct(logits[:,start:end].view(-1,_size),\n",
    "#                                                torch.nn.functional.one_hot(labels[:,i].view(-1),num_classes=_size).float()\n",
    "#                                               )\n",
    "            \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-nlp-library/blob/main/that_nlp_library/model_main.py#L120){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### loss_for_classification\n",
       "\n",
       ">      loss_for_classification (logits, labels, is_multilabel=False,\n",
       ">                               is_multihead=False, head_sizes=[],\n",
       ">                               head_weights=[])\n",
       "\n",
       "The general loss function for classification\n",
       "\n",
       "- If is_multilabel is ```False``` and is_multihead is ```False```: One-Head Classification, e.g. You predict 1 out of n class\n",
       "\n",
       "- If is_multilabel is ```False``` and is_multihead is ```True```: Multi-Head Classification, e.g. You predict 1 out of n classes at Level 1, \n",
       "and 1 out of m classes at Level 2\n",
       "\n",
       "- If is_multilabel is ```True``` and is_multihead is ```False```: One-Head Multi-Label Classification, e.g. You predict x out of n class (x>=1)\n",
       "\n",
       "- If is_multilabel is ```True``` and is_multihead is ```True```: Not supported!\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| logits |  |  | output of the last linear layer, before any softmax/sigmoid. Size: (bs,class_size) |\n",
       "| labels |  |  | determined by your datasetdict. Size: (bs,number_of_head) |\n",
       "| is_multilabel | bool | False | Whether this is a multilabel classification |\n",
       "| is_multihead | bool | False | Whether this is a multihead (multi-level) classification |\n",
       "| head_sizes | list | [] | class size for each head |\n",
       "| head_weights | list | [] | loss weight for each head |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-nlp-library/blob/main/that_nlp_library/model_main.py#L120){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### loss_for_classification\n",
       "\n",
       ">      loss_for_classification (logits, labels, is_multilabel=False,\n",
       ">                               is_multihead=False, head_sizes=[],\n",
       ">                               head_weights=[])\n",
       "\n",
       "The general loss function for classification\n",
       "\n",
       "- If is_multilabel is ```False``` and is_multihead is ```False```: One-Head Classification, e.g. You predict 1 out of n class\n",
       "\n",
       "- If is_multilabel is ```False``` and is_multihead is ```True```: Multi-Head Classification, e.g. You predict 1 out of n classes at Level 1, \n",
       "and 1 out of m classes at Level 2\n",
       "\n",
       "- If is_multilabel is ```True``` and is_multihead is ```False```: One-Head Multi-Label Classification, e.g. You predict x out of n class (x>=1)\n",
       "\n",
       "- If is_multilabel is ```True``` and is_multihead is ```True```: Not supported!\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| logits |  |  | output of the last linear layer, before any softmax/sigmoid. Size: (bs,class_size) |\n",
       "| labels |  |  | determined by your datasetdict. Size: (bs,number_of_head) |\n",
       "| is_multilabel | bool | False | Whether this is a multilabel classification |\n",
       "| is_multihead | bool | False | Whether this is a multihead (multi-level) classification |\n",
       "| head_sizes | list | [] | class size for each head |\n",
       "| head_weights | list | [] | loss weight for each head |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(loss_for_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def finetune(lr, # Learning rate\n",
    "             bs, # Batch size\n",
    "             wd, # Weight decay\n",
    "             epochs, # Number of epochs\n",
    "             ddict, # The HuggingFace datasetdict\n",
    "             tokenizer,# HuggingFace tokenizer\n",
    "             o_dir = './tmp_weights', # Directory to save weights\n",
    "             save_checkpoint=False, # Whether to save weights (checkpoints) to o_dir\n",
    "             model=None, # NLP model\n",
    "             model_init=None, # A function to initialize model\n",
    "             data_collator=None, # HuggingFace data collator\n",
    "             compute_metrics=None, # A function to compute metric, e.g. `compute_metrics_classification`\n",
    "             grad_accum_steps=2, # The batch at each step will be divided by this integer and gradient will be accumulated over gradient_accumulation_steps steps.\n",
    "             lr_scheduler_type='cosine',  # The scheduler type to use. Including: linear, cosine, cosine_with_restarts, polynomial, constant, constant_with_warmup\n",
    "             warmup_ratio=0.1, # The warmup ratio for some lr scheduler\n",
    "             no_valid=False, # Whether there is a validation set or not\n",
    "             seed=42, # Random seed\n",
    "             report_to='none' # The list of integrations to report the results and logs to. Supported platforms are \"azure_ml\", \"comet_ml\", \"mlflow\", \"neptune\", \"tensorboard\",\"clearml\" and \"wandb\". Use \"all\" to report to all integrations installed, \"none\" for no integrations.\n",
    "            ):\n",
    "    \"The main model training/finetuning function\"\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    seed_everything(seed)\n",
    "    training_args = TrainingArguments(o_dir, \n",
    "                                learning_rate=lr, \n",
    "                                warmup_ratio=warmup_ratio if lr_scheduler_type!='linear' else 0.0, \n",
    "                                lr_scheduler_type=lr_scheduler_type, \n",
    "                                fp16=True,\n",
    "                                do_train=True,\n",
    "                                do_eval= not no_valid,\n",
    "                                evaluation_strategy=\"no\" if no_valid else \"epoch\", \n",
    "                                save_strategy=\"epoch\" if save_checkpoint else 'no',\n",
    "                                overwrite_output_dir=True,\n",
    "                                gradient_accumulation_steps=grad_accum_steps,\n",
    "                                per_device_train_batch_size=bs, \n",
    "                                per_device_eval_batch_size=bs,\n",
    "                                num_train_epochs=epochs, weight_decay=wd,\n",
    "                                report_to=report_to,\n",
    "                                logging_dir=os.path.join(o_dir, 'log') if report_to!='none' else None,\n",
    "                                logging_steps = len(ddict[\"train\"]) // bs,\n",
    "                                )\n",
    "\n",
    "    # instantiate trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        model_init=model_init if model is None else None,\n",
    "        args=training_args,\n",
    "        train_dataset=ddict['train'],#.shard(200, 0),    # Only use subset of the dataset for a quick training. Remove shard for full training\n",
    "        eval_dataset=ddict['validation'] if not no_valid else None,#.shard(100, 0), # Only use subset of the dataset for a quick training. Remove shard for full training\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    trainer.train()\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-nlp-library/blob/main/that_nlp_library/model_main.py#L175){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### finetune\n",
       "\n",
       ">      finetune (lr, bs, wd, epochs, ddict, tokenizer, o_dir='./tmp_weights',\n",
       ">                save_checkpoint=False, model=None, model_init=None,\n",
       ">                data_collator=None, compute_metrics=None, grad_accum_steps=2,\n",
       ">                lr_scheduler_type='cosine', warmup_ratio=0.1, no_valid=False,\n",
       ">                seed=42, report_to='none')\n",
       "\n",
       "The main model training/finetuning function\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| lr |  |  | Learning rate |\n",
       "| bs |  |  | Batch size |\n",
       "| wd |  |  | Weight decay |\n",
       "| epochs |  |  | Number of epochs |\n",
       "| ddict |  |  | The HuggingFace datasetdict |\n",
       "| tokenizer |  |  | HuggingFace tokenizer |\n",
       "| o_dir | str | ./tmp_weights | Directory to save weights |\n",
       "| save_checkpoint | bool | False | Whether to save weights (checkpoints) to o_dir |\n",
       "| model | NoneType | None | NLP model |\n",
       "| model_init | NoneType | None | A function to initialize model |\n",
       "| data_collator | NoneType | None | HuggingFace data collator |\n",
       "| compute_metrics | NoneType | None | A function to compute metric, e.g. `compute_metrics_classification` |\n",
       "| grad_accum_steps | int | 2 | The batch at each step will be divided by this integer and gradient will be accumulated over gradient_accumulation_steps steps. |\n",
       "| lr_scheduler_type | str | cosine | The scheduler type to use. Including: linear, cosine, cosine_with_restarts, polynomial, constant, constant_with_warmup |\n",
       "| warmup_ratio | float | 0.1 | The warmup ratio for some lr scheduler |\n",
       "| no_valid | bool | False | Whether there is a validation set or not |\n",
       "| seed | int | 42 | Random seed |\n",
       "| report_to | str | none | The list of integrations to report the results and logs to. Supported platforms are \"azure_ml\", \"comet_ml\", \"mlflow\", \"neptune\", \"tensorboard\",\"clearml\" and \"wandb\". Use \"all\" to report to all integrations installed, \"none\" for no integrations. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-nlp-library/blob/main/that_nlp_library/model_main.py#L175){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### finetune\n",
       "\n",
       ">      finetune (lr, bs, wd, epochs, ddict, tokenizer, o_dir='./tmp_weights',\n",
       ">                save_checkpoint=False, model=None, model_init=None,\n",
       ">                data_collator=None, compute_metrics=None, grad_accum_steps=2,\n",
       ">                lr_scheduler_type='cosine', warmup_ratio=0.1, no_valid=False,\n",
       ">                seed=42, report_to='none')\n",
       "\n",
       "The main model training/finetuning function\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| lr |  |  | Learning rate |\n",
       "| bs |  |  | Batch size |\n",
       "| wd |  |  | Weight decay |\n",
       "| epochs |  |  | Number of epochs |\n",
       "| ddict |  |  | The HuggingFace datasetdict |\n",
       "| tokenizer |  |  | HuggingFace tokenizer |\n",
       "| o_dir | str | ./tmp_weights | Directory to save weights |\n",
       "| save_checkpoint | bool | False | Whether to save weights (checkpoints) to o_dir |\n",
       "| model | NoneType | None | NLP model |\n",
       "| model_init | NoneType | None | A function to initialize model |\n",
       "| data_collator | NoneType | None | HuggingFace data collator |\n",
       "| compute_metrics | NoneType | None | A function to compute metric, e.g. `compute_metrics_classification` |\n",
       "| grad_accum_steps | int | 2 | The batch at each step will be divided by this integer and gradient will be accumulated over gradient_accumulation_steps steps. |\n",
       "| lr_scheduler_type | str | cosine | The scheduler type to use. Including: linear, cosine, cosine_with_restarts, polynomial, constant, constant_with_warmup |\n",
       "| warmup_ratio | float | 0.1 | The warmup ratio for some lr scheduler |\n",
       "| no_valid | bool | False | Whether there is a validation set or not |\n",
       "| seed | int | 42 | Random seed |\n",
       "| report_to | str | none | The list of integrations to report the results and logs to. Supported platforms are \"azure_ml\", \"comet_ml\", \"mlflow\", \"neptune\", \"tensorboard\",\"clearml\" and \"wandb\". Use \"all\" to report to all integrations installed, \"none\" for no integrations. |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _forward_pass_for_predictions(batch,\n",
    "                                 model=None, # NLP model\n",
    "                                 topk=1, # Number of labels to return for each head\n",
    "                                 is_multilabel=False, # Is this a multilabel classification?\n",
    "                                 multilabel_threshold=0.5, # The threshold for multilabel classification\n",
    "                                 tokenizer=None, # HuggingFace tokenizer\n",
    "                                 data_collator=None, # HuggingFace data collator\n",
    "                                 cols_to_remove=[], # list of keys (columns) to remove from ```batch```\n",
    "                                 label_names=[], # Names of the label columns\n",
    "                                 label_sizes=[], # Size of each label\n",
    "                                 device = None, # device that the model is trained on\n",
    "                                 is_dhc=False\n",
    "                                 ):\n",
    "    if data_collator is not None:\n",
    "# --- Convert from  \n",
    "# {'input_ids': [tensor([    0, 10444,   244, 14585,   125,  2948,  5925,   368,     2]), \n",
    "#                tensor([    0, 16098,  2913,   244,   135,   198, 34629,  6356,     2])]\n",
    "# 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), \n",
    "#                    tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])]\n",
    "#                    }\n",
    "# --- to\n",
    "#         [{'input_ids': tensor([    0, 10444,   244, 14585,   125,  2948,  5925,   368,     2]),\n",
    "#           'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
    "#          {'input_ids': tensor([    0, 16098,  2913,   244,   135,   198, 34629,  6356,     2]),\n",
    "#           'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])}]\n",
    "\n",
    "        # remove string text, due to transformer new version       \n",
    "        collator_inp = []\n",
    "        ks = [k for k in batch.keys() if k not in cols_to_remove]\n",
    "        vs = [batch[k] for k in ks]\n",
    "        for pair in zip(*vs):\n",
    "            collator_inp.append({k:v for k,v in zip(ks,pair)})\n",
    "        \n",
    "        batch = data_collator(collator_inp)\n",
    "    \n",
    "    inputs = {k:v.to(device) for k,v in batch.items()\n",
    "              if k in tokenizer.model_input_names}\n",
    "    \n",
    "    _f = partial(torch.nn.functional.softmax,dim=1) if not is_multilabel else torch.sigmoid\n",
    "    \n",
    "    # switch to eval mode for evaluation\n",
    "    if model.training:\n",
    "        model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        outputs_logits = outputs.logits\n",
    "        outputs_list=[]\n",
    "        if is_dhc:\n",
    "            # outputs_logits will be a list of n (typically 2) heads' logits, each has shape (bs,class_size)\n",
    "            for i in range(len(label_names)):\n",
    "                outputs_list.append(_f(outputs_logits[i].cpu()))\n",
    "        else:\n",
    "            # outputs_logits will have shape (bs,sum of all class sizes). We split into each class\n",
    "            outputs_logits = outputs_logits.cpu()\n",
    "            _s=0\n",
    "            _e=label_sizes[0]\n",
    "            for i in range(len(label_names)):\n",
    "                outputs_list.append(_f(outputs_logits[:,_s:_e]))\n",
    "                _s+=label_sizes[i]\n",
    "                _e+=label_sizes[i+1] if i+1<len(label_names) else 0\n",
    "        \n",
    "        # save prediction and probability\n",
    "        pred_label_list=[]\n",
    "        pred_prob_list=[]\n",
    "        if is_multilabel:\n",
    "            for i in range(len(label_names)):\n",
    "                pred_label_list.append(outputs_list[i]>=multilabel_threshold)\n",
    "                pred_prob_list.append(outputs_list[i])\n",
    "        else:\n",
    "            for i in range(len(label_names)):\n",
    "                _p,_l = torch.topk(outputs_list[i],topk,dim=-1)\n",
    "                if topk==1:\n",
    "                    _l,_p = _l[:,0],_p[:,0]\n",
    "                pred_label_list.append(_l)\n",
    "                pred_prob_list.append(_p)\n",
    "    \n",
    "    # Switch back to train mode\n",
    "    if not model.training:\n",
    "        model.train()\n",
    "        \n",
    "    results={}\n",
    "    for i in range(len(label_names)):\n",
    "        results[f'pred_{label_names[i]}']= pred_label_list[i].numpy()\n",
    "        results[f'pred_prob_{label_names[i]}']= pred_prob_list[i].numpy()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ModelController():\n",
    "    def __init__(self,\n",
    "                 model, # NLP model\n",
    "                 data_store:TextDataMain=None, # a TextDataMain object\n",
    "                 metric_funcs=[accuracy_score], # Metric function (can be from Sklearn)\n",
    "                 seed=42, # Random seed\n",
    "                ):\n",
    "        self.model = model\n",
    "        self.data_store = data_store\n",
    "        self.metric_funcs = metric_funcs\n",
    "        self.seed = seed\n",
    "        \n",
    "    def fit(self,\n",
    "            epochs, # Number of epochs\n",
    "            learning_rate, # Learning rate\n",
    "            ddict=None, # DatasetDict to fit (will override data_store)\n",
    "            batch_size=16, # Batch size\n",
    "            weight_decay=0.01, # Weight decay\n",
    "            lr_scheduler_type='cosine', # The scheduler type to use. Including: linear, cosine, cosine_with_restarts, polynomial, constant, constant_with_warmup\n",
    "            warmup_ratio=0.1, # The warmup ratio for some lr scheduler\n",
    "            o_dir = './tmp_weights', # Directory to save weights\n",
    "            save_checkpoint=False, # Whether to save weights (checkpoints) to o_dir\n",
    "            hf_report_to='none', # The list of HuggingFace-allowed integrations to report the results and logs to\n",
    "            compute_metrics=None, # A function to compute metric, e.g. `compute_metrics_classification` which utilizes the given ```metric_funcs``` \n",
    "            grad_accum_steps=2, # Gradient will be accumulated over gradient_accumulation_steps steps.\n",
    "            tokenizer=None, # Tokenizer (to override one in ```data_store```)\n",
    "            data_collator=None, # Data Collator (to override one in ```data_store```)\n",
    "            label_names=None, # Names of the label (dependent variable) columns (to override one in ```data_store```)\n",
    "            head_sizes=None, # Class size for each head (to override one in ```model```)\n",
    "           ):\n",
    "        \n",
    "        if tokenizer is None: tokenizer=check_and_get_attribute(self.data_store,'tokenizer')\n",
    "        if data_collator is None: data_collator=getattr(self.data_store,'data_collator',None)\n",
    "        if ddict is None: ddict = check_and_get_attribute(self.data_store,'main_ddict')\n",
    "            \n",
    "        if label_names is None: label_names=check_and_get_attribute(self.data_store,'label_names')\n",
    "        label_names = val2iterable(label_names)\n",
    "        \n",
    "        if head_sizes is None: head_sizes=check_and_get_attribute(self.model,'head_class_sizes')\n",
    "        head_sizes = val2iterable(head_sizes)\n",
    "        \n",
    "        if len(set(ddict.keys()) & set(['train','training']))==0:\n",
    "            raise ValueError(\"Missing the following key for DatasetDict: train/training\")\n",
    "        no_valid = len(set(ddict.keys()) & set(['validation','val']))==0\n",
    "\n",
    "        _compute_metrics = partial(compute_metrics,\n",
    "                                   metric_funcs=self.metric_funcs,\n",
    "                                   head_sizes=head_sizes,\n",
    "                                   label_names=label_names \n",
    "                                  )\n",
    "        \n",
    "\n",
    "        trainer = finetune(learning_rate,batch_size,weight_decay,epochs,\n",
    "                           ddict,tokenizer,o_dir,\n",
    "                           save_checkpoint=save_checkpoint,\n",
    "                           model=self.model,\n",
    "                           data_collator=data_collator,\n",
    "                           compute_metrics=_compute_metrics,\n",
    "                           grad_accum_steps=grad_accum_steps,\n",
    "                           lr_scheduler_type=lr_scheduler_type,\n",
    "                           warmup_ratio=warmup_ratio,\n",
    "                           no_valid=no_valid,\n",
    "                           seed=self.seed,\n",
    "                           report_to=hf_report_to)\n",
    "        self.trainer = trainer\n",
    "        \n",
    "    def predict_raw_text(self,\n",
    "                         content:dict|list|str, # Either a single sentence, list of sentence or a dictionary with keys are metadata, values are list\n",
    "                         batch_size=1, # Batch size. For a small amount of texts, you might want to keep this small\n",
    "                         is_multilabel=None, # Is this a multilabel classification?\n",
    "                         multilabel_threshold=0.5, # Threshold for multilabel classification\n",
    "                         topk=1, # Number of labels to return for each head\n",
    "                         is_dhc=False # Are outpuf (of model) separate heads?\n",
    "                        ):\n",
    "        if not isinstance(self.data_store,TextDataMain) or not self.data_store._main_called:\n",
    "            raise ValueError('This functionality needs a TextDataMain object which has already processed some training data')\n",
    "        with HiddenPrints():\n",
    "            test_ddict = self.data_store.get_test_datasetdict_from_dict(content)\n",
    "            df_result =  self.predict_ddict(ddict=test_ddict,\n",
    "                                            ds_type='test',\n",
    "                                            batch_size=batch_size,\n",
    "                                            is_multilabel=is_multilabel,\n",
    "                                            multilabel_threshold=multilabel_threshold,\n",
    "                                            topk=topk,\n",
    "                                            is_dhc=is_dhc\n",
    "                                           )\n",
    "        return df_result\n",
    "    \n",
    "    def predict_ddict(self,\n",
    "                      ddict=None, # DatasetDict to predict (will override ```data_store```)\n",
    "                      ds_type='test', # Keys of DatasetDict to predict\n",
    "                      batch_size=16, # Batch size\n",
    "                      is_multilabel=None, # Is this a multilabel classification?\n",
    "                      multilabel_threshold=0.5, # Threshold for multilabel classification\n",
    "                      topk=1, # Number of labels to return for each head\n",
    "                      tokenizer=None, # Tokenizer (to override one in ```data_store```)\n",
    "                      data_collator=None, # Data Collator (to override one in ```data_store```)\n",
    "                      label_names=None, # Names of the label (dependent variable) columns (to override one in ```data_store```)\n",
    "                      class_names_predefined=None, # List of names associated with the labels (same index order) (to override one in ```data_store```)\n",
    "                      device=None, # Device that the model is trained on\n",
    "                      is_dhc=False # Are outpuf (of model) separate heads?\n",
    "                     ):\n",
    "        if device is None: device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if is_multilabel is None: is_multilabel=getattr(self.model,'is_multilabel',False)\n",
    "        label_lists = class_names_predefined\n",
    "        \n",
    "        if tokenizer is None: tokenizer=check_and_get_attribute(self.data_store,'tokenizer')\n",
    "        if data_collator is None: data_collator=getattr(self.data_store,'data_collator',None)\n",
    "        if label_names is None: label_names=check_and_get_attribute(self.data_store,'label_names')\n",
    "        if label_lists is None: label_lists = check_and_get_attribute(self.data_store,'label_lists')\n",
    "        if not isinstance(label_names,list):\n",
    "            label_names=[label_names]\n",
    "        if not isinstance(label_lists[0],list):\n",
    "            label_lists=[label_lists]    \n",
    "            \n",
    "        label_sizes = [len(cs) for cs in label_lists]\n",
    "        if ddict is None: ddict = check_and_get_attribute(self.data_store,'main_ddict') \n",
    "        if ds_type not in ddict.keys():\n",
    "            raise ValueError(f'{ds_type} is not in the given DatasetDict keys')\n",
    "        \n",
    "        ddict.set_format(\"torch\",\n",
    "                        columns=[\"input_ids\", \"attention_mask\"])\n",
    "        \n",
    "        print_msg('Start making predictions',20)\n",
    "        preserved_kws=['input_ids', 'token_type_ids', 'attention_mask','label'] # hard-coded\n",
    "        cols_to_remove = (set(ddict[ds_type].features.keys()) - set(preserved_kws)) | {'text'}\n",
    "        ddict[ds_type] = ddict[ds_type].map(\n",
    "            partial(_forward_pass_for_predictions,model=self.model,\n",
    "                    topk=topk,\n",
    "                    is_multilabel=is_multilabel,\n",
    "                    multilabel_threshold=multilabel_threshold,\n",
    "                    tokenizer=tokenizer,\n",
    "                    data_collator=data_collator,\n",
    "                    cols_to_remove=cols_to_remove,\n",
    "                   label_names=label_names,\n",
    "                    label_sizes=label_sizes,\n",
    "                    is_dhc = is_dhc,\n",
    "                    device=device\n",
    "                   ), \n",
    "            batched=True, batch_size=batch_size)\n",
    "    \n",
    "        ddict.set_format(\"pandas\")\n",
    "        \n",
    "        df_result = ddict[ds_type][:]\n",
    "        cols_to_keep = [c for c in df_result.columns.values if c not in preserved_kws[:-1]]\n",
    "        df_result = df_result.loc[:,cols_to_keep]\n",
    "        \n",
    "        # convert pred id to string label\n",
    "        for i in range(len(label_names)):  \n",
    "            if not is_multilabel:\n",
    "                if topk==1:\n",
    "                    df_result[f'pred_{label_names[i]}'] = df_result[f'pred_{label_names[i]}'].apply(lambda x: label_lists[i][int(x)])\n",
    "                else:\n",
    "                    df1 = pd.DataFrame(df_result[f'pred_{label_names[i]}'].to_list(),columns=[f'pred_{label_names[i]}_top{j}' for j in range(1,topk+1)])\n",
    "                    df1_prob = pd.DataFrame(df_result[f'pred_prob_{label_names[i]}'].to_list(),columns=[f'pred_prob_{label_names[i]}_top{j}' for j in range(1,topk+1)])\n",
    "\n",
    "                    for j in range(1,topk+1):\n",
    "                        df1[f'pred_{label_names[i]}_top{j}'] =  df1[f'pred_{label_names[i]}_top{j}'].apply(lambda x: label_lists[i][int(x)])\n",
    "\n",
    "                    df_result = pd.concat([df_result,df1,df1_prob],axis=1)\n",
    "            else:\n",
    "                get_label_str_multilabel = lambda row: ','.join([label_lists[i][int(j)] for j in np.where(row==True)[0]])\n",
    "                df_result[f'pred_{label_names[i]}_string'] = df_result[f'pred_{label_names[i]}'].apply(get_label_str_multilabel)\n",
    "\n",
    "        return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-nlp-library/blob/main/that_nlp_library/model_main.py#L321){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelController\n",
       "\n",
       ">      ModelController (model,\n",
       ">                       data_store:that_nlp_library.text_main.TextDataMain=None,\n",
       ">                       metric_funcs=[<function accuracy_score at\n",
       ">                       0x7f900acdc700>], seed=42)\n",
       "\n",
       "Initialize self.  See help(type(self)) for accurate signature.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model |  |  | NLP model |\n",
       "| data_store | TextDataMain | None | a TextDataMain object |\n",
       "| metric_funcs | list | [<function accuracy_score>] | Metric function (can be from Sklearn) |\n",
       "| seed | int | 42 | Random seed |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-nlp-library/blob/main/that_nlp_library/model_main.py#L321){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelController\n",
       "\n",
       ">      ModelController (model,\n",
       ">                       data_store:that_nlp_library.text_main.TextDataMain=None,\n",
       ">                       metric_funcs=[<function accuracy_score at\n",
       ">                       0x7f900acdc700>], seed=42)\n",
       "\n",
       "Initialize self.  See help(type(self)) for accurate signature.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model |  |  | NLP model |\n",
       "| data_store | TextDataMain | None | a TextDataMain object |\n",
       "| metric_funcs | list | [<function accuracy_score>] | Metric function (can be from Sklearn) |\n",
       "| seed | int | 42 | Random seed |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ModelController)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-nlp-library/blob/main/that_nlp_library/model_main.py#L333){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelController.fit\n",
       "\n",
       ">      ModelController.fit (epochs, learning_rate, ddict=None, batch_size=16,\n",
       ">                           weight_decay=0.01, lr_scheduler_type='cosine',\n",
       ">                           warmup_ratio=0.1, o_dir='./tmp_weights',\n",
       ">                           save_checkpoint=False, hf_report_to='none',\n",
       ">                           compute_metrics=None, grad_accum_steps=2,\n",
       ">                           tokenizer=None, data_collator=None,\n",
       ">                           label_names=None, head_sizes=None)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| epochs |  |  | Number of epochs |\n",
       "| learning_rate |  |  | Learning rate |\n",
       "| ddict | NoneType | None | DatasetDict to fit (will override data_store) |\n",
       "| batch_size | int | 16 | Batch size |\n",
       "| weight_decay | float | 0.01 | Weight decay |\n",
       "| lr_scheduler_type | str | cosine | The scheduler type to use. Including: linear, cosine, cosine_with_restarts, polynomial, constant, constant_with_warmup |\n",
       "| warmup_ratio | float | 0.1 | The warmup ratio for some lr scheduler |\n",
       "| o_dir | str | ./tmp_weights | Directory to save weights |\n",
       "| save_checkpoint | bool | False | Whether to save weights (checkpoints) to o_dir |\n",
       "| hf_report_to | str | none | The list of HuggingFace-allowed integrations to report the results and logs to |\n",
       "| compute_metrics | NoneType | None | A function to compute metric, e.g. `compute_metrics_classification` which utilizes the given ```metric_funcs``` |\n",
       "| grad_accum_steps | int | 2 | Gradient will be accumulated over gradient_accumulation_steps steps. |\n",
       "| tokenizer | NoneType | None | Tokenizer (to override one in ```data_store```) |\n",
       "| data_collator | NoneType | None | Data Collator (to override one in ```data_store```) |\n",
       "| label_names | NoneType | None | Names of the label (dependent variable) columns (to override one in ```data_store```) |\n",
       "| head_sizes | NoneType | None | Class size for each head (to override one in ```model```) |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-nlp-library/blob/main/that_nlp_library/model_main.py#L333){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelController.fit\n",
       "\n",
       ">      ModelController.fit (epochs, learning_rate, ddict=None, batch_size=16,\n",
       ">                           weight_decay=0.01, lr_scheduler_type='cosine',\n",
       ">                           warmup_ratio=0.1, o_dir='./tmp_weights',\n",
       ">                           save_checkpoint=False, hf_report_to='none',\n",
       ">                           compute_metrics=None, grad_accum_steps=2,\n",
       ">                           tokenizer=None, data_collator=None,\n",
       ">                           label_names=None, head_sizes=None)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| epochs |  |  | Number of epochs |\n",
       "| learning_rate |  |  | Learning rate |\n",
       "| ddict | NoneType | None | DatasetDict to fit (will override data_store) |\n",
       "| batch_size | int | 16 | Batch size |\n",
       "| weight_decay | float | 0.01 | Weight decay |\n",
       "| lr_scheduler_type | str | cosine | The scheduler type to use. Including: linear, cosine, cosine_with_restarts, polynomial, constant, constant_with_warmup |\n",
       "| warmup_ratio | float | 0.1 | The warmup ratio for some lr scheduler |\n",
       "| o_dir | str | ./tmp_weights | Directory to save weights |\n",
       "| save_checkpoint | bool | False | Whether to save weights (checkpoints) to o_dir |\n",
       "| hf_report_to | str | none | The list of HuggingFace-allowed integrations to report the results and logs to |\n",
       "| compute_metrics | NoneType | None | A function to compute metric, e.g. `compute_metrics_classification` which utilizes the given ```metric_funcs``` |\n",
       "| grad_accum_steps | int | 2 | Gradient will be accumulated over gradient_accumulation_steps steps. |\n",
       "| tokenizer | NoneType | None | Tokenizer (to override one in ```data_store```) |\n",
       "| data_collator | NoneType | None | Data Collator (to override one in ```data_store```) |\n",
       "| label_names | NoneType | None | Names of the label (dependent variable) columns (to override one in ```data_store```) |\n",
       "| head_sizes | NoneType | None | Class size for each head (to override one in ```model```) |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ModelController.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-nlp-library/blob/main/that_nlp_library/model_main.py#L407){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelController.predict_ddict\n",
       "\n",
       ">      ModelController.predict_ddict (ddict=None, ds_type='test', batch_size=16,\n",
       ">                                     is_multilabel=None,\n",
       ">                                     multilabel_threshold=0.5, topk=1,\n",
       ">                                     tokenizer=None, data_collator=None,\n",
       ">                                     label_names=None,\n",
       ">                                     class_names_predefined=None, device=None,\n",
       ">                                     is_dhc=False)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| ddict | NoneType | None | DatasetDict to predict (will override ```data_store```) |\n",
       "| ds_type | str | test | Keys of DatasetDict to predict |\n",
       "| batch_size | int | 16 | Batch size |\n",
       "| is_multilabel | NoneType | None | Is this a multilabel classification? |\n",
       "| multilabel_threshold | float | 0.5 | Threshold for multilabel classification |\n",
       "| topk | int | 1 | Number of labels to return for each head |\n",
       "| tokenizer | NoneType | None | Tokenizer (to override one in ```data_store```) |\n",
       "| data_collator | NoneType | None | Data Collator (to override one in ```data_store```) |\n",
       "| label_names | NoneType | None | Names of the label (dependent variable) columns (to override one in ```data_store```) |\n",
       "| class_names_predefined | NoneType | None | List of names associated with the labels (same index order) (to override one in ```data_store```) |\n",
       "| device | NoneType | None | Device that the model is trained on |\n",
       "| is_dhc | bool | False | Are outpuf (of model) separate heads? |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-nlp-library/blob/main/that_nlp_library/model_main.py#L407){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelController.predict_ddict\n",
       "\n",
       ">      ModelController.predict_ddict (ddict=None, ds_type='test', batch_size=16,\n",
       ">                                     is_multilabel=None,\n",
       ">                                     multilabel_threshold=0.5, topk=1,\n",
       ">                                     tokenizer=None, data_collator=None,\n",
       ">                                     label_names=None,\n",
       ">                                     class_names_predefined=None, device=None,\n",
       ">                                     is_dhc=False)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| ddict | NoneType | None | DatasetDict to predict (will override ```data_store```) |\n",
       "| ds_type | str | test | Keys of DatasetDict to predict |\n",
       "| batch_size | int | 16 | Batch size |\n",
       "| is_multilabel | NoneType | None | Is this a multilabel classification? |\n",
       "| multilabel_threshold | float | 0.5 | Threshold for multilabel classification |\n",
       "| topk | int | 1 | Number of labels to return for each head |\n",
       "| tokenizer | NoneType | None | Tokenizer (to override one in ```data_store```) |\n",
       "| data_collator | NoneType | None | Data Collator (to override one in ```data_store```) |\n",
       "| label_names | NoneType | None | Names of the label (dependent variable) columns (to override one in ```data_store```) |\n",
       "| class_names_predefined | NoneType | None | List of names associated with the labels (same index order) (to override one in ```data_store```) |\n",
       "| device | NoneType | None | Device that the model is trained on |\n",
       "| is_dhc | bool | False | Are outpuf (of model) separate heads? |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ModelController.predict_ddict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-nlp-library/blob/main/that_nlp_library/model_main.py#L385){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelController.predict_raw_text\n",
       "\n",
       ">      ModelController.predict_raw_text (content:dict|list|str, batch_size=1,\n",
       ">                                        is_multilabel=None,\n",
       ">                                        multilabel_threshold=0.5, topk=1,\n",
       ">                                        is_dhc=False)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| content | dict \\| list \\| str |  | Either a single sentence, list of sentence or a dictionary with keys are metadata, values are list |\n",
       "| batch_size | int | 1 | Batch size. For a small amount of texts, you might want to keep this small |\n",
       "| is_multilabel | NoneType | None | Is this a multilabel classification? |\n",
       "| multilabel_threshold | float | 0.5 | Threshold for multilabel classification |\n",
       "| topk | int | 1 | Number of labels to return for each head |\n",
       "| is_dhc | bool | False | Are outpuf (of model) separate heads? |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-nlp-library/blob/main/that_nlp_library/model_main.py#L385){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelController.predict_raw_text\n",
       "\n",
       ">      ModelController.predict_raw_text (content:dict|list|str, batch_size=1,\n",
       ">                                        is_multilabel=None,\n",
       ">                                        multilabel_threshold=0.5, topk=1,\n",
       ">                                        is_dhc=False)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| content | dict \\| list \\| str |  | Either a single sentence, list of sentence or a dictionary with keys are metadata, values are list |\n",
       "| batch_size | int | 1 | Batch size. For a small amount of texts, you might want to keep this small |\n",
       "| is_multilabel | NoneType | None | Is this a multilabel classification? |\n",
       "| multilabel_threshold | float | 0.5 | Threshold for multilabel classification |\n",
       "| topk | int | 1 | Number of labels to return for each head |\n",
       "| is_dhc | bool | False | Are outpuf (of model) separate heads? |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ModelController.predict_raw_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
