{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1059a85b",
   "metadata": {},
   "source": [
    "# Text Processing Benchmark\n",
    "\n",
    "> This module contains some benchmarks for `TextDataController`\n",
    "\n",
    "- skip_showdoc: true\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5471f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda list | grep 'datasets\\|transformers'\n",
    "# datasets                  2.11.0                   pypi_0    pypi\n",
    "# transformers              4.28.1                   pypi_0    pypi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117bf1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from that_nlp_library.text_transformation import *\n",
    "from that_nlp_library.text_augmentation import *\n",
    "from that_nlp_library.text_main import *\n",
    "from importlib.machinery import SourceFileLoader\n",
    "from datasets import load_dataset,enable_caching,disable_caching\n",
    "from transformers import RobertaTokenizer\n",
    "import os\n",
    "import time\n",
    "from underthesea import text_normalize\n",
    "import nlpaug.augmenter.char as nac\n",
    "from functools import partial\n",
    "import random\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334304df",
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_caching() # disable huggingface caching to get a fair benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4a1ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmarking(tdc,bs,tokenizer,n=10,shuffle_trn=True):\n",
    "    time1 = time.time()\n",
    "    tdc.process_and_tokenize(tokenizer,max_length=512,shuffle_trn=shuffle_trn)\n",
    "    time2 = time.time() \n",
    "    print(f'Time it takes to process + tokenize training texts: {(time2-time1):.3f} s')\n",
    "    for i,v in enumerate(tdc.main_ddict['train']):\n",
    "        if n is not None and i==bs*n: break\n",
    "    time3 = time.time()\n",
    "    if n is not None:\n",
    "        print(f'Time it takes to go through {n*bs} items: {(time3-time2):.3f} s')\n",
    "    else:\n",
    "        print(f'Time it takes to go through all items: {(time3-time2):.3f} s')\n",
    "\n",
    "#     print(f'Total time: {(time3-time1):.3f} s')\n",
    "def benchmarking_and_memory_usage(tdc,bs,tokenizer,n=10,shuffle_trn=True):\n",
    "    mem_usage = memory_usage((benchmarking,[tdc,bs,tokenizer,n,shuffle_trn]))\n",
    "    print(f'Maximum memory usage: {max(mem_usage):.3f} MiB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_aug_stochastic(x,aug=None,p=0.5):\n",
    "    results = aug.augment(x)\n",
    "    if not isinstance(x,list): return results[0] if random.random()<p else x\n",
    "    return [a if random.random()<p else b for a,b in zip(results,x)]\n",
    "\n",
    "aug = nac.KeyboardAug(aug_char_max=3,aug_char_p=0.1,aug_word_p=0.07)\n",
    "nearby_aug_func = partial(nlp_aug_stochastic,aug=aug,p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52823398",
   "metadata": {},
   "source": [
    "## Benchmark on medium-size dataset (~117k rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e42c90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117430"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "len(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7409d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4328e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181dfc75",
   "metadata": {},
   "source": [
    "### Without iterable dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc4486",
   "metadata": {},
   "source": [
    "With filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59eee14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 14.940 s\n",
      "Time it takes to go through 1280 items: 0.155 s\n",
      "Maximum memory usage: 825.723 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=False,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2f329b",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e76af35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 15.741 s\n",
      "Time it takes to go through 1280 items: 0.168 s\n",
      "Maximum memory usage: 857.930 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=False,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fb15dd",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83bf561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 35.980 s\n",
      "Time it takes to go through 1280 items: 0.176 s\n",
      "Maximum memory usage: 893.555 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=False,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477c7108",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation + no shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f305c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 35.534 s\n",
      "Time it takes to go through 1280 items: 0.180 s\n",
      "Maximum memory usage: 892.668 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=False,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer,shuffle_trn=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c90964",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation + higher batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9237da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 35.427 s\n",
      "Time it takes to go through 5120 items: 0.746 s\n",
      "Maximum memory usage: 794.441 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=512,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=False,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,512,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f0a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48a42d44",
   "metadata": {},
   "source": [
    "### With iterable dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b8ab9b",
   "metadata": {},
   "source": [
    "With filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b911d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 2.888 s\n",
      "Time it takes to go through 1280 items: 0.571 s\n",
      "Maximum memory usage: 752.379 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e5a1f",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fcfec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 2.615 s\n",
      "Time it takes to go through 1280 items: 0.547 s\n",
      "Maximum memory usage: 804.832 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd0eccb",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67735d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 22.078 s\n",
      "Time it takes to go through 1280 items: 0.606 s\n",
      "Maximum memory usage: 857.551 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb47209",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation + no shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670228b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 22.369 s\n",
      "Time it takes to go through 1280 items: 0.543 s\n",
      "Maximum memory usage: 857.930 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer,shuffle_trn=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb0bad5",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation + higher batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b38806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 21.482 s\n",
      "Time it takes to go through 5120 items: 2.150 s\n",
      "Maximum memory usage: 752.199 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=512,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,512,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05db4506",
   "metadata": {},
   "source": [
    "### With streaming (v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95672320",
   "metadata": {},
   "source": [
    "With filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff6a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.002 s\n",
      "Time it takes to go through 1280 items: 1.327 s\n",
      "Maximum memory usage: 686.387 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db24722f",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be37936d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.002 s\n",
      "Time it takes to go through 1280 items: 1.470 s\n",
      "Maximum memory usage: 803.281 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b27c14",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fcf362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.082 s\n",
      "Time it takes to go through 1280 items: 95.631 s\n",
      "Maximum memory usage: 6908.953 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8931a13d",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation + no shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ccb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.078 s\n",
      "Time it takes to go through 1280 items: 11.870 s\n",
      "Maximum memory usage: 6892.258 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=True,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer,shuffle_trn=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a048e2",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation + higher batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39095e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "#                     split='train',\n",
    "#                     streaming=True)\n",
    "\n",
    "# tdc = TextDataController(dset,\n",
    "#                          main_text='Review Text',\n",
    "#                          label_names='Department Name',\n",
    "#                          filter_dict={'Review Text': lambda x: x is not None,\n",
    "#                                       'Department Name': lambda x: x is not None,\n",
    "#                                      },\n",
    "#                          class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "#                          metadatas=['Title','Division Name'],\n",
    "#                          content_transformations=[text_normalize,str.lower],\n",
    "#                          content_augmentations= [nearby_aug_func,str.lower], \n",
    "#                          val_ratio=None,\n",
    "#                          batch_size=512,\n",
    "#                          seed=42,\n",
    "#                          convert_training_to_iterable=True,\n",
    "#                          verbose=False\n",
    "#                         )\n",
    "# benchmarking_and_memory_usage(tdc,512,tokenizer,shuffle_trn=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0818ae",
   "metadata": {},
   "source": [
    "### With streaming (v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e96971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmarking(tdc,bs,tokenizer,n=10):\n",
    "    time1 = time.time()\n",
    "    tdc.process_and_tokenize(tokenizer,max_length=512)\n",
    "    time2 = time.time() \n",
    "    print(f'Time it takes to process + tokenize training texts: {(time2-time1):.3f} s')\n",
    "    for i,v in enumerate(tdc.main_ddict['train']):\n",
    "        if n is not None and i==bs*n: break\n",
    "    time3 = time.time()\n",
    "    if n is not None:\n",
    "        print(f'Time it takes to go through {n*bs} items: {(time3-time2):.3f} s')\n",
    "    else:\n",
    "        print(f'Time it takes to go through all items: {(time3-time2):.3f} s')\n",
    "\n",
    "def benchmarking_and_memory_usage(tdc,bs,tokenizer,n=10):\n",
    "    mem_usage = memory_usage((benchmarking,[tdc,bs,tokenizer,n]))\n",
    "    print(f'Maximum memory usage: {max(mem_usage):.3f} MiB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100767dd",
   "metadata": {},
   "source": [
    "With filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c56ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "\n",
    "tdc = TextDataControllerStreaming(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cb886d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.808 s\n",
      "Time it takes to go through 1280 items: 0.639 s\n",
      "Maximum memory usage: 672.266 MiB\n"
     ]
    }
   ],
   "source": [
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9b6829",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85b534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.818 s\n",
      "Time it takes to go through 1280 items: 0.568 s\n",
      "Maximum memory usage: 679.590 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "\n",
    "tdc = TextDataControllerStreaming(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a5ad5d",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d862452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.826 s\n",
      "Time it takes to go through 1280 items: 1.599 s\n",
      "Maximum memory usage: 679.723 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "\n",
    "tdc = TextDataControllerStreaming(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc83d5d0",
   "metadata": {},
   "source": [
    "With filter + metadatas concatenation + content transformation + content augmentation + higher batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41254916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 0.835 s\n",
      "Time it takes to go through 5120 items: 5.734 s\n",
      "Maximum memory usage: 677.559 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "\n",
    "tdc = TextDataControllerStreaming(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         class_names_predefined=['Bottoms', 'Dresses', 'Intimate', 'Jackets', 'Tops', 'Trend'],\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         batch_size=512,\n",
    "                         seed=42,\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,512,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73ff21e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed874069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2ea6bf3",
   "metadata": {},
   "source": [
    "### Test the effect of batch size and num_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01352f23",
   "metadata": {},
   "source": [
    "Text processing + tokenization are the most time-consuming tasks, thus we will check how different batch size and num proc will affect these tasks' running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb9bb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 71.757 s\n",
      "Time it takes to go through all items: 15.128 s\n",
      "Maximum memory usage: 1041.410 MiB\n"
     ]
    }
   ],
   "source": [
    "bs=16\n",
    "\n",
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=False,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer,n=None,shuffle_trn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d7c689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 60.165 s\n",
      "Time it takes to go through all items): 15.950 s\n",
      "Maximum memory usage: 831.129 MiB\n"
     ]
    }
   ],
   "source": [
    "bs=128\n",
    "\n",
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=False,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer,n=None,shuffle_trn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ae879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 58.748 s\n",
      "Time it takes to go through all items: 16.631 s\n",
      "Maximum memory usage: 845.074 MiB\n"
     ]
    }
   ],
   "source": [
    "bs=128*10\n",
    "\n",
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=False,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer,n=None,shuffle_trn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e55bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=16):   0%|          | 0/117430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=16):   0%|          | 0/113205 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/113140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 47.417 s\n",
      "Time it takes to go through all items: 16.684 s\n",
      "Maximum memory usage: 1009.738 MiB\n"
     ]
    }
   ],
   "source": [
    "bs=128*10\n",
    "\n",
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=False,\n",
    "                         num_proc=16,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer,n=None,shuffle_trn=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810f73a9",
   "metadata": {},
   "source": [
    "Conclusion: increase BOTH batch size and num_proc can help decrease the processing + tokenization time, but the relationship between batch size, num_proc and running time are not linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3517f654",
   "metadata": {},
   "source": [
    "## Improving processing time with caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23abbf1",
   "metadata": {},
   "source": [
    "The worst processing time is recorded with an non-iterable training set, with the following preprocessing: 2-column filtering, 2-column metadatas, 2 content transformations, 2 content augmentation; the total preprocessing time is ~62s for 117k dataset. However, this results in the best data iteration time: 0.183s for going through 1280 items.\n",
    "\n",
    "With caching, we can significantly reduce the preprocessing time. That means, you only need to do all preprocessings once; all subsequent call will take advatages of this cached result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aaf4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_caching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05c6840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-a8e48b2fdcc1675b_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-7f67ed2247bad412_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-8895dee11a0750d6_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-7cb19b4a6f7bb9bc_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-8d6c7bf742ea98e4_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-48a8c757ecb89ade_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-896ddc2616d23c5e_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-e0a802a1bedd79b5_*_of_00004.arrow\n",
      "Loading cached shuffled indices for dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-eae3d3101ec08ba5.arrow\n",
      "Loading cached processed dataset at /home/quan/.cache/huggingface/datasets/csv/sample_data-b5f53892a1b938ad/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-baf7b5167460c6dd.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to process + tokenize training texts: 1.471 s\n",
      "Time it takes to go through 1280 items: 0.176 s\n",
      "Maximum memory usage: 874.715 MiB\n"
     ]
    }
   ],
   "source": [
    "dset = load_dataset('sample_data',data_files=['Womens_Clothing_Reviews.csv' for i in range(5)],\n",
    "                    split='train',\n",
    "                    streaming=False)\n",
    "\n",
    "tdc = TextDataController(dset,\n",
    "                         main_text='Review Text',\n",
    "                         label_names='Department Name',\n",
    "                         filter_dict={'Review Text': lambda x: x is not None,\n",
    "                                      'Department Name': lambda x: x is not None,\n",
    "                                     },\n",
    "                         metadatas=['Title','Division Name'],\n",
    "                         content_transformations=[text_normalize,str.lower],\n",
    "                         content_augmentations= [nearby_aug_func,str.lower], \n",
    "                         val_ratio=None,\n",
    "                         batch_size=bs,\n",
    "                         seed=42,\n",
    "                         convert_training_to_iterable=False,\n",
    "                         verbose=False\n",
    "                        )\n",
    "benchmarking_and_memory_usage(tdc,bs,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5f6231",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30342fd9",
   "metadata": {},
   "source": [
    "With CPU batch size of 128, and data iteration of 1280 items (10 batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c575d04",
   "metadata": {},
   "source": [
    "1. Time to process + tokenize. Unit: seconds\n",
    "\n",
    "|  | Filtering | + 2-column metadatas | + 2 tfms and 2 augs | + no train shuffling |\n",
    "|------------------------------|-------------------------|-------------------------|-----------------|--------------------|\n",
    "| no iterable training         | 37.038                  | 40.147                  | 62.309          | 59.452             |\n",
    "| iterable training            | 2.85                    | 2.623                   | 22.31           | 22.421             |\n",
    "| streaming                    | 0.002                   | 0.002                   | 0.084           | 0.08               |\n",
    "\n",
    "2. Time to loop through 1280 items (10 batches). Unit: seconds\n",
    "\n",
    "|                              | Filtering | + 2-column metadatas | + 2 tfms and 2 augs | + no train shuffling |\n",
    "|------------------------------|-------------------------|-----------------|--------------------|------------------------------------|\n",
    "| no iterable training         | 0.155                    | 0.181           | 0.183              | 0.184                              |\n",
    "| iterable training            | 0.464                    | 0.544           | 0.562              | 0.474                              |\n",
    "| streaming                    | 1.244                    | 1.365           | 95.443             | 11.529                             |\n",
    "\n",
    "3. Maximum memory usage. Unit: megabytes\n",
    "\n",
    "|                              | Filtering | + 2-column metadatas | + 2 tfms and 2 augs | + no train shuffling |\n",
    "|------------------------------|-------------------------|-----------------|--------------------|------------------------------------|\n",
    "| no iterable training         | 762.734 | 806.473                  | 859.008         | 867.031            | \n",
    "| iterable training            |799.742 | 838.613                  | 891.176         | 892                |\n",
    "| streaming                    | 752.238 | 829.074                  | 6955.02         | 6841.391           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea69aad",
   "metadata": {},
   "source": [
    "## Tips and tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80831d5",
   "metadata": {},
   "source": [
    "- For non-streaming data, the best way to minimize processing and iteration time is:\n",
    "    - Use non-iterable training (which means don't turn training set into an Iterable Dataset)\n",
    "    - Turn on dataset caching, and run the processing step once for it to be cached\n",
    "- If caching is not an option, then use iterable training (turn trainingset into an Iterable Dataset)\n",
    "- The more content transformations and augmentations added, the slower the process + iteration. This is especially true for streaming data\n",
    "- For streaming data, which might be the slowest option, here are a few things to speed up the whole pipeline:\n",
    "    - Try to define and create a validation set split in your dataset; don't use the validation split functionality of `TextDataController\n",
    "    - Minimize the amount of content transformation and content augmentation\n",
    "    - Turn off `shuffle_trn`\n",
    "    - Set a smaller CPU batch size. E.g. in my 64gb RAM machine, and this dataset of 117k rows, I can only set batch size up to 200 to avoid memory error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb73e85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
